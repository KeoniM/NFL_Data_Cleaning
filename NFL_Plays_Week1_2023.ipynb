{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ciN_CS4bOcpV",
        "rTlTgrlpO_q1",
        "HPdKuDJJPIUZ",
        "ELSW1R82_TqT",
        "uau4ner4_fug",
        "XCAisXBXGNyb",
        "9L_L6vxtmnLQ",
        "bRGsJa-J8CPe",
        "oHh3e-2kHDIM",
        "TieP_Cy5rmj-",
        "CZpJpikZCx--",
        "Rp-Bszm-B9rh",
        "eIX_e2jUrwdt",
        "Rt2DLo02qSa5",
        "yzGnlGvPZiZE",
        "dhsLNvcBA9uW",
        "I_uTKSIZsZDi",
        "9A1yQxl0kmLn",
        "9M6XwDERno2n",
        "U7HnZWShxAX5",
        "VYVhXDgbC3m3",
        "01U2No85CuOo",
        "wMTxhm9K2gY9",
        "56zcEqI4C9NQ",
        "F09Qp3xQ9oq9",
        "vMM5uVTFyDYu",
        "m-sl_mhsaHWQ",
        "3i6ytmPQ5463",
        "btd2EUHxtbL2",
        "QHp6b-_SqOw_",
        "MGd9pIPpvtL2",
        "Qh-8uXf-lvh1",
        "I4cK_IySHwL3",
        "TrudwcGMsfXh",
        "lXOsRYYuiXxf"
      ],
      "authorship_tag": "ABX9TyMpcz0cBUlF9WOt2/awXJxg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KeoniM/NFL_Data_Cleaning/blob/main/NFL_Plays_Week1_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PURPOSE:**\n",
        "- Accurately clean a week's worth of play data\n",
        "  - Season 2023 -> Week 1\n",
        "\n",
        "**THOUGHTS, CONCERNS AND IDEAS FOR LATER:**\n",
        "\n",
        "*General*\n",
        "\n",
        "1. Players with the same name\n",
        "  - I do think that the raw data has naming conventions to decipher between two players with the exact same name but not 100% sure.\n",
        "2. Cleaning check (TESTING)\n",
        "  - I need some type of method that will help decern whether these plays have been cleaned correctly. Currently I am manually checking but this is not sustainable or efficient.\n",
        "    - **IDEA:** Cross reference recorded NFL stats with stats here and compare likeness. (maybe return a df that highlights differences?)\n",
        "3. Adjust features (PlayOutcomes/PlayTypes/IsScoringDrive/etc...) for plays that have been split up into multiple rows (Fumble Recoveries, Interceptions, etc...).\n",
        "  - EXAMPLE: Running back fumbles on a run play but recovers it and rushes for x yards.\n",
        "    - This would still count towards his rushing yards.\n",
        "    - 'PlayType' = 'Run'\n",
        "    - 'PlayOutcome' = 'X Yard Run'\n",
        "      - 2 rows will be present for this type of play. 1 before fumble and 1 after fumble. Each will have their own separate 'PlayOutcome'..?\n",
        "  - EXAMPLE: Any fumble recovery that is not the runningback on an intended running play\n",
        "    - This would not count as rushing yards for the player who recovered the fumble.\n",
        "    - 'PlayType' = 'Fumble Return'..?\n",
        "    - 'PlayOutcome' = 'X Yard Fumble Return'..?\n",
        "  - EXAMPLE: If a team throws an interception and that interception results in a touchdown for the opposing team, I do not think it should be considered as a 'scoring drive' for the team that threw the interception.\n",
        "    - IDEA: For the category \"isScoringDrive\" the categories could be:\n",
        "      1. 0 - Is not a scoring drive\n",
        "      2. 1 - Is scoring drive for team on offense\n",
        "      3. 2 - Is scoring drive for team on defense\n",
        "  - When a play is split up into multiple rows, should each row have the starting formation of the play or should the initial starting row of the play have the formation?\n",
        "  - IDEA: Should I broaden 'playtypes' to include:\n",
        "    1. yardage after fumble (Currently have it as 'Run' playtype)\n",
        "    2. yardage after interception (Currently have it as 'Interception')\n",
        "4. Condense features.\n",
        "  - For plays such as punt or kickoff, maybe I can group together data such as who is the longsnapper, holder and kicker instead of representing them on their own.\n",
        "5. Condense regular expressions to grab multiple pieces of wanted data instead of individual.\n",
        "6. Use 'Fuzzywuzzy' to find like play outcomes.\n",
        "  - This will give me a chance to automate play types instead of eying them and seaparating them manually.\n",
        "    - Not sure if I will actually need this?\n",
        "7. Map team name with their abbreviations ( e.g. \"Cowboys\" <-> \"DAL\" )\n",
        "  - Maybe with larger datasets with multiple weeks, I can map team names with team abbrevations that match up the most.\n",
        "8. Shorten cleaning methods by creating a helper method to grab data from the defense on a play\n",
        "9. Add features to break down penalty plays. This might be beneficial to get more detailed on.\n",
        "10. Punt and kickoff returns are practically identical. Try to find a regular expression that will capture them both AND catch touchdown plays too.\n",
        "11. I am realizing that NFL.com does not have every single play within a game. I am missing an extra point after a touchdown.\n",
        "12. When a player gets sacked, there is no way to determine what type of play the offense was going for (pass/run) based off of the play description.\n",
        "13. If a drive ends with an interception for a touchdown, every play within the drive will say that 'TeamWithPossession' is the other team.\n",
        "14. Not all plays are recorded. There are some plays missing.\n",
        "15. Make sure to add a feature descriptions for raw untouched data\n",
        "\n",
        "*Offense*\n",
        "\n",
        "1. Trick plays\n",
        "  - Need a larger sample size that contains more trick plays\n",
        "2. Latterals\n",
        "  - Need a larger sample size that contains more latterals\n",
        "    - (Only one has been found within the dataset \"Season 2023 Week 1\", it was handled for that specific play type but have not implement for all)\n",
        "      - IDEA: Make a new helper method to handle \"Handoff\" plays.\n",
        "        - Should I make a new feature for handoffs? Like a feature that links one action to another? Would that be valuable?\n",
        "\n",
        "*Defense*\n",
        "\n",
        "1. Nuance of players recorded for sacks & forced fumbles\n",
        "  - Look under sack play type cleaning method\n",
        "    - The formatting of multiple defending players in on a fumbled play may cause wrong recording of data (e.i. player who assisted in tackle may be credited for the forced fumble)\n",
        "\n",
        "2. DEFENSIVE STATS ARE CURRENTLY WRONG\n",
        "  - I will work on 0.5 tackes, solo tackles and assists. I need to adjust cleaning methods to collect this data better.\n",
        "    - ';' means solo and assisted tackle\n",
        "    - ',' means 0.5 tackle\n",
        "  - Need to figure out when players a noticed for good coverage? Assisting in an interception (I think this is what the play descriptions are stating?)\n",
        "3. Safety\n",
        "  - I have not come across safeties yet."
      ],
      "metadata": {
        "id": "bDIp3ojKOdg2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MOUNTING AND IMPORTS"
      ],
      "metadata": {
        "id": "ciN_CS4bOcpV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZS3J98keONRD",
        "outputId": "86814428-cfd2-4ccb-e50e-948fe14b1ae9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Used to access personal google cloud services\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gLupTRXO5gw",
        "outputId": "d524b0ac-9798-4688-e76c-d344033ea1ec"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authenticated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "\n",
        "# Data manipulation\n",
        "import pandas as pd\n",
        "\n",
        "# Regular expressions\n",
        "import re\n",
        "\n",
        "# Grab data from database\n",
        "from google.cloud import bigquery"
      ],
      "metadata": {
        "id": "1YadW6p7O7Lf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # debugger (maybe use in the future)\n",
        "# %pdb on"
      ],
      "metadata": {
        "id": "jKpGDloBiQN8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOADING DATA (BigQuery queries)"
      ],
      "metadata": {
        "id": "rTlTgrlpO_q1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Client connect to bigquery project\n",
        "client = bigquery.Client('nfl-data-430702')"
      ],
      "metadata": {
        "id": "W05L1TH6PAcb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Season 2023 Week 1"
      ],
      "metadata": {
        "id": "HPdKuDJJPIUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Grabbing all plays from 2023 Week 1 NFL Sesason\n",
        "week1_2023_plays_query = \"\"\"\n",
        "                         SELECT *\n",
        "                         FROM `nfl-data-430702.NFL_Scores.NFL-Plays-Week1_2023`\n",
        "                         \"\"\"\n",
        "\n",
        "# Running psuedo query, and returns the amount of bytes it will take to run query\n",
        "dry_run_config = bigquery.QueryJobConfig(dry_run=True)\n",
        "dry_run_query = client.query(week1_2023_plays_query, job_config=dry_run_config)\n",
        "print(\"This query will process {} bytes.\".format(dry_run_query.total_bytes_processed))\n",
        "\n",
        "# Running query (Being mindful of the amount of data being grabbed)\n",
        "# Will grab a maximum of a Gigabyte\n",
        "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**9)\n",
        "safe_config_query = client.query(week1_2023_plays_query, job_config=safe_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnOg_zdhPLHi",
        "outputId": "1a72adc6-8fa8-42c4-863b-8c1494fa458f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This query will process 570194 bytes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Putting data attained from query into a dataframe\n",
        "week1_2023_plays = safe_config_query.to_dataframe()"
      ],
      "metadata": {
        "id": "27xLLVO6PfSJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "week1_2023_plays.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pJP-0GxhPhI_",
        "outputId": "ef3ff7a7-58f9-4c37-d45f-87b123945cda"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Season    Week  Day   Date AwayTeam HomeTeam      Quarter  DriveNumber  \\\n",
              "0    2023  Week 1  MON  09/11    Bills     Jets  1ST QUARTER            1   \n",
              "1    2023  Week 1  MON  09/11    Bills     Jets  1ST QUARTER            1   \n",
              "2    2023  Week 1  MON  09/11    Bills     Jets  1ST QUARTER            1   \n",
              "3    2023  Week 1  MON  09/11    Bills     Jets  1ST QUARTER            1   \n",
              "4    2023  Week 1  MON  09/11    Bills     Jets  1ST QUARTER            1   \n",
              "\n",
              "  TeamWithPossession  IsScoringDrive  PlayNumberInDrive  IsScoringPlay  \\\n",
              "0                BUF               0                  1              0   \n",
              "1                BUF               0                  2              0   \n",
              "2                BUF               0                  3              0   \n",
              "3                BUF               0                  4              0   \n",
              "4                BUF               0                  5              0   \n",
              "\n",
              "   PlayOutcome                                    PlayDescription  \\\n",
              "0      Kickoff  G.Zuerlein kicks 65 yards from NYJ 35 to end z...   \n",
              "1  7 Yard Pass  (15:00) (Shotgun) J.Allen pass short right to ...   \n",
              "2  5 Yard Pass  (14:34) (No Huddle, Shotgun) J.Allen pass shor...   \n",
              "3   3 Yard Run  (14:01) J.Cook up the middle to BUF 40 for 3 y...   \n",
              "4   2 Yard Run  (13:24) (Shotgun) J.Cook up the middle to BUF ...   \n",
              "\n",
              "             PlayStart  \n",
              "0  Kickoff from NYJ 35  \n",
              "1   1st & 10 at BUF 25  \n",
              "2    2nd & 3 at BUF 32  \n",
              "3   1st & 10 at BUF 37  \n",
              "4    2nd & 7 at BUF 40  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fe247a82-706b-4069-a1e1-5f177c12869d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Season</th>\n",
              "      <th>Week</th>\n",
              "      <th>Day</th>\n",
              "      <th>Date</th>\n",
              "      <th>AwayTeam</th>\n",
              "      <th>HomeTeam</th>\n",
              "      <th>Quarter</th>\n",
              "      <th>DriveNumber</th>\n",
              "      <th>TeamWithPossession</th>\n",
              "      <th>IsScoringDrive</th>\n",
              "      <th>PlayNumberInDrive</th>\n",
              "      <th>IsScoringPlay</th>\n",
              "      <th>PlayOutcome</th>\n",
              "      <th>PlayDescription</th>\n",
              "      <th>PlayStart</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023</td>\n",
              "      <td>Week 1</td>\n",
              "      <td>MON</td>\n",
              "      <td>09/11</td>\n",
              "      <td>Bills</td>\n",
              "      <td>Jets</td>\n",
              "      <td>1ST QUARTER</td>\n",
              "      <td>1</td>\n",
              "      <td>BUF</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Kickoff</td>\n",
              "      <td>G.Zuerlein kicks 65 yards from NYJ 35 to end z...</td>\n",
              "      <td>Kickoff from NYJ 35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2023</td>\n",
              "      <td>Week 1</td>\n",
              "      <td>MON</td>\n",
              "      <td>09/11</td>\n",
              "      <td>Bills</td>\n",
              "      <td>Jets</td>\n",
              "      <td>1ST QUARTER</td>\n",
              "      <td>1</td>\n",
              "      <td>BUF</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>7 Yard Pass</td>\n",
              "      <td>(15:00) (Shotgun) J.Allen pass short right to ...</td>\n",
              "      <td>1st &amp; 10 at BUF 25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2023</td>\n",
              "      <td>Week 1</td>\n",
              "      <td>MON</td>\n",
              "      <td>09/11</td>\n",
              "      <td>Bills</td>\n",
              "      <td>Jets</td>\n",
              "      <td>1ST QUARTER</td>\n",
              "      <td>1</td>\n",
              "      <td>BUF</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>5 Yard Pass</td>\n",
              "      <td>(14:34) (No Huddle, Shotgun) J.Allen pass shor...</td>\n",
              "      <td>2nd &amp; 3 at BUF 32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2023</td>\n",
              "      <td>Week 1</td>\n",
              "      <td>MON</td>\n",
              "      <td>09/11</td>\n",
              "      <td>Bills</td>\n",
              "      <td>Jets</td>\n",
              "      <td>1ST QUARTER</td>\n",
              "      <td>1</td>\n",
              "      <td>BUF</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3 Yard Run</td>\n",
              "      <td>(14:01) J.Cook up the middle to BUF 40 for 3 y...</td>\n",
              "      <td>1st &amp; 10 at BUF 37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2023</td>\n",
              "      <td>Week 1</td>\n",
              "      <td>MON</td>\n",
              "      <td>09/11</td>\n",
              "      <td>Bills</td>\n",
              "      <td>Jets</td>\n",
              "      <td>1ST QUARTER</td>\n",
              "      <td>1</td>\n",
              "      <td>BUF</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2 Yard Run</td>\n",
              "      <td>(13:24) (Shotgun) J.Cook up the middle to BUF ...</td>\n",
              "      <td>2nd &amp; 7 at BUF 40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe247a82-706b-4069-a1e1-5f177c12869d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fe247a82-706b-4069-a1e1-5f177c12869d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fe247a82-706b-4069-a1e1-5f177c12869d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-da1a490d-8755-47c1-921c-04ef6773f15c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-da1a490d-8755-47c1-921c-04ef6773f15c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-da1a490d-8755-47c1-921c-04ef6773f15c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "week1_2023_plays",
              "summary": "{\n  \"name\": \"week1_2023_plays\",\n  \"rows\": 2600,\n  \"fields\": [\n    {\n      \"column\": \"Season\",\n      \"properties\": {\n        \"dtype\": \"Int64\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2023\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Week\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Week 1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Day\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"MON\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"09/11\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AwayTeam\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"Bills\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HomeTeam\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"Jets\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Quarter\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2ND QUARTER\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DriveNumber\",\n      \"properties\": {\n        \"dtype\": \"Int64\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TeamWithPossession\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 32,\n        \"samples\": [\n          \"PIT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IsScoringDrive\",\n      \"properties\": {\n        \"dtype\": \"Int64\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PlayNumberInDrive\",\n      \"properties\": {\n        \"dtype\": \"Int64\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IsScoringPlay\",\n      \"properties\": {\n        \"dtype\": \"Int64\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PlayOutcome\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 170,\n        \"samples\": [\n          \"Touchdown Buccaneers\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PlayDescription\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2487,\n        \"samples\": [\n          \"(:54) (Shotgun) K.Cousins pass deep middle to J.Jefferson to TB 22 for 42 yards (A.Winfield).\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PlayStart\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2119,\n        \"samples\": [\n          \"3rd & 16 at LA 18\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Noting the original size of the raw uncleaned dataframe of data\n",
        "# - (rows, columns)\n",
        "week1_2023_plays.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oShT8MvlRQdR",
        "outputId": "cd3306d3-5d34-4cb8-f04d-a0ea2f43262b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2600, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CATEGORIZE PLAYS\n",
        "- The goal here is to parse out the different values for 'PlayOutcome'\n",
        "  - This is where I will separate different types of plays\n",
        "    - ( pass / run / kickoff / etc. )"
      ],
      "metadata": {
        "id": "9JD1VzJWRWn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Maybe try to fuzzywuzzy this in the future?\n",
        "# - I need to narrow these down into basic categories.\n",
        "# - (Take away numbers & \"Yard\")\n",
        "# - Find the most common words between all outcomes (hoping to get all categories e.i. 'Pass', 'Run', 'Touchdown', etc...)\n",
        "\n",
        "# All play outcomes from the game\n",
        "# - From here we can categorize and clean plays accordingly\n",
        "week1_2023_plays['PlayOutcome'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0WcGgv1RXl0",
        "outputId": "a9784bb4-a8bb-4e43-a7bc-b131392334cd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Kickoff', '7 Yard Pass', '5 Yard Pass', '3 Yard Run',\n",
              "       '2 Yard Run', 'Pass Incomplete', 'Punt', '-5 Yard Penalty',\n",
              "       '5 Yard Run', '1 Yard Pass', '14 Yard Run', '3 Yard Pass',\n",
              "       '8 Yard Run', '6 Yard Pass', '15 Yard Pass', '-9 Yard Sack',\n",
              "       '4 Yard Pass', '13 Yard Pass', 'Field Goal', '-2 Yard Sack',\n",
              "       'Interception', '-5 Yard Run', '18 Yard Pass', '8 Yard Pass',\n",
              "       '6 Yard Run', '12 Yard Run', '-1 Yard Run', '26 Yard Pass',\n",
              "       'Touchdown Bills', 'Extra Point Good', '13 Yard Run',\n",
              "       '-3 Yard Sack', '7 Yard Run', '9 Yard Pass', '4 Yard Run',\n",
              "       'Fumble', '-10 Yard Penalty', '10 Yard Pass', '26 Yard Run',\n",
              "       '5 Yard Penalty', '-10 Yard Sack', '22 Yard Pass', '-4 Yard Run',\n",
              "       '-12 Yard Sack', '83 Yard Run', '1 Yard Run', '2 Yard Pass',\n",
              "       '10 Yard Run', 'Run for No Gain', '12 Yard Pass', '20 Yard Pass',\n",
              "       '9 Yard Run', '-2 Yard Pass', 'Sack', '24 Yard Pass',\n",
              "       '14 Yard Pass', 'Touchdown Jets', '-3 Yard Run', '-2 Yard Run',\n",
              "       'Touchdown Packers', '16 Yard Pass', '30 Yard Pass',\n",
              "       '-8 Yard Sack', '51 Yard Pass', '37 Yard Pass', '-8 Yard Run',\n",
              "       'Turnover on Downs', '19 Yard Pass', '23 Yard Pass', '-7 Yard Run',\n",
              "       '11 Yard Run', '11 Yard Pass', '-7 Yard Sack', '-4 Yard Pass',\n",
              "       '-11 Yard Sack', '-6 Yard Run', 'Touchdown Bears',\n",
              "       '2PT Conversion Success', '2PT Conversion Fails',\n",
              "       'Touchdown Colts', '35 Yard Pass', '-5 Yard Sack',\n",
              "       '15 Yard Penalty', '-14 Yard Run', '-1 Yard Sack', '-3 Yard Pass',\n",
              "       'Touchdown Jaguars', '29 Yard Pass', '22 Yard Run',\n",
              "       '18 Yard Penalty', 'Field Goal No Good', '-1 Yard Pass',\n",
              "       '17 Yard Run', '19 Yard Run', 'Touchdown Browns', '33 Yard Pass',\n",
              "       '16 Yard Run', 'Touchdown Chiefs', '25 Yard Pass', '34 Yard Pass',\n",
              "       '41 Yard Penalty', '21 Yard Pass', 'Touchdown Lions',\n",
              "       '-12 Yard Penalty', '18 Yard Run', '23 Yard Run',\n",
              "       'Pass for No Gain', 'Touchdown Cowboys', '49 Yard Pass',\n",
              "       '37 Yard Penalty', '25 Yard Run', '-4 Yard Sack', '-5 Yard Pass',\n",
              "       'Touchdown Ravens', '26 Yard Penalty', '1 Yard Penalty',\n",
              "       '17 Yard Penalty', '17 Yard Pass', '-6 Yard Sack', '-6 Yard Pass',\n",
              "       '27 Yard Pass', '45 Yard Pass', 'Touchdown Saints', '41 Yard Pass',\n",
              "       '46 Yard Pass', 'Touchdown Raiders', '16 Yard Penalty',\n",
              "       '31 Yard Pass', 'Touchdown Broncos', 'Extra Point No Good',\n",
              "       '-7 Yard Pass', 'Touchdown Falcons', '-13 Yard Sack',\n",
              "       '21 Yard Run', '-7 Yard Penalty', '-4 Yard Penalty',\n",
              "       'Touchdown Panthers', '9 Yard Penalty', '4 Yard Penalty',\n",
              "       'Touchdown Buccaneers', '20 Yard Run', 'Touchdown Vikings',\n",
              "       '42 Yard Pass', '36 Yard Pass', 'Touchdown Chargers',\n",
              "       '55 Yard Run', '13 Yard Penalty', 'Penalty', 'Touchdown Dolphins',\n",
              "       '28 Yard Pass', '30 Yard Penalty', '47 Yard Pass',\n",
              "       'Touchdown Patriots', '32 Yard Pass', 'Touchdown Eagles',\n",
              "       '-14 Yard Penalty', 'Touchdown Rams', '-15 Yard Penalty',\n",
              "       '44 Yard Pass', '10 Yard Penalty', 'Touchdown Seahawks',\n",
              "       '15 Yard Run', '3 Yard Penalty', 'Touchdown 49ers', '39 Yard Run',\n",
              "       'Touchdown Steelers', '11 Yard Penalty', '29 Yard Run',\n",
              "       'Touchdown Cardinals', 'Touchdown Commanders'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTES:\n",
        "# - Currently, I am eyeing at all unique play outcomes to categorizing them.\n",
        "#   - This type of approach is not flexable because a play outcome can\n",
        "#     arise that has not been seen yet.\n",
        "#     - There may be more play outcomes in the future when working on a full season,\n",
        "#       let alone all seasons and future games\n",
        "\n",
        "# Play Types with complete cleaning methods (As far as this sample size goes)\n",
        "\n",
        "# ~ OFFENSE ~\n",
        "df_2023_pass_week1 = week1_2023_plays[week1_2023_plays['PlayOutcome'].str.contains('Pass')]\n",
        "df_2023_run_week1 = week1_2023_plays[week1_2023_plays['PlayOutcome'].str.contains('Run')]\n",
        "# ~ DEFENSE ~\n",
        "df_2023_interception_week1 = week1_2023_plays[week1_2023_plays['PlayOutcome'].str.contains('Interception')]\n",
        "df_2023_sack_week1 = week1_2023_plays[week1_2023_plays['PlayOutcome'].str.contains('Sack')]\n",
        "# ~ SPECIAL TEAMS ~\n",
        "df_2023_punt_week1 = week1_2023_plays[week1_2023_plays['PlayOutcome'].str.contains('Punt')]\n",
        "df_2023_kickoff_week1 = week1_2023_plays[week1_2023_plays['PlayOutcome'].str.contains('Kickoff')]\n",
        "# ~ SCORING ~\n",
        "df_2023_touchdown_week1 = week1_2023_plays[week1_2023_plays['PlayOutcome'].str.contains('Touchdown')]\n",
        "df_2023_extrapoint_week1 = week1_2023_plays[week1_2023_plays['PlayOutcome'].str.contains('Extra Point')]\n",
        "df_2023_fieldgoal_week1 = week1_2023_plays[week1_2023_plays['PlayOutcome'].str.contains('Field Goal')]\n",
        "df_2023_2pt_conversion_week1 = week1_2023_plays[week1_2023_plays['PlayOutcome'].str.contains('2PT Conversion')]\n",
        "# ~ OTHER ~\n",
        "df_2023_fumble_week1 = week1_2023_plays[week1_2023_plays['PlayOutcome'].str.contains('Fumble')]\n",
        "df_2023_penalty_week1 = week1_2023_plays[week1_2023_plays['PlayOutcome'].str.contains('Penalty')]\n",
        "df_2023_turnover_on_downs_week1 = week1_2023_plays[week1_2023_plays['PlayOutcome'].str.contains('Turnover on Downs')]\n"
      ],
      "metadata": {
        "id": "sYCiceyQRrxl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SANITY CHECK (All Plays Accounted for)\n",
        "  - Once all plays have been categorizing, will compare the sum of all plays within each category to the size of the original dataframe of plays.\n",
        "    - Goal is to make sure the number of plays is the same."
      ],
      "metadata": {
        "id": "ELSW1R82_TqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Categorized plays\n",
        "\n",
        "plays_list = [df_2023_pass_week1,         # Offense\n",
        "              df_2023_run_week1,\n",
        "              df_2023_interception_week1, # Defense\n",
        "              df_2023_sack_week1,\n",
        "              df_2023_punt_week1,         # Special Teams\n",
        "              df_2023_kickoff_week1,\n",
        "              df_2023_touchdown_week1,    # Scoring\n",
        "              df_2023_extrapoint_week1,\n",
        "              df_2023_fieldgoal_week1,\n",
        "              df_2023_2pt_conversion_week1,\n",
        "              df_2023_fumble_week1,       # Other\n",
        "              df_2023_penalty_week1,\n",
        "              df_2023_turnover_on_downs_week1]\n",
        "\n",
        "num_plays_categorized = 0\n",
        "\n",
        "for plays in plays_list:\n",
        "  num_plays_categorized = num_plays_categorized + len(plays)\n",
        "\n",
        "num_plays_categorized == len(week1_2023_plays)"
      ],
      "metadata": {
        "id": "PcD7xXS03qBu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "674b9caa-a7ad-4810-e99d-68103b653465"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HELPER METHODS (personal use)\n",
        "- For personal use, does not actually take part in cleaning dataset at all."
      ],
      "metadata": {
        "id": "uau4ner4_fug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PURPOSE:\n",
        "# - Quick look at a section of plays\n",
        "#   - Ideally the plays that the user wants to break down and clean.\n",
        "# INPUT PARAMETERS:\n",
        "# df_all_plays      - DataFrame - The original dataframe where the desired plays to view came from\n",
        "# df_section_plays  - DataFrame - A section of the original dataframe the user wants to view\n",
        "# RETURN:\n",
        "# - Printing to the console:\n",
        "#   1. index of play\n",
        "#   2. 'PlayDescription' feature of play\n",
        "#   3. 'PlayOutcome' feature of play\n",
        "def print_plays(df_all_plays, df_section_plays):\n",
        "  for idx, value in df_section_plays['PlayOutcome'].items():\n",
        "    play = df_all_plays['PlayDescription'].iloc[idx]\n",
        "    print(\"index:\" + str(idx))\n",
        "    for i in play.split(\". \"):\n",
        "      print(i)\n",
        "    print(value)\n",
        "    print()"
      ],
      "metadata": {
        "id": "u8Sza2J8_hwG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EXAMPLE: Displaying all touchdown plays within dataset\n",
        "\n",
        "print_plays(week1_2023_plays, df_2023_touchdown_week1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aWsMN7EqofF",
        "outputId": "9a3e637b-c8ef-43d1-a8d7-27977432951d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "index:33\n",
            "(4:51) (Shotgun) J.Allen pass short right to S.Diggs for 5 yards, TOUCHDOWN.\n",
            "Touchdown Bills\n",
            "\n",
            "index:134\n",
            "(4:58) Z.Wilson pass short left to G.Wilson for 3 yards, TOUCHDOWN.\n",
            "Touchdown Jets\n",
            "\n",
            "index:152\n",
            "(9:21) S.Martin punts 42 yards to NYJ 35, Center-R.Ferguson\n",
            "X.Gipson for 65 yards, TOUCHDOWN.\n",
            "Touchdown Jets\n",
            "\n",
            "index:163\n",
            "(6:14) (Shotgun) J.Love pass short middle to R.Doubs for 8 yards, TOUCHDOWN.\n",
            "Touchdown Packers\n",
            "\n",
            "index:197\n",
            "(10:23) (Shotgun) A.Jones right guard for 1 yard, TOUCHDOWN.\n",
            "Touchdown Packers\n",
            "\n",
            "index:202\n",
            "(6:34) (Shotgun) J.Love pass short middle to A.Jones for 35 yards, TOUCHDOWN\n",
            "GB-A.Jones was injured during the play\n",
            "His return is Questionable.\n",
            "Touchdown Packers\n",
            "\n",
            "index:214\n",
            "(13:34) J.Love pass short left to R.Doubs for 4 yards, TOUCHDOWN.\n",
            "Touchdown Packers\n",
            "\n",
            "index:219\n",
            "(12:53) (Shotgun) J.Fields pass short middle intended for D.Mooney INTERCEPTED by Q.Walker [K.Clark] at CHI 37\n",
            "Q.Walker for 37 yards, TOUCHDOWN\n",
            "PENALTY on GB-R.Douglas, Unsportsmanlike Conduct, 15 yards, enforced between downs.\n",
            "Touchdown Packers\n",
            "\n",
            "index:289\n",
            "(1:04) (Shotgun) J.Fields pass deep right to D.Mooney for 20 yards, TOUCHDOWN.\n",
            "Touchdown Bears\n",
            "\n",
            "index:311\n",
            "(2:58) R.Johnson left guard for 2 yards, TOUCHDOWN.\n",
            "Touchdown Bears\n",
            "\n",
            "index:339\n",
            "(15:00) (Shotgun) A.Richardson up the middle for 2 yards, TOUCHDOWN.\n",
            "Touchdown Colts\n",
            "\n",
            "index:363\n",
            "(11:33) (Shotgun) A.Richardson pass short left to M.Pittman for 39 yards, TOUCHDOWN.\n",
            "Touchdown Colts\n",
            "\n",
            "index:375\n",
            "(2:41) (Shotgun) T.Lawrence sacked at JAX 28 for -8 yards (D.Buckner)\n",
            "FUMBLES (D.Buckner) [D.Buckner], recovered by JAX-T.Bigsby at JAX 35\n",
            "T.Bigsby to JAX 35 for no gain (Z.Franklin)\n",
            "FUMBLES (Z.Franklin), RECOVERED by IND-D.Buckner at JAX 26\n",
            "D.Buckner for 26 yards, TOUCHDOWN\n",
            "The Replay Official reviewed the score ruling, and the play was Upheld\n",
            "The ruling on the field stands.\n",
            "Touchdown Colts\n",
            "\n",
            "index:419\n",
            "(5:26) (Shotgun) T.Lawrence pass short left to C.Ridley for 9 yards, TOUCHDOWN.\n",
            "Touchdown Jaguars\n",
            "\n",
            "index:436\n",
            "(5:02) (Shotgun) T.Lawrence pass deep right to Z.Jones for 18 yards, TOUCHDOWN.\n",
            "Touchdown Jaguars\n",
            "\n",
            "index:481\n",
            "(5:17) (Shotgun) T.Bigsby left guard for 1 yard, TOUCHDOWN.\n",
            "Touchdown Jaguars\n",
            "\n",
            "index:485\n",
            "(4:15) T.Etienne left tackle for 26 yards, TOUCHDOWN.\n",
            "Touchdown Jaguars\n",
            "\n",
            "index:610\n",
            "(:22) (Shotgun) D.Watson left end for 13 yards, TOUCHDOWN.\n",
            "Touchdown Browns\n",
            "\n",
            "index:639\n",
            "(9:14) N.Harris and J.Hudson reported in as eligible\n",
            " D.Watson pass short right to H.Bryant for 3 yards, TOUCHDOWN.\n",
            "Touchdown Browns\n",
            "\n",
            "index:672\n",
            "(11:56) (Shotgun) P.Mahomes pass short left to R.Rice for 1 yard, TOUCHDOWN.\n",
            "Touchdown Chiefs\n",
            "\n",
            "index:684\n",
            "(:37) (Shotgun) P.Mahomes pass short right to B.Bell for 4 yards, TOUCHDOWN.\n",
            "Touchdown Chiefs\n",
            "\n",
            "index:745\n",
            "(2:52) (Shotgun) J.Goff pass short right to A.St\n",
            "Brown for 9 yards, TOUCHDOWN.\n",
            "Touchdown Lions\n",
            "\n",
            "index:777\n",
            "(11:04) (Shotgun) P.Mahomes pass short right intended for K.Toney INTERCEPTED by B.Branch at 50\n",
            "B.Branch for 50 yards, TOUCHDOWN.\n",
            "Touchdown Lions\n",
            "\n",
            "index:801\n",
            "(7:11) D.Montgomery up the middle for 8 yards, TOUCHDOWN.\n",
            "Touchdown Lions\n",
            "\n",
            "index:827\n",
            "(8:14) G.Gano 45 yard field goal is BLOCKED (J.Thomas), Center-C.Kreiter, Holder-J.Gillan, RECOVERED by DAL-N.Igbinoghene at DAL 42\n",
            "N.Igbinoghene for 58 yards, TOUCHDOWN.\n",
            "Touchdown Cowboys\n",
            "\n",
            "index:840\n",
            "(2:30) (Shotgun) D.Jones pass short left intended for S.Barkley INTERCEPTED by D.Bland (T.Diggs) at NYG 22\n",
            "D.Bland for 22 yards, TOUCHDOWN.\n",
            "Touchdown Cowboys\n",
            "\n",
            "index:858\n",
            "(8:07) T.Pollard right end for 2 yards, TOUCHDOWN.\n",
            "Touchdown Cowboys\n",
            "\n",
            "index:874\n",
            "(10:05) T.Pollard right end for 1 yard, TOUCHDOWN.\n",
            "Touchdown Cowboys\n",
            "\n",
            "index:890\n",
            "(11:37) K.Turpin left end for 7 yards, TOUCHDOWN.\n",
            "Touchdown Cowboys\n",
            "\n",
            "index:988\n",
            "(1:05) J.Dobbins right end for 4 yards, TOUCHDOWN.\n",
            "Touchdown Ravens\n",
            "\n",
            "index:1010\n",
            "(9:58) (No Huddle, Shotgun) J.Hill right tackle for 2 yards, TOUCHDOWN.\n",
            "Touchdown Ravens\n",
            "\n",
            "index:1018\n",
            "(5:24) (Shotgun) J.Hill right guard for 2 yards, TOUCHDOWN.\n",
            "Touchdown Ravens\n",
            "\n",
            "index:1194\n",
            "(1:28) (Shotgun) D.Carr pass deep right to R.Shaheed for 19 yards, TOUCHDOWN.\n",
            "Touchdown Saints\n",
            "\n",
            "index:1307\n",
            "(9:32) (Shotgun) J.Garoppolo pass short left to J.Meyers for 3 yards, TOUCHDOWN\n",
            "PENALTY on LV-J.Meyers, Taunting, 15 yards, enforced between downs.\n",
            "Touchdown Raiders\n",
            "\n",
            "index:1353\n",
            "(6:38) (Shotgun) J.Garoppolo pass short right to J.Meyers for 6 yards, TOUCHDOWN.\n",
            "Touchdown Raiders\n",
            "\n",
            "index:1382\n",
            "(:50) (Shotgun) R.Wilson pass short right to L.Humphrey for 5 yards, TOUCHDOWN.\n",
            "Touchdown Broncos\n",
            "\n",
            "index:1406\n",
            "(:18) (Shotgun) R.Wilson pass short right to C.Sutton for 5 yards, TOUCHDOWN.\n",
            "Touchdown Broncos\n",
            "\n",
            "index:1454\n",
            "(15:00) (Shotgun) D.Ridder pass short right to B.Robinson for 11 yards, TOUCHDOWN.\n",
            "Touchdown Falcons\n",
            "\n",
            "index:1489\n",
            "(14:18) T.Allgeier left end for 3 yards, TOUCHDOWN\n",
            "The Replay Official reviewed the runner was inbounds ruling, and the play was Upheld\n",
            "The ruling on the field stands.\n",
            "Touchdown Falcons\n",
            "\n",
            "index:1501\n",
            "(4:52) T.Allgeier left tackle for 3 yards, TOUCHDOWN.\n",
            "Touchdown Falcons\n",
            "\n",
            "index:1539\n",
            "(5:13) (No Huddle, Shotgun) B.Young pass short right to H.Hurst for 4 yards, TOUCHDOWN.\n",
            "Touchdown Panthers\n",
            "\n",
            "index:1633\n",
            "(1:14) (Shotgun) B.Mayfield pass deep middle to M.Evans for 28 yards, TOUCHDOWN.\n",
            "Touchdown Buccaneers\n",
            "\n",
            "index:1652\n",
            "(6:06) (Shotgun) B.Mayfield pass short middle to T.Palmer for 7 yards, TOUCHDOWN.\n",
            "Touchdown Buccaneers\n",
            "\n",
            "index:1709\n",
            "(11:21) (No Huddle, Shotgun) K.Cousins pass deep middle to J.Addison for 39 yards, TOUCHDOWN\n",
            "Penalty on TB-J.Dean, Illegal Contact, declined.\n",
            "Touchdown Vikings\n",
            "\n",
            "index:1749\n",
            "(13:43) (Shotgun) K.Cousins pass short right to A.Mattison for 4 yards, TOUCHDOWN.\n",
            "Touchdown Vikings\n",
            "\n",
            "index:1773\n",
            "(4:42) A.Ekeler right tackle for 1 yard, TOUCHDOWN.\n",
            "Touchdown Chargers\n",
            "\n",
            "index:1787\n",
            "(9:11) J.Herbert pass short middle to D.Parham for 1 yard, TOUCHDOWN\n",
            "Penalty on MIA-K.Kohou, Defensive Offside, declined.\n",
            "Touchdown Chargers\n",
            "\n",
            "index:1818\n",
            "(9:20) J.Herbert up the middle for 1 yard, TOUCHDOWN.\n",
            "Touchdown Chargers\n",
            "\n",
            "index:1834\n",
            "(14:03) (No Huddle, Shotgun) J.Kelley up the middle for 2 yards, TOUCHDOWN.\n",
            "Touchdown Chargers\n",
            "\n",
            "index:1874\n",
            "(1:19) (No Huddle) R.Mostert left guard for 2 yards, TOUCHDOWN.\n",
            "Touchdown Dolphins\n",
            "\n",
            "index:1901\n",
            "(1:47) T.Tagovailoa pass short middle to R.Cracraft for 1 yard, TOUCHDOWN.\n",
            "Touchdown Dolphins\n",
            "\n",
            "index:1917\n",
            "(2:18) (Shotgun) T.Tagovailoa pass deep right to T.Hill for 35 yards, TOUCHDOWN.\n",
            "Touchdown Dolphins\n",
            "\n",
            "index:1937\n",
            "(1:48) (Shotgun) T.Tagovailoa pass short right to T.Hill for 4 yards, TOUCHDOWN.\n",
            "Touchdown Dolphins\n",
            "\n",
            "index:1965\n",
            "(4:39) (Shotgun) M.Jones pass short left to H.Henry for 9 yards, TOUCHDOWN.\n",
            "Touchdown Patriots\n",
            "\n",
            "index:1973\n",
            "(:30) (Shotgun) M.Jones pass deep middle to K.Bourne for 19 yards, TOUCHDOWN.\n",
            "Touchdown Patriots\n",
            "\n",
            "index:2012\n",
            "(3:43) (No Huddle, Shotgun) M.Jones pass short right to K.Bourne for 11 yards, TOUCHDOWN.\n",
            "Touchdown Patriots\n",
            "\n",
            "index:2052\n",
            "(5:12) (Shotgun) M.Jones pass short right intended for K.Bourne INTERCEPTED by D.Slay at PHI 30\n",
            "D.Slay for 70 yards, TOUCHDOWN.\n",
            "Touchdown Eagles\n",
            "\n",
            "index:2057\n",
            "(2:47) (Shotgun) J.Hurts pass short right to D.Smith for 5 yards, TOUCHDOWN.\n",
            "Touchdown Eagles\n",
            "\n",
            "index:2133\n",
            "(:42) (No Huddle) K.Williams left guard for 1 yard, TOUCHDOWN.\n",
            "Touchdown Rams\n",
            "\n",
            "index:2166\n",
            "(9:01) K.Williams left guard for 7 yards, TOUCHDOWN.\n",
            "Touchdown Rams\n",
            "\n",
            "index:2191\n",
            "(9:49) C.Akers left end for 1 yard, TOUCHDOWN.\n",
            "Touchdown Rams\n",
            "\n",
            "index:2240\n",
            "(9:21) (Shotgun) G.Smith pass short left to D.Metcalf for 10 yards, TOUCHDOWN.\n",
            "Touchdown Seahawks\n",
            "\n",
            "index:2285\n",
            "(9:34) B.Purdy pass short middle to B.Aiyuk for 8 yards, TOUCHDOWN.\n",
            "Touchdown 49ers\n",
            "\n",
            "index:2304\n",
            "(13:36) (Shotgun) B.Purdy pass deep right to B.Aiyuk for 19 yards, TOUCHDOWN.\n",
            "Touchdown 49ers\n",
            "\n",
            "index:2331\n",
            "(14:15) C.McCaffrey left tackle for 65 yards, TOUCHDOWN.\n",
            "Touchdown 49ers\n",
            "\n",
            "index:2398\n",
            "(:13) (Shotgun) K.Pickett pass short left to P.Freiermuth for 3 yards, TOUCHDOWN.\n",
            "Touchdown Steelers\n",
            "\n",
            "index:2475\n",
            "(1:02) (Shotgun) S.Howell sacked at WAS 12 for -14 yards (D.Gardeck)\n",
            "FUMBLES (D.Gardeck) [D.Gardeck], RECOVERED by ARI-C.Thomas at WAS 2\n",
            "C.Thomas for 2 yards, TOUCHDOWN.\n",
            "Touchdown Cardinals\n",
            "\n",
            "index:2535\n",
            "(4:22) (Shotgun) S.Howell pass short left to B.Robinson for 7 yards, TOUCHDOWN.\n",
            "Touchdown Commanders\n",
            "\n",
            "index:2585\n",
            "(11:54) (Shotgun) S.Howell scrambles left end for 6 yards, TOUCHDOWN.\n",
            "Touchdown Commanders\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PIPELINE\n",
        "  - ORDER\n",
        "    1. Team Dictionary\n",
        "      - Used to map team names with thier acronyms\n",
        "    2. Regular expressions\n",
        "      - Used to find common patterns within raw data\n",
        "    3. Cleaning methods\n",
        "      - Unique cleaning methods for each play type\n",
        "    4. Main pipeline method\n",
        "      - Control flow of cleaning methods\n",
        "\n"
      ],
      "metadata": {
        "id": "AkZ2lDw3yF4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. TEAM DICTIONARY"
      ],
      "metadata": {
        "id": "ZtbzjEyWlB8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dict_teams = {\n",
        "    'Cardinals': 'ARI', 'Falcons': 'ATL', 'Ravens': 'BAL', 'Bills': 'BUF', 'Panthers': 'CAR', 'Bears': 'CHI',\n",
        "    'Bengals': 'CIN', 'Browns': 'CLE', 'Cowboys': 'DAL', 'Broncos': 'DEN', 'Lions': 'DET', 'Packers': 'GB',\n",
        "    'Texans': 'HOU', 'Colts': 'IND', 'Jaguars': 'JAX', 'Chiefs': 'KC', 'Raiders': 'LV', 'Chargers': 'LAC',\n",
        "    'Rams': 'LAR', 'Dolphins': 'MIA', 'Vikings': 'MIN', 'Patriots': 'NE', 'Saints': 'NO', 'Giants': 'NYG',\n",
        "    'Jets': 'NYJ', 'Eagles': 'PHI', 'Steelers': 'PIT', '49ers': 'SF', 'Seahawks': 'SEA', 'Buccaneers': 'TB',\n",
        "    'Titans': 'TEN', 'Commanders': 'WAS'\n",
        "}"
      ],
      "metadata": {
        "id": "f1J4J0JllNCP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_teams_2 = {\n",
        "    'ARI': 'Cardinals', 'ATL': 'Falcons', 'BAL': 'Ravens', 'BUF': 'Bills', 'CAR': 'Panthers', 'CHI': 'Bears',\n",
        "    'CIN': 'Bengals', 'CLE': 'Browns', 'DAL': 'Cowboys', 'DEN': 'Broncos', 'DET': 'Lions', 'GB': 'Packers',\n",
        "    'HOU': 'Texans', 'IND': 'Colts', 'JAX': 'Jaguars', 'KC': 'Chiefs', 'LV': 'Raiders', 'LAC': 'Chargers',\n",
        "    'LAR': 'Rams', 'MIA': 'Dolphins', 'MIN': 'Vikings', 'NE': 'Patriots', 'NO': 'Saints', 'NYG': 'Giants',\n",
        "    'NYJ': 'Jets', 'PHI': 'Eagles', 'PIT': 'Steelers', 'SF': '49ers', 'SEA': 'Seahawks', 'TB': 'Buccaneers',\n",
        "    'TEN': 'Titans', 'WAS': 'Commanders'\n",
        "}"
      ],
      "metadata": {
        "id": "51RyMwQllJ0f"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. REGULAR EXPRESSIONS"
      ],
      "metadata": {
        "id": "XksC21RH41fY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "####################################################\n",
        "# REGULAR EXPRESSIONS USED TO LOCATE SPECIFIC DATA #\n",
        "####################################################\n",
        "\n",
        "# Will eventually have to combine some regular expressions into one\n",
        "# - For example, punt returns <-> kick returns <-> interceptions <-> fumble recoveries (?)\n",
        "\n",
        "###########\n",
        "# GENERAL #\n",
        "###########\n",
        "\n",
        "# Players name (Grabs every variation come across so far)\n",
        "name_pattern = \"(?:[A-Za-z]+-)*[A-Za-z]+\\.[A-Za-z]+(?:-[A-Za-z]+)*\"\n",
        "\n",
        "# Player team (Grabs team of player)\n",
        "team_name_pattern = \"([A-Za-z]+)-(?:[A-Za-z]+-)*[A-Za-z]+\\.[A-Za-z]+(?:-[A-Za-z]+)*\"\n",
        "\n",
        "################\n",
        "# PLAY DETAILS #\n",
        "################\n",
        "\n",
        "# Play start time\n",
        "time_on_clock_pattern = r'\\((\\d*:\\d+)\\)'\n",
        "\n",
        "# Offense play formation\n",
        "formation = r'\\(([A-Za-z]+ ?[A-Za-z]*,? ?[A-Za-z]*)\\)'\n",
        "\n",
        "# Yards gained on play\n",
        "yardage_gained = r'for (-?[0-9]+) yards?'\n",
        "\n",
        "# Positioning of the start of the play\n",
        "play_start_pattern = \"(?:1st|2nd|3rd|4th) & [0-9]+ at ([A-Z]+) ([0-9]+)\"\n",
        "\n",
        "# Positioning at the end of the play\n",
        "# to GB 35 for 11 yards\n",
        "# (2:31) (Shotgun) E.Ezukanma left end pushed ob at LAC 27 for 7 yards (A.Gilman).\n",
        "play_end_pattern = \"(?:to|at) (?:([A-Z]+) )?([0-9]+) for (-?[0-9]+) yards?\"\n",
        "\n",
        "# Yardage from penalty\n",
        "# , 15 yards, enforced at NYG 38.\n",
        "penalty_yardage_pattern = \", ([0-9]+) yards?, enforced at (?:([A-Z]+) )?([0-9]+)\"\n",
        "\n",
        "###########\n",
        "# OFFENSE #\n",
        "###########\n",
        "\n",
        "# Passer (Player passing, Player spiking, Player who got sacked)\n",
        "passer_name_pattern = f\"({name_pattern}) (?:pass|spiked|sacked)\"\n",
        "\n",
        "# Rushing play (Player running ball)\n",
        "rusher_pattern = f\"({name_pattern})(?: scrambles)? (?:left|right|up|kneels).?\"\n",
        "\n",
        "# Pass play (Returns intended receiver and the direction of the pass)\n",
        "receiver_pattern = f\"(short|deep) (left|right|middle) (?:to|intended for) ({name_pattern})\"\n",
        "\n",
        "# 2 Point Conversion (Pass attempt)\n",
        "tp_conversion_pass_pattern = f\"({name_pattern}) pass to ({name_pattern})\"\n",
        "\n",
        "# 2 Point Conversion (Rush attempt)\n",
        "tp_conversion_rush_pattern = f\"({name_pattern}) rushes (?:left|right|up)\"\n",
        "\n",
        "# Handoff\n",
        "handoff_pattern = f\"Handoff to ({name_pattern}) to(?: [A-Z]+)? [0-9]+ for -?[0-9]+ yards?\"\n",
        "\n",
        "###########\n",
        "# DEFENSE #\n",
        "###########\n",
        "\n",
        "# Tackles (solo, assist, shared) <-- the goal. Right now all I have is tackle1 and tackle2\n",
        "\n",
        "# Main defender on play (Used to grab tackler1 and used to grab players that sacked the passer)\n",
        "defense_tackler_1_name_pattern = f\"\\(({name_pattern})\"\n",
        "\n",
        "# Second defender on play (Used to grab tackler2)\n",
        "defense_tackler_2_name_pattern = f\" ({name_pattern})\\)\" # Will have a \")\" at the end of the name\n",
        "\n",
        "\n",
        "\n",
        "solo_tackle_pattern = f\"\\(({name_pattern})\\)\"\n",
        "\n",
        "shared_tackle_pattern = f\"\\(({name_pattern}), ({name_pattern})\\)\"\n",
        "\n",
        "assisted_tackle_pattern = f\"\\(({name_pattern}); ({name_pattern})\\)\"\n",
        "\n",
        "\n",
        "\n",
        "# Pressure (Who applied pressure to passer)\n",
        "# - I think it might be possible for multiple defenders to apply pressure to the passer.\n",
        "defense_pressure_name_pattern = f\"\\[({name_pattern})\\]\"\n",
        "\n",
        "# Interception (Player who intercepted pass)\n",
        "interception_name_pattern = f\"INTERCEPTED by ({name_pattern})\"\n",
        "\n",
        "# Quarterback Fumbles (Quarterback fumble solo, Quarterback fumble solo -> who recovers, Quarterback <-> Center discrepancy)\n",
        "\n",
        "# How far passer went before fumbling on his own\n",
        "qb_fumble_pattern = f\" ({name_pattern}) to(?: [A-Z]+) [0-9]+ for -?[0-9]+ yards$\" # Passer fumbles are always the initial action of the play\n",
        "\n",
        "# Action directly after a quarterback only fumble\n",
        "qb_fumble_description_pattern = f\"^FUMBLES, \"\n",
        "\n",
        "# Fumble missnap (Will either be the quarterback or center.)\n",
        "aborted_fumble_pattern = f\"({name_pattern}) FUMBLES\"\n",
        "\n",
        "# Forced fumbles (Player who forced the fumble)\n",
        "forced_fumble_pattern = f\"FUMBLES \\(({name_pattern})\\)\"\n",
        "\n",
        "# Sack (Who is credited with a sack, who split sack, how many yards was the sack)\n",
        "\n",
        "# Fumble from sack (Player who forced the fumble on a sack)\n",
        "sacked_forced_fumble_sentence = f\"FUMBLES \\({name_pattern}\\) \\[({name_pattern})\\]\"\n",
        "\n",
        "# Split sack (Players who equally received credit for sack)\n",
        "split_sack_pattern = f\"sack split by ({name_pattern}) and ({name_pattern})\"\n",
        "\n",
        "# Yardage of sack (starting from line of scrimmage)\n",
        "yardage_from_sack = r'sacked(?: ob)? at(?: [A-Z]+)? [0-9]+ for (-?[0-9]+) yards'\n",
        "\n",
        "# Defense takeaway (takeaway for yardage)\n",
        "defensive_takeaway_run_pattern = f\"^({name_pattern}) (?:pushed ob at|ran ob at|to)(?: [A-Z]+) -?[0-9]+ for \" # yardage after fumble recovery & yardage after interception\n",
        "\n",
        "# Defense takeaway (takeaway for touchdown)\n",
        "touchdown_after_takeaway_pattern = f\"({name_pattern}) for [0-9]+ yards, TOUCHDOWN\" # touchdown after a fumble recovery or interception\n",
        "\n",
        "#################\n",
        "# SPECIAL TEAMS #\n",
        "#################\n",
        "\n",
        "# Punting play (Who was the punter, How many yards the ball went, Who was the Longsnapper)\n",
        "punting_pattern = f\"({name_pattern}) punts (-?[0-9]+) yards? to(?: [A-Z]+ -?[0-9]+| -?[0-9]+| end zone), Center-({name_pattern})\"\n",
        "\n",
        "# Punt return (Who was returning the punt, How many yards did they go, The player(s) that tackled the returner)\n",
        "# punt_return_pattern = f\"({name_pattern}) (?:pushed ob at|ran ob at|to)(?: [A-Z]+)? [0-9]+ for (-?[0-9]+) yards? \\(({name_pattern})(?:(?:,|;) ({name_pattern}))?\\)\" # yardage after punt\n",
        "punt_return_pattern = f\"({name_pattern}) (?:pushed ob at|ran ob at|to)(?: [A-Z]+)? [0-9]+ for\"\n",
        "\n",
        "# J.Reed (didn't try to advance) to CHI 44 for no gain.\n",
        "kick_return_pattern = f\"({name_pattern})(?: \\(didn't try to advance\\))? (?:pushed ob at|ran ob at|to)(?: [A-Z]+)? [0-9]+ for (no gain|(-?[0-9]+) yards? \\(({name_pattern})(?:(?:,|;) ({name_pattern}))?\\))\" # yardage after kickoff\n",
        "\n",
        "# Punt return resulting in fair catch\n",
        "punt_fair_catch_pattern = f\", fair catch by ({name_pattern})\"\n",
        "\n",
        "# Punt or kickoff downed by\n",
        "kick_downed_by_pattern = f\", downed by ({name_pattern})\"\n",
        "\n",
        "# Kickoff play (Who was the kicker, How many yards the ball was kicked )\n",
        "kickoff_pattern = f\"({name_pattern}) kicks(?: onside)? (-?[0-9]+) yards from\"\n",
        "\n",
        "# Field goal (Good)\n",
        "field_goal_good_pattern = f\"({name_pattern}) (-?[0-9]+) yard field goal is GOOD, Center-({name_pattern}), Holder-({name_pattern}).\"\n",
        "\n",
        "# Field goal (no good)\n",
        "field_goal_no_good_pattern = f\"({name_pattern}) (-?[0-9]+) yard field goal is No Good, ([A-Za-z]+(?: [A-Za-z]+)*), Center-({name_pattern}), Holder-({name_pattern}).\"\n",
        "\n",
        "# Field goal (blocked)\n",
        "field_goal_blocked_pattern = f\"({name_pattern}) (-?[0-9]+) yard field goal is BLOCKED \\(({name_pattern})\\), Center-({name_pattern}), Holder-({name_pattern}), RECOVERED by ({name_pattern})\"\n",
        "\n",
        "# Extra point (good)\n",
        "extra_point_good_pattern = f\"({name_pattern}) extra point is GOOD, Center-({name_pattern}), Holder-({name_pattern}).\"\n",
        "\n",
        "# Extra point (no good)\n",
        "extra_point_no_good_pattern = f\"({name_pattern}) extra point is No Good, ([A-Za-z]+(?: [A-Za-z]+)*), Center-({name_pattern}), Holder-({name_pattern}).\"\n",
        "\n",
        "##############\n",
        "#  INJURIES  #\n",
        "##############\n",
        "\n",
        "# Injuries (Returns the player(s) who go injuried during play)\n",
        "# injury = f\"[A-Z]+-({name_pattern}) was injured during the play\"\n",
        "injury_pattern = f\"[A-Z]+-({name_pattern}) was injured during the play\""
      ],
      "metadata": {
        "id": "7GjwQpriPJcS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PREPROCESSING DATA"
      ],
      "metadata": {
        "id": "DFaoNUpK6sjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Value mapping the \"Quarter\" feature\n",
        "week1_2023_plays['Quarter'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emY80yEPMQHs",
        "outputId": "836549a7-ac89-4483-e420-58bcec345a18"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['1ST QUARTER', '2ND QUARTER', '3RD QUARTER', '4TH QUARTER',\n",
              "       'OVERTIME'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "week1_2023_plays_modified = week1_2023_plays.copy()\n",
        "\n",
        "dict_replace_quarter = {'1ST QUARTER': 1, '2ND QUARTER': 2, '3RD QUARTER': 3, '4TH QUARTER': 4, 'OVERTIME': 5}\n",
        "\n",
        "week1_2023_plays_modified['Quarter'] = week1_2023_plays_modified['Quarter'].map(dict_replace_quarter)"
      ],
      "metadata": {
        "id": "uQbvMHKhNags"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. CLEANING METHODS"
      ],
      "metadata": {
        "id": "8LYvErx95uaA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###HELPER CLEANING METHODS"
      ],
      "metadata": {
        "id": "X-Tm3s7Nskgl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### helper method for fumbles"
      ],
      "metadata": {
        "id": "Xn4gd8SjZpOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PURPOSE:\n",
        "# - Universal helper method that extracts fumbled data from every playtype.\n",
        "\n",
        "# BASIC PLAN:\n",
        "# 1. Accept a single row of a play that has been fumbled from the main dataframe of plays.\n",
        "# 2. Replace that single row with a dataframe containing all extracted data.\n",
        "#    - These replacement dataframes are not limited to a single row but can be many, depending on the play.\n",
        "\n",
        "# BASIC DESIGN STEP BY STEP:\n",
        "# 1. Split play description into significant actions and put into a list\n",
        "#    EXAMPLES:\n",
        "#    - intended play\n",
        "#    - fumble recovery for yardage\n",
        "# 2. Clean significant actions as their own rows\n",
        "#    EXAMPLE METHODS USED TO CLEAN:\n",
        "#    - main cleaning method (method used to clean a playtype that is using this helper method)\n",
        "#    - run playtype cleaning method (Will be used to clean all fumble recoveries for yardage)\n",
        "# 3. Create and return replacement dataframe containing all cleaned significant actions (or rows)\n",
        "\n",
        "# INPUT PARAMETERS:\n",
        "# df_plays                  - dataframe - dataframe of plays\n",
        "# play                      -  String   - 'PlayDescription' of the current play that is being cleaned\n",
        "# play_index                -  Integer  - index of play (Almost always from main dataframe of plays)\n",
        "# main_action_patterns      -    list   - A list of regular expressions that are meant to pinpoint primary\n",
        "#                                         actions within a play that will be used to extract these actions\n",
        "#                                         to create a row within the replacement dataframe\n",
        "# main_cleaning_method      - function  - A callback function (the function using this helper method) which\n",
        "#                                         is used to clean intended play actions\n",
        "\n",
        "# RETURN:\n",
        "# df_multi_row_play - dataframe - dataframe of organized and cleaned actions stemming from a single unclean fumbled play\n",
        "\n",
        "# NOTE: I need to comment effectively, grabbing all the nuances of what is being grabbed\n",
        "#       for each playtype. All playtypes are different and need to be described.\n",
        "\n",
        "# CONCERNS:\n",
        "# 1. Nuance on sacked plays\n",
        "#    - Formatting of defender who caused sack is different from a solo and an assisted\n",
        "# 2. Who is at fault for aborted plays\n",
        "#    - Formatting on aborted plays is different if the fault lands on the center or passer\n",
        "# 3. May have to add the parameter \"secondary_action_patterns\"\n",
        "#    - I just ran into the issue of a kickoff return fumble.\n",
        "#      - In this case there is 1. the kickoff 2. the kickoff return 3. the fumble from kickoff return.\n",
        "\n",
        "def extract_fumble_data(df_plays, play, play_index, main_action_patterns, main_cleaning_method):\n",
        "\n",
        "  original_play_copy = df_plays.loc[play_index]\n",
        "\n",
        "  # Breaking play description into a list of sentences\n",
        "  play_elements = play.split(\". \")\n",
        "\n",
        "  #################\n",
        "  # KEY VARIABLES #\n",
        "  #################\n",
        "\n",
        "  # 'play_split' info:\n",
        "  # - Designed to be a 2D list (list of lists)\n",
        "  # - All elements within this list together will represent a single play.\n",
        "  # - Each element within the list will become a separate row that will replace/add to the original dataframe of plays.\n",
        "  #   - Each element represents a distict action within the single play and will have all data required for that new row.\n",
        "  #   ROW CONTENTS:\n",
        "  #   1. [ ( The intended play ) + ( Extra data ) , ( Who caused the fumble ) ]   <-  This row will have extra info such as (injuries / penalties / eligibility / etc...)\n",
        "  #                                                                                   - \"The intended play\" includes 'Aborted' plays\n",
        "  # ~ 2. [            ( The fumble recovery )     , ( Who caused the fumble ) ]   <-  This can happen repeatedly or not at all\n",
        "  # ~ 3. [ (The fumble recovery for a touchdown) ]                                <-  This can only happen once for a single play or not at all\n",
        "  play_split = []\n",
        "\n",
        "  # 'extra_data' info:\n",
        "  # - Will be a single string containing all additional data from the play such as (injuries / penalties / eligibility / etc...)\n",
        "  # - Will be put into a single row dataframe and cleaned\n",
        "  #   - Once extra data has been cleaned, the single row (now clean) dataframe will serve as a shell for\n",
        "  #     the first new row that will replace the old play within the main dataframe.\n",
        "  #     - This first new row will have the initial action of the play as well as all additional information from the play\n",
        "  extra_data = \"\"\n",
        "\n",
        "  # - Iterate through each element within play_elements\n",
        "  # - NOTE: We are iterating through actions of the play cronologically\n",
        "  for string in play_elements:\n",
        "\n",
        "    ######################################\n",
        "    # ORGANIZING KEY ACTIONS WITHIN PLAY #\n",
        "    ######################################\n",
        "\n",
        "    # ACTIONS WITHIN PLAY THAT DESERVE THEIR OWN ROW:\n",
        "    # These situations will have their own list element within \"play_split\" (meaning their own row within the new cleaned replacement dataframe)\n",
        "    # 1. intended play (initial action might be a better name for plays such as ones that have been aborted)\n",
        "    #    RUN PLAYS:\n",
        "    #     - Fumbles after inteded run play\n",
        "    #     - Aborted fumbles\n",
        "    #     - qb only fumbles\n",
        "    #    SACKED PLAYS:\n",
        "    #     - fumbles after sack\n",
        "    #    PASSING PLAYS:\n",
        "    #     - Fumbles after intended pass play\n",
        "    #     - qb only fumbles\n",
        "    #    KICKOFF PLAYS:\n",
        "    #     - Fumbles happen during kickoff return\n",
        "    # 2. runs after fumble recoveries (emphasis on the plural)\n",
        "    # 3. touchdown after fumble recovery (can only happen once) (looks unique for each playtype) <- this might not be true.\n",
        "    #    ! ! ! ATTENTION ! ! !\n",
        "    #    - I have a small sample size for this.\n",
        "    #    - This is one thing that I need to double check correctness on later in the future when having a larger sample size.\n",
        "    #    RUNS PLAYS:\n",
        "    #    - Are fumble recovery touchdown from run plays accounted for?\n",
        "    #    SACKED PLAYS\n",
        "    #    - touchdown after a sacked play\n",
        "    #    PASSING PLAYS:\n",
        "    #    - Are fumble recovery touchdown from passing plays accounted for?\n",
        "    #\n",
        "    #    - Are all fumble recoveries the same? wouldn't they all be rushing playtypes?\n",
        "    # 4. handoffs\n",
        "    for play_pattern in main_action_patterns:\n",
        "      if re.search(play_pattern, string) != None:\n",
        "        play_split.append([string])\n",
        "        break\n",
        "    if re.search(play_pattern, string) != None:\n",
        "      continue\n",
        "\n",
        "    # ADD ON SECTION (Actions that will add to elements that will obtain their own row)\n",
        "    # - Appends data to elements within 'play_split'\n",
        "    #   - Every element within play_split is a list, this section will add to those individual lists\n",
        "    #     - Specifically it will append to the last element within 'play_split' and the reason for that\n",
        "    #       is because as we are iterating through sentences cronologically, the appending element\n",
        "    #       will always follow directly after the element that needs it\n",
        "    # These situations will add to the last element within 'play_split' (For all playtypes)\n",
        "    # 1. forced fumble description (happens after regular plays & sometimes after fumble recoveries)\n",
        "    # 2. fumble description describing a qb only fumble (happens after a qb only fumble)\n",
        "    for play_pattern in [forced_fumble_pattern, qb_fumble_description_pattern]:\n",
        "      if re.search(play_pattern, string):\n",
        "        index_last_element = len(play_split) - 1\n",
        "        play_split[index_last_element] = [play_split[index_last_element][0], string]\n",
        "        break\n",
        "    if re.search(play_pattern, string) != None:\n",
        "      continue\n",
        "\n",
        "    # When a sentence does not fit within the top 2 sections ( 1. adding an element to the list || 2. appending to an element in the list )\n",
        "    # - Glue the sentence into 'extra_data' to be cleaned separately.\n",
        "    extra_data = extra_data + string + \". \"\n",
        "\n",
        "  ################################\n",
        "  # CLEANING ACTIONS WITHIN PLAY #\n",
        "  ################################\n",
        "\n",
        "  # GRABBING: Initial action of play (e.g. Intended play / aborted fumble / qb only fumble / etc...)\n",
        "  intended_play_description = play_split.pop(0)\n",
        "\n",
        "  # Creating a single row dataframe of the original play\n",
        "  unclean_original_play_copy = pd.DataFrame([original_play_copy.copy()], columns=df_plays.columns)\n",
        "\n",
        "  # CREATING SHELL FOR: Initial action of play\n",
        "  # - shell is only necessary with plays that have extra data (injuries / penalties / eligibility / etc...)\n",
        "  # - extra data will only be available within the first row of the replacement dataframe\n",
        "  if extra_data:\n",
        "    unclean_original_play_copy['PlayDescription'] = extra_data\n",
        "    unclean_original_play_copy = main_cleaning_method(unclean_original_play_copy)\n",
        "\n",
        "  # CLEANING: Initial action of play\n",
        "  # No matter what the initial action is, the description will always be the first element of the first element within 'play_split'\n",
        "  unclean_original_play_copy['PlayDescription'] = intended_play_description[0]\n",
        "\n",
        "  # May have to adjust in the future.\n",
        "  # - ON SACKED PLAYS, there is nuance on the formatting of a player who caused a sack and a forced fumble.\n",
        "  #   - Sometimes it'll look something like this \"FUMBLES (B.Burns) [B.Burns]\" <- [B.Burns] is credited with the forced fumble\n",
        "  #   - less often it'll look like \"FUMBLES (B.Burns)\" <- B.Burns is credited with the forced fumble.\n",
        "  # - ON ABORTED PLAYS, there is nuace on the formatting of a player who caused the play to be aborted.\n",
        "  #   - the word \"Aborted\" will either be in parenthesis or without, this signals whether the center was at fault or the passer.\n",
        "  #     - Need to figure out how to record this data.\n",
        "  # - ON KICKOFF PLAYS\n",
        "  #   - Because there is the kickoff, then the kickoff return, then the fumble on the kickoff return,\n",
        "  #     the intended play will not have the fumble detail but still needs to be cleaned.\n",
        "\n",
        "  # intended play / qb only fumble\n",
        "  if len(intended_play_description) > 1:\n",
        "    unclean_original_play_copy['FumbleDetails'] = intended_play_description[1]\n",
        "    forced_fumble = re.findall(forced_fumble_pattern, intended_play_description[1])\n",
        "    if len(forced_fumble) > 0:\n",
        "      unclean_original_play_copy['ForcedFumbleBy'] = forced_fumble[0]\n",
        "    cleaned_original_play_copy = main_cleaning_method(unclean_original_play_copy)\n",
        "\n",
        "  # kickoff (fumble occurs after kickoff return)\n",
        "  kickoff = re.findall(kickoff_pattern, intended_play_description[0])\n",
        "  if len(kickoff) > 0:\n",
        "    cleaned_original_play_copy = main_cleaning_method(unclean_original_play_copy)\n",
        "\n",
        "  # blocked field goal recovery (fumble would occur during the recovery run) <-------\n",
        "  # - I think here I will need to:\n",
        "  #   1. separate 'PlayDescription' by \", \"\n",
        "  #   2. Remove the section that states who recovered the blocked field goal attempt\n",
        "  #      - Hold to add back into 'PlayDescription' after rest has been cleaned.\n",
        "  #      - This is important because if I were to send it to be cleaned along with\n",
        "  #        the rest of the string, it would cause an infinite loop.\n",
        "  #   3. clean the rest of the string using the main cleaning method\n",
        "  field_goal_blocked = re.findall(field_goal_blocked_pattern, intended_play_description[0])\n",
        "  if len(field_goal_blocked) > 0:\n",
        "    field_goal_blocked_elements = intended_play_description[0].split(\", \")\n",
        "    for i in field_goal_blocked_elements:\n",
        "      if i.lower().find('recovered') != -1:\n",
        "        field_goal_blocked_elements.pop(field_goal_blocked_elements.index(i))\n",
        "        print(\", \".join(field_goal_blocked_elements))\n",
        "        unclean_original_play_copy['PlayDescription'] = \", \".join(field_goal_blocked_elements)\n",
        "        cleaned_original_play_copy = main_cleaning_method(unclean_original_play_copy)\n",
        "        cleaned_original_play_copy['PlayDescription'] = f\"{unclean_original_play_copy['PlayDescription'], {i}}\"\n",
        "        print(cleaned_original_play_copy['Yardage'].iloc[0])\n",
        "        break\n",
        "\n",
        "  # Aborted fumble (Dig more into this. I dont think this captures only ABORTED fumbles)\n",
        "  # I think I have to make this more specific than dumping everything else into here.\n",
        "  else:\n",
        "    unclean_original_play_copy['FumbleDetails'] = intended_play_description[0]\n",
        "    cleaned_original_play_copy = unclean_original_play_copy\n",
        "\n",
        "  # FUMBLE RECOVERIES FOR YARDAGE & FUMBLE RECOVERIES FOR TOUCHDOWNS\n",
        "\n",
        "  # Created list for the possibility of having multiple fumbles and recoveries in a single play\n",
        "  list_recovery_runs = []\n",
        "\n",
        "  for play in play_split:\n",
        "\n",
        "    recovery_row = pd.DataFrame([original_play_copy.copy()], columns=df_plays.columns)\n",
        "\n",
        "    # Recovery after fumble was fumbled\n",
        "    if len(play) > 1:\n",
        "      recovery_row['FumbleDetails'] = play[1]\n",
        "      forced_fumble = re.findall(forced_fumble_pattern, play[1])\n",
        "      if len(forced_fumble) > 0:\n",
        "        recovery_row['ForcedFumbleBy'] = forced_fumble[0]\n",
        "\n",
        "    recovery_row['PlayDescription'] = play[0]\n",
        "    # Pass after fumble recovery\n",
        "    pass_play = re.findall(passer_name_pattern, play[0])\n",
        "    if len(pass_play) > 0:\n",
        "      recovery_row['PlayOutcome'] = 'Pass'\n",
        "      cleaned_recovery_row = clean_pass_plays(recovery_row)\n",
        "    # Everything else can be labeled as a run play\n",
        "    else:\n",
        "      recovery_row['PlayOutcome'] = 'Run' # <-- Possibly change this in the future (could be something like 'fumble recovery run?' unless it was the rb that recovered)\n",
        "      cleaned_recovery_row = clean_run_plays(recovery_row)\n",
        "\n",
        "    cleaned_recovery_row['PlayOutcome'] = original_play_copy['PlayOutcome'] # <- Maybe this isn't correct? when a play is split by multiple rows, this becomes tricky.\n",
        "    list_recovery_runs.append(cleaned_recovery_row)\n",
        "\n",
        "  ###################\n",
        "  # 3.NEW DATAFRAME #\n",
        "  ###################\n",
        "  # - Create the cleaned replacement row(s) for the original row.\n",
        "\n",
        "  if len(list_recovery_runs) > 0:\n",
        "    df_multi_row_play = pd.DataFrame(columns=df_plays.columns)\n",
        "    df_multi_row_play = pd.concat([cleaned_original_play_copy, *list_recovery_runs], ignore_index=True)\n",
        "  else:\n",
        "    df_multi_row_play = cleaned_original_play_copy\n",
        "\n",
        "  return df_multi_row_play"
      ],
      "metadata": {
        "id": "BTValJtzaAV9"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### helper method for penalties"
      ],
      "metadata": {
        "id": "XCAisXBXGNyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I want to see how many rushing yards are awarded to the rusher when a penalty is involved.\n",
        "\n",
        "# RUSHING PLAYS\n",
        "# - If the penalty was beyond the line of scrimmage and brought back, the rusher is\n",
        "#   awarded with any positive gained yards up to the spotting of the ball.\n",
        "# - If the penalty was behind or at the line of scrimmage, the play does does not count.\n",
        "\n",
        "# - I think here I should find:\n",
        "#   1. Where the play started\n",
        "#      - How am I supposed to know which direction the offensive is going based off of a play?\n",
        "#        - Do I look at if the gain was positive? And see from marker where they started to\n",
        "#          where they finished?\n",
        "#        - How do I know if going higher or going lower than the starting position is positive?\n",
        "#          - I need to figure out if the took place before, on or behind the line of scrimmage.\n",
        "#          - I feel like it might help if I use\n",
        "#            1. the starting position\n",
        "#            2. yardage gained from the play and what position on the field it ended up\n",
        "#               - Whether that yardage gained was positive or negative\n",
        "\n",
        "#              if (starting position yard < ending position yard) &\n",
        "#                 (play gain yardage > 0):\n",
        "#                 - Positive would be\n",
        "#                   - anything greater than position yard (team side)\n",
        "#                   - anything on opposing team side\n",
        "#              EXAMPLE:\n",
        "#              starting position = GB 24\n",
        "#              ending position = GB 35\n",
        "#              play gain yardage = 11\n",
        "#              - Positive would be:\n",
        "#                - 'GB' (>24)\n",
        "#                - 'Opposing team acronym' (49-1)\n",
        "\n",
        "#             There has to be an easier way to do this.\n",
        "#             - Maybe I can go based off 100 (the entire football field)\n",
        "#               - So I can figure out which direction is positive and add either 0 or 50 to the\n",
        "#                 yardage based off of the team acronym.\n",
        "#                 - I need to figure out which direction is positive from the\n",
        "#                   starting position.\n",
        "\n",
        "\n",
        "#   - Figure out which team area is the starting point.\n",
        "#     - Figure this out for 0 yard run too\n",
        "\n",
        "\n",
        "\n",
        "#   2. Where the penalty was enfored\n",
        "#   3. Where the ball is placed\n",
        "\n",
        "def accepted_penalty_play_on_offense(df_plays, play, index_of_play):\n",
        "\n",
        "  print(index_of_play)\n",
        "\n",
        "  print(df_plays['PlayOutcome'].loc[index_of_play])\n",
        "\n",
        "\n",
        "  # Ultimately, All I want is to figure out how much positive yards were gained if any\n",
        "  # on an accepted offensive penalty.\n",
        "\n",
        "  # position yardage (+) & play yardage (+):\n",
        "  # - the starting position team zone is the beginning (0-50) (home territory)\n",
        "  # position yardage (-) & play yardage (+):\n",
        "  # - the starting position team zone is the ending (50-100) (enemy territory)\n",
        "  # position yardage (+) & play yardage (-):\n",
        "  # - the starting position team zone is the ending (50-100) (enemy territory)\n",
        "  # position yardage (-) & play yardage (-):\n",
        "  # - the starting position team zone is the beginning (0-50) (home territory)\n",
        "\n",
        "  # Unique cases\n",
        "  # zones switch (home territory -> enemy territory) (e.g. KC 47 -> BUF 47)\n",
        "  # play yardage (+):\n",
        "  # - the starting position team zone is the beginning (0-50)\n",
        "  # play yardage (-):\n",
        "  # - the starting position team zone is the ending (50-100)\n",
        "  # penalty occured on the line of scrimmage\n",
        "  # - doesn't matter. yardage gained is 0\n",
        "\n",
        "  # What can I do with knowledge of which zone is 0-50 yards in a drive?\n",
        "  # - Ultimately I want to be able to find how much yards are awarded to offensive\n",
        "  #   players during a penalized play.\n",
        "  #   - I can take the ending point, subtract the starting, then subtract the penalty.\n",
        "  #     - If any yards are left over, then those yards are awarded to the rushing play (for run plays)\n",
        "\n",
        "  # What do I need to figure out?\n",
        "  # - Starting point (on 100 yard format)\n",
        "  # - ending point (on 100 yard format)\n",
        "  # - penalty enforcement (on 100 yard format)\n",
        "  # - offensive or defensive penalty\n",
        "  # - subtract penalty\n",
        "  # - If resulting number is less than starting point, yardage = 0\n",
        "  # - If resulting number is greater than starting point, yardage = result\n",
        "\n",
        "  # Play start\n",
        "  play_start = df_plays['PlayStart'].loc[index_of_play]\n",
        "  play_start_elements = re.findall(play_start_pattern, play_start)\n",
        "  if len(play_start_elements) > 0:\n",
        "    print(play_start_elements)\n",
        "\n",
        "  # Play end\n",
        "  play_end_elements = re.findall(play_end_pattern, play)\n",
        "  if len(play_end_elements) > 0:\n",
        "    print(play_end_elements)\n",
        "\n",
        "  # Penalty data\n",
        "  penalty_elements = re.findall(penalty_yardage_pattern, play)\n",
        "  print(penalty_elements)\n",
        "\n",
        "\n",
        "  # I cannot forget to take care of a 0 yard gain.\n",
        "  # What happens if a penalty is on the 50 with no team acronym?\n",
        "\n",
        "\n",
        "  # 0-100 yard format (example 'GB 30': 30 yards OR 80 yards)\n",
        "  starting_position = 0\n",
        "  ending_position = 0\n",
        "  penalty_enforcement_position = 0\n",
        "\n",
        "  # Starting of play and ending of play are in the same 50 yard zone\n",
        "  if play_start_elements[0][0] == play_end_elements[0][0]:\n",
        "    # position yardage (+)\n",
        "    if play_start_elements[0][1] < play_end_elements[0][1]:\n",
        "      # play yardage (+)\n",
        "      if int(play_end_elements[0][2]) > 0:\n",
        "        # print(f'{play_start_elements[0][0]} zone is (0-50)')\n",
        "        starting_position = int(play_start_elements[0][1])\n",
        "        ending_position = int(play_end_elements[0][1])\n",
        "        penalty_enforcement_position = int(penalty_elements[0][2])\n",
        "      # play yardage (-)\n",
        "      else:\n",
        "        print(f'{play_start_elements[0][0]} zone is (50-100)')\n",
        "        starting_position = 100 - int(play_start_elements[0][1])\n",
        "        ending_position = 100 - int(play_end_elements[0][1])\n",
        "        penalty_enforcement_position = 100 - int(penalty_elements[0][2])\n",
        "    # position yardage (-)\n",
        "    else:\n",
        "      # play yardage (+)\n",
        "      if int(play_end_elements[0][2]) > 0:\n",
        "        print(f'{play_start_elements[0][0]} zone is (50-100)')\n",
        "        starting_position = 100 - int(play_start_elements[0][1])\n",
        "        ending_position = 100 - int(play_end_elements[0][1])\n",
        "        penalty_enforcement_position = 100 - int(penalty_elements[0][2])\n",
        "      # play yardage (-)\n",
        "      else:\n",
        "        print(f'{play_start_elements[0][0]} zone is (0-50)')\n",
        "        starting_position = int(play_start_elements[0][1])\n",
        "        ending_position = int(play_end_elements[0][1])\n",
        "        penalty_enforcement_position = int(penalty_elements[0][2])\n",
        "  else:\n",
        "    # play yardage (+)\n",
        "    if int(play_end_elements[0][2]) > 0:\n",
        "      print(f'{play_start_elements[0][0]} zone is (0-50)')\n",
        "      zero_to_fifty_zone = play_start_elements[0][0]\n",
        "      starting_position = int(play_start_elements[0][1])\n",
        "      ending_position = 100 - int(play_end_elements[0][1])\n",
        "      if penalty_elements[0][1] == zero_to_fifty_zone:\n",
        "        penalty_enforcement_position = int(penalty_elements[0][2])\n",
        "      else:\n",
        "        penalty_enforcement_position = 100 - int(penalty_elements[0][2])\n",
        "    # play yardage (-)\n",
        "    else:\n",
        "      print(f'{play_start_elements[0][0]} zone is (50-100)')\n",
        "      fifty_to_hundred_zone = play_start_elements[0][0]\n",
        "      starting_position = 100 - int(play_start_elements[0][1])\n",
        "      ending_position = int(play_end_elements[0][1])\n",
        "      if penalty_elements[0][1] == fifty_to_hundred_zone:\n",
        "        penalty_enforcement_position = 100 - int(penalty_elements[0][2])\n",
        "      else:\n",
        "        penalty_enforcement_position = int(penalty_elements[0][2])\n",
        "\n",
        "  print(starting_position)\n",
        "  print(ending_position)\n",
        "  print(penalty_enforcement_position)\n",
        "\n",
        "\n",
        "  resulting_position = penalty_enforcement_position - int(penalty_elements[0][0])\n",
        "  print(resulting_position)\n",
        "\n",
        "\n",
        "  print(resulting_position - starting_position)\n",
        "\n",
        "  print(play)\n",
        "  print()"
      ],
      "metadata": {
        "id": "-vvSkaYgGRAo"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OFFENSE CLEANING METHODS"
      ],
      "metadata": {
        "id": "n_HCeydwrbwx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### PASS PLAYS"
      ],
      "metadata": {
        "id": "9L_L6vxtmnLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PURPOSE:\n",
        "# - Clean all passing type plays within a given dataframe.\n",
        "# INPUT PARAMETERS:\n",
        "# df_plays    - dataframe - NFL plays (can include play types other than passing)\n",
        "# index_start -  integer  - index where within the dataframe the method will start\n",
        "#                           cleaning in ascending order.\n",
        "# RETURN:\n",
        "# df_plays - dataframe - the same input df_plays but with all passing play types cleaned\n",
        "\n",
        "# NOTE:\n",
        "# - I want this to work with slices of the main dataframe as well.\n",
        "#   - Within slices, I think it is crucial to keep the original indexing from the main\n",
        "#     dataframe for ease to put back into the original dataframe.\n",
        "\n",
        "def clean_pass_plays(df_plays, index_start = None):\n",
        "\n",
        "  # Adjusting df_plays to start cleaning at a specified index (index_start)\n",
        "  if index_start != None:\n",
        "    df_plays_adjusted = df_plays.loc[index_start:]\n",
        "    # Locating all passing type plays within dataframe\n",
        "    df_pass_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('Pass')]\n",
        "  else:\n",
        "    # Locating all passing type plays within dataframe\n",
        "    df_pass_plays = df_plays[df_plays['PlayOutcome'].str.contains('Pass')]\n",
        "\n",
        "  for idx, play in df_pass_plays['PlayDescription'].items():\n",
        "\n",
        "    ################\n",
        "    # Play details #\n",
        "    ################\n",
        "\n",
        "    # Play Type\n",
        "    df_plays.loc[idx, 'PlayType'] = 'Pass'\n",
        "\n",
        "    # TimeOnTheClock\n",
        "    TimeOnTheClock = re.findall(time_on_clock_pattern, play)\n",
        "    if len(TimeOnTheClock) > 0:\n",
        "      df_plays.loc[idx, 'TimeOnTheClock'] = TimeOnTheClock[0]\n",
        "\n",
        "    ############\n",
        "    # REVERSES #\n",
        "    ############\n",
        "\n",
        "    # In 'PlayDescription' all information before the \"reversed\" sentence is not needed.\n",
        "    # - All information before is stored within 'ReverseDetails' and the remaining is cleaned.\n",
        "    if play.find('REVERSED') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      for i in play_elements:\n",
        "        if i.find(\"REVERSED\") != -1:\n",
        "          df_plays.at[idx, 'ReverseDetails'] = play_elements[:play_elements.index(i) + 1]\n",
        "          play = \". \".join(play_elements[play_elements.index(i) + 1:])\n",
        "          break\n",
        "\n",
        "    ############################\n",
        "    # REPORTING IN AS ELIGIBLE #\n",
        "    ############################\n",
        "\n",
        "    # I do not think this contains any useful data so I am going to exclude it.\n",
        "    if play.find('reported in as eligible') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      for i in play_elements:\n",
        "        if i.find('reported in as eligible') != -1:\n",
        "          play = \". \".join(play_elements[play_elements.index(i) + 1:])\n",
        "          break\n",
        "\n",
        "    ###########\n",
        "    # FUMBLES #\n",
        "    ###########\n",
        "\n",
        "    # Additional rows may be added after certain types of fumbled passing plays.\n",
        "    # - The idea here is that, in those situations, the helping method 'extract_fumble_data'\n",
        "    #   will return a small dataframe of the rows that the single play split into.\n",
        "    #   - When this small dataframe is returned, it will replace the original play\n",
        "    #     within the main dataframe of plays and then continue on cleaning the rest of the passing plays.\n",
        "\n",
        "    if play.find('FUMBLES') != -1:\n",
        "      main_action_patterns = [passer_name_pattern, qb_fumble_pattern, defensive_takeaway_run_pattern]\n",
        "      main_cleaning_method = clean_pass_plays\n",
        "      df_replacement_rows = extract_fumble_data(df_plays, play, idx,\n",
        "                                                main_action_patterns,\n",
        "                                                main_cleaning_method)\n",
        "\n",
        "      # \"df_plays.index.tolist().index(idx)\" needed for method usage with slices of original dataframe.\n",
        "      df_before = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before, df_replacement_rows, df_after], ignore_index=True)\n",
        "      index_of_last_added_row = idx + len(df_replacement_rows) - 1\n",
        "      if df_pass_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_pass_plays(df_plays, index_of_last_added_row + 1)\n",
        "\n",
        "    ###########\n",
        "    # OFFENSE #\n",
        "    ###########\n",
        "\n",
        "    # NOTE:\n",
        "    # - Incomplete passes will have 'PlayOutcome' as 'Pass Incomplete' as well\n",
        "    #   as yardage value being 0.0\n",
        "\n",
        "    # Yardage gained\n",
        "    yardage = re.findall(yardage_gained, play)\n",
        "    if len(yardage) > 0:\n",
        "      df_plays.loc[idx, 'Yardage'] = int(yardage[0])\n",
        "    else:\n",
        "      df_plays.loc[idx, 'Yardage'] = 0\n",
        "\n",
        "    # Formation\n",
        "    Formation = re.findall(formation, play)\n",
        "    if len(Formation) > 0:\n",
        "      if Formation[0] == 'Aborted':\n",
        "        pass\n",
        "      else:\n",
        "        df_plays.loc[idx, 'Formation'] = Formation[0]\n",
        "\n",
        "    # Passer (What about spikes?)\n",
        "    passer_name = re.findall(passer_name_pattern, play)\n",
        "    if len(passer_name) > 0:\n",
        "      df_plays.loc[idx, 'Passer'] = passer_name[0]\n",
        "\n",
        "    receiver_name_and_passing_details = re.findall(receiver_pattern, play)\n",
        "    if len(receiver_name_and_passing_details) > 0:\n",
        "      df_plays.loc[idx, 'Direction'] = f\"{receiver_name_and_passing_details[0][0]} {receiver_name_and_passing_details[0][1]}\"\n",
        "      df_plays.loc[idx, 'Receiver'] = receiver_name_and_passing_details[0][2]\n",
        "\n",
        "    # Unique situation (offense spikes the ball)\n",
        "    if play.find('spike') != -1:\n",
        "      df_plays.loc[idx, 'Direction'] = 'spiked' # Direction?\n",
        "\n",
        "    #############\n",
        "    #  DEFENSE  #\n",
        "    #############\n",
        "\n",
        "    solo_tackle = re.findall(solo_tackle_pattern, play)\n",
        "    if len(solo_tackle) > 0:\n",
        "      df_plays.loc[idx, 'SoloTackle'] = solo_tackle[0]\n",
        "\n",
        "    shared_tackle = re.findall(shared_tackle_pattern, play)\n",
        "    if len(shared_tackle) > 0:\n",
        "      df_plays.at[idx, 'SharedTackle'] = shared_tackle[0]\n",
        "\n",
        "    assisted_tackle = re.findall(assisted_tackle_pattern, play)\n",
        "    if len(assisted_tackle) > 0:\n",
        "      df_plays.loc[idx, 'SoloTackle'] = assisted_tackle[0][0]\n",
        "      df_plays.loc[idx, 'AssistedTackle'] = assisted_tackle[0][1]\n",
        "\n",
        "    pressure_by = re.findall(defense_pressure_name_pattern, play)\n",
        "    if len(pressure_by) > 0:\n",
        "      df_plays.loc[idx, 'PressureBy'] = pressure_by[0]\n",
        "\n",
        "    ##############\n",
        "    #  INJURIES  #\n",
        "    ##############\n",
        "\n",
        "    injuries = re.findall(injury_pattern, play)\n",
        "    if len(injuries) > 0:\n",
        "      df_plays.at[idx, 'InjuredPlayers'] = injuries\n",
        "\n",
        "    #############\n",
        "    #  PENALTY  #\n",
        "    #############\n",
        "\n",
        "    # Accepted Penalty\n",
        "    if play.find('PENALTY') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      penalties = []\n",
        "      for i in play_elements:\n",
        "        if i.find('PENALTY') != -1:\n",
        "          penalties.append(i)\n",
        "      df_plays.at[idx, 'AcceptedPenalty'] = penalties\n",
        "\n",
        "    # Declined Penalty\n",
        "    if play.find('Penalty') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      penalties = []\n",
        "      for i in play_elements:\n",
        "        if i.find('Penalty') != -1:\n",
        "          penalties.append(i)\n",
        "      df_plays.at[idx, 'DeclinedPenalty'] = penalties\n",
        "\n",
        "  if df_pass_plays.tail(1).index.tolist()[0] == idx:\n",
        "    return df_plays"
      ],
      "metadata": {
        "id": "cUrrWP2jI3yC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### RUN PLAYS"
      ],
      "metadata": {
        "id": "bRGsJa-J8CPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # PURPOSE:\n",
        "# # - Clean run play types\n",
        "# # INPUT PARAMETERS:\n",
        "# # df_plays    - dataframe - dataframe of plays\n",
        "# # index_start -  integer  - the starting index of the associated input dataframe\n",
        "# #                           to begin cleaning.\n",
        "# # RETURN:\n",
        "# # df_plays - dataframe - dataframe of plays that now has all useful run play\n",
        "# #                        data accessable and clean.\n",
        "\n",
        "# # NOTE:\n",
        "# # - Need to comment on how this is also a method being used for\n",
        "# #   1. fumble recoveries for yardage\n",
        "# #   2. fumble recoveries for touchdown\n",
        "# # - I also have not come across a case where a rushing play has been fumbled and someone\n",
        "# #   recovered the ball and scored a touchdown yet.\n",
        "\n",
        "# def clean_run_plays(df_plays, index_start = None):\n",
        "\n",
        "#   if index_start != None:\n",
        "#     df_plays_adjusted = df_plays.loc[index_start:]\n",
        "#     df_run_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('Run')]\n",
        "#   else:\n",
        "#     df_run_plays = df_plays[df_plays['PlayOutcome'].str.contains('Run')]\n",
        "\n",
        "#   # Iterating through every run play within 'df_run_plays'\n",
        "#   for idx, play in df_run_plays['PlayDescription'].items():\n",
        "\n",
        "#     ################\n",
        "#     # Play details #\n",
        "#     ################\n",
        "\n",
        "#     # Play Type\n",
        "#     df_plays.loc[idx, 'PlayType'] = 'Run'\n",
        "\n",
        "#     # TimeOnTheClock\n",
        "#     TimeOnTheClock = re.findall(time_on_clock_pattern, play)\n",
        "#     if len(TimeOnTheClock) > 0:\n",
        "#       df_plays.loc[idx, 'TimeOnTheClock'] = TimeOnTheClock[0]\n",
        "\n",
        "#     # Formation\n",
        "#     Formation = re.findall(formation, play)\n",
        "#     if len(Formation) > 0:\n",
        "#       if Formation[0] == 'Aborted':\n",
        "#         pass\n",
        "#       else:\n",
        "#         df_plays.loc[idx, 'Formation'] = Formation[0]\n",
        "\n",
        "#     ############\n",
        "#     # REVERSES #\n",
        "#     ############\n",
        "\n",
        "#     # In 'PlayDescription' all information before the \"reversed\" sentence is not needed.\n",
        "#     # - All information before is stored within 'ReverseDetails' and the remaining is cleaned.\n",
        "#     if play.find('REVERSED') != -1:\n",
        "#       play_elements = play.split(\". \")\n",
        "#       for i in play_elements:\n",
        "#         if i.find(\"REVERSED\") != -1:\n",
        "#           df_plays.at[idx, 'ReverseDetails'] = play_elements[:play_elements.index(i) + 1]\n",
        "#           play = \". \".join(play_elements[play_elements.index(i) + 1:])\n",
        "#           break\n",
        "\n",
        "#     ############################\n",
        "#     # REPORTING IN AS ELIGIBLE #\n",
        "#     ############################\n",
        "\n",
        "#     # I do not think this contains any useful data so I am going to exclude it.\n",
        "#     if play.find('reported in as eligible') != -1:\n",
        "#       play_elements = play.split(\". \")\n",
        "#       for i in play_elements:\n",
        "#         if i.find('reported in as eligible') != -1:\n",
        "#           play = \". \".join(play_elements[play_elements.index(i) + 1:])\n",
        "#           break\n",
        "\n",
        "#     ###########\n",
        "#     # FUMBLES #\n",
        "#     ###########\n",
        "\n",
        "#     if play.find('FUMBLES') != -1:\n",
        "\n",
        "#       # - I think it would help to comment on each action added\n",
        "#       # - Does this catch fumble recovery touchdowns?\n",
        "#       main_action_patterns = [rusher_pattern, aborted_fumble_pattern, qb_fumble_pattern, defensive_takeaway_run_pattern, handoff_pattern]\n",
        "#       main_cleaning_method = clean_run_plays\n",
        "#       df_replacement_rows = extract_fumble_data(df_plays, play, idx,\n",
        "#                                                 main_action_patterns,\n",
        "#                                                 main_cleaning_method)\n",
        "\n",
        "#       # \"df_plays.index.tolist().index(idx)\" needed for method usage with slices of original dataframe.\n",
        "#       df_before = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "#       df_after = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "#       df_plays = pd.concat([df_before, df_replacement_rows, df_after], ignore_index=True)\n",
        "#       index_of_last_added_row = idx + len(df_replacement_rows) - 1\n",
        "\n",
        "#       # returning row after the last index\n",
        "#       if df_run_plays.tail(1).index.tolist()[0] == idx:\n",
        "#         return df_plays\n",
        "#       else:\n",
        "#         return clean_run_plays(df_plays, index_of_last_added_row + 1)\n",
        "\n",
        "#     #############\n",
        "#     #  OFFENSE  #\n",
        "#     #############\n",
        "\n",
        "#     # Rusher\n",
        "#     rusher_patterns = [rusher_pattern, defensive_takeaway_run_pattern, qb_fumble_pattern, touchdown_after_takeaway_pattern, handoff_pattern]\n",
        "#     # Loop through patterns and find the first match\n",
        "#     for pattern in rusher_patterns:\n",
        "#       rusher = re.findall(pattern, play)\n",
        "#       if len(rusher) > 0:\n",
        "#         rusher_name = rusher[0]\n",
        "#         df_plays.loc[idx, 'Rusher'] = rusher_name\n",
        "#         break\n",
        "\n",
        "#     # Direction\n",
        "#     rushing_directions = ['guard', 'middle', 'tackle', 'end', 'kneels']\n",
        "#     for i in rushing_directions:\n",
        "#       if play.find(i) != -1:\n",
        "#         start = play.find(rusher_name) + len(rusher_name) + 1\n",
        "#         end = play.find(i) + len(i)\n",
        "#         df_plays.loc[idx, 'Direction'] = play[start:end]\n",
        "#         break\n",
        "\n",
        "#     # Yardage gained\n",
        "#     yardage = re.findall(yardage_gained, play)\n",
        "#     if len(yardage) > 0:\n",
        "#       df_plays.loc[idx, 'Yardage'] = int(yardage[0])\n",
        "#     else:\n",
        "#       df_plays.loc[idx, 'Yardage'] = 0\n",
        "\n",
        "#     #############\n",
        "#     #  DEFENSE  #\n",
        "#     #############\n",
        "\n",
        "#     solo_tackle = re.findall(solo_tackle_pattern, play)\n",
        "#     if len(solo_tackle) > 0:\n",
        "#       df_plays.loc[idx, 'SoloTackle'] = solo_tackle[0]\n",
        "\n",
        "#     shared_tackle = re.findall(shared_tackle_pattern, play)\n",
        "#     if len(shared_tackle) > 0:\n",
        "#       df_plays.at[idx, 'SharedTackle'] = shared_tackle[0]\n",
        "\n",
        "#     assisted_tackle = re.findall(assisted_tackle_pattern, play)\n",
        "#     if len(assisted_tackle) > 0:\n",
        "#       df_plays.loc[idx, 'SoloTackle'] = assisted_tackle[0][0]\n",
        "#       df_plays.loc[idx, 'AssistedTackle'] = assisted_tackle[0][1]\n",
        "\n",
        "#     ##############\n",
        "#     #  INJURIES  #\n",
        "#     ##############\n",
        "\n",
        "#     injuries = re.findall(injury_pattern, play)\n",
        "#     if len(injuries) > 0:\n",
        "#       df_plays.at[idx, 'InjuredPlayers'] = injuries\n",
        "\n",
        "#     #############\n",
        "#     #  PENALTY  #\n",
        "#     #############\n",
        "\n",
        "#     # Accepted Penalty\n",
        "#     if play.find('PENALTY') != -1:\n",
        "#       play_elements = play.split(\". \")\n",
        "#       penalties = []\n",
        "#       for i in play_elements:\n",
        "#         if i.find('PENALTY') != -1:\n",
        "#           penalties.append(i)\n",
        "#       df_plays.at[idx, 'AcceptedPenalty'] = penalties\n",
        "\n",
        "#     # Declined Penalty\n",
        "#     if play.find('Penalty') != -1:\n",
        "#       play_elements = play.split(\". \")\n",
        "#       penalties = []\n",
        "#       for i in play_elements:\n",
        "#         if i.find('Penalty') != -1:\n",
        "#           penalties.append(i)\n",
        "#       df_plays.at[idx, 'DeclinedPenalty'] = penalties\n",
        "\n",
        "#     # Return if the last play has been cleaned in 'df_run_plays'\n",
        "#     if df_run_plays.tail(1).index.tolist()[0] == idx:\n",
        "#       return df_plays"
      ],
      "metadata": {
        "id": "6OuwiIlqCYVN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PURPOSE:\n",
        "# - Clean run play types\n",
        "# INPUT PARAMETERS:\n",
        "# df_plays    - dataframe - dataframe of plays\n",
        "# index_start -  integer  - the starting index of the associated input dataframe\n",
        "#                           to begin cleaning.\n",
        "# RETURN:\n",
        "# df_plays - dataframe - dataframe of plays that now has all useful run play\n",
        "#                        data accessable and clean.\n",
        "\n",
        "# NOTE:\n",
        "# - Need to comment on how this is also a method being used for\n",
        "#   1. fumble recoveries for yardage\n",
        "#   2. fumble recoveries for touchdown\n",
        "# - I also have not come across a case where a rushing play has been fumbled and someone\n",
        "#   recovered the ball and scored a touchdown yet.\n",
        "\n",
        "def clean_run_plays(df_plays, index_start = None):\n",
        "\n",
        "  if index_start != None:\n",
        "    df_plays_adjusted = df_plays.loc[index_start:]\n",
        "    df_run_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('Run')]\n",
        "  else:\n",
        "    df_run_plays = df_plays[df_plays['PlayOutcome'].str.contains('Run')]\n",
        "\n",
        "  # Iterating through every run play within 'df_run_plays'\n",
        "  for idx, play in df_run_plays['PlayDescription'].items():\n",
        "\n",
        "    ################\n",
        "    # Play details #\n",
        "    ################\n",
        "\n",
        "    # Play Type\n",
        "    df_plays.loc[idx, 'PlayType'] = 'Run'\n",
        "\n",
        "    # TimeOnTheClock\n",
        "    TimeOnTheClock = re.findall(time_on_clock_pattern, play)\n",
        "    if len(TimeOnTheClock) > 0:\n",
        "      df_plays.loc[idx, 'TimeOnTheClock'] = TimeOnTheClock[0]\n",
        "\n",
        "    # Formation\n",
        "    Formation = re.findall(formation, play)\n",
        "    if len(Formation) > 0:\n",
        "      if Formation[0] == 'Aborted':\n",
        "        pass\n",
        "      else:\n",
        "        df_plays.loc[idx, 'Formation'] = Formation[0]\n",
        "\n",
        "    ############\n",
        "    # REVERSES #\n",
        "    ############\n",
        "\n",
        "    # In 'PlayDescription' all information before the \"reversed\" sentence is not needed.\n",
        "    # - All information before is stored within 'ReverseDetails' and the remaining is cleaned.\n",
        "    if play.find('REVERSED') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      for i in play_elements:\n",
        "        if i.find(\"REVERSED\") != -1:\n",
        "          df_plays.at[idx, 'ReverseDetails'] = play_elements[:play_elements.index(i) + 1]\n",
        "          play = \". \".join(play_elements[play_elements.index(i) + 1:])\n",
        "          break\n",
        "\n",
        "    ############################\n",
        "    # REPORTING IN AS ELIGIBLE #\n",
        "    ############################\n",
        "\n",
        "    # I do not think this contains any useful data so I am going to exclude it.\n",
        "    if play.find('reported in as eligible') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      for i in play_elements:\n",
        "        if i.find('reported in as eligible') != -1:\n",
        "          play = \". \".join(play_elements[play_elements.index(i) + 1:])\n",
        "          break\n",
        "\n",
        "    ###########\n",
        "    # FUMBLES #\n",
        "    ###########\n",
        "\n",
        "    if play.find('FUMBLES') != -1:\n",
        "\n",
        "      # - I think it would help to comment on each action added\n",
        "      # - Does this catch fumble recovery touchdowns? <--\n",
        "      main_action_patterns = [rusher_pattern, aborted_fumble_pattern, qb_fumble_pattern, defensive_takeaway_run_pattern, handoff_pattern]\n",
        "      main_cleaning_method = clean_run_plays\n",
        "      df_replacement_rows = extract_fumble_data(df_plays, play, idx,\n",
        "                                                main_action_patterns,\n",
        "                                                main_cleaning_method)\n",
        "\n",
        "      # \"df_plays.index.tolist().index(idx)\" needed for method usage with slices of original dataframe.\n",
        "      df_before = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before, df_replacement_rows, df_after], ignore_index=True)\n",
        "      index_of_last_added_row = idx + len(df_replacement_rows) - 1\n",
        "\n",
        "      # returning row after the last index\n",
        "      if df_run_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_run_plays(df_plays, index_of_last_added_row + 1)\n",
        "\n",
        "    #############\n",
        "    #  OFFENSE  #\n",
        "    #############\n",
        "\n",
        "    # Rusher\n",
        "    rusher_patterns = [rusher_pattern, defensive_takeaway_run_pattern, qb_fumble_pattern, touchdown_after_takeaway_pattern, handoff_pattern]\n",
        "    # Loop through patterns and find the first match\n",
        "    for pattern in rusher_patterns:\n",
        "      rusher = re.findall(pattern, play)\n",
        "      if len(rusher) > 0:\n",
        "        rusher_name = rusher[0]\n",
        "        df_plays.loc[idx, 'Rusher'] = rusher_name\n",
        "        break\n",
        "\n",
        "    # Direction\n",
        "    rushing_directions = ['guard', 'middle', 'tackle', 'end', 'kneels']\n",
        "    for i in rushing_directions:\n",
        "      if play.find(i) != -1:\n",
        "        start = play.find(rusher_name) + len(rusher_name) + 1\n",
        "        end = play.find(i) + len(i)\n",
        "        df_plays.loc[idx, 'Direction'] = play[start:end]\n",
        "        break\n",
        "\n",
        "    # Yardage gained\n",
        "    yardage = re.findall(yardage_gained, play)\n",
        "    if len(yardage) > 0:\n",
        "      df_plays.loc[idx, 'Yardage'] = int(yardage[0])\n",
        "    else:\n",
        "      df_plays.loc[idx, 'Yardage'] = 0\n",
        "\n",
        "    #############\n",
        "    #  DEFENSE  #\n",
        "    #############\n",
        "\n",
        "    solo_tackle = re.findall(solo_tackle_pattern, play)\n",
        "    if len(solo_tackle) > 0:\n",
        "      df_plays.loc[idx, 'SoloTackle'] = solo_tackle[0]\n",
        "\n",
        "    shared_tackle = re.findall(shared_tackle_pattern, play)\n",
        "    if len(shared_tackle) > 0:\n",
        "      df_plays.at[idx, 'SharedTackle'] = shared_tackle[0]\n",
        "\n",
        "    assisted_tackle = re.findall(assisted_tackle_pattern, play)\n",
        "    if len(assisted_tackle) > 0:\n",
        "      df_plays.loc[idx, 'SoloTackle'] = assisted_tackle[0][0]\n",
        "      df_plays.loc[idx, 'AssistedTackle'] = assisted_tackle[0][1]\n",
        "\n",
        "    ##############\n",
        "    #  INJURIES  #\n",
        "    ##############\n",
        "\n",
        "    injuries = re.findall(injury_pattern, play)\n",
        "    if len(injuries) > 0:\n",
        "      df_plays.at[idx, 'InjuredPlayers'] = injuries\n",
        "\n",
        "    #############\n",
        "    #  PENALTY  #\n",
        "    #############\n",
        "\n",
        "    # I am going to create new features to add onto penalties\n",
        "    # 1. Yardage from penalty\n",
        "    #    - offensive penalty yards\n",
        "    #    - defensive penalty yards\n",
        "    # 2. Offensive penalty\n",
        "    # 3. Defensive penalty\n",
        "    # 4. Maybe I should add a 'total yards gained' feature?\n",
        "    #    - This way, I can easily grab\n",
        "    #      1. Yards from play\n",
        "    #      2. Yards from penalty\n",
        "    #      3. Yards gained all together\n",
        "    # 5. Should I have a 'Player awarded yardage' feature?\n",
        "    #\n",
        "    # - I'm going to have to make a helper method to handle plays containing\n",
        "    #   penalties.\n",
        "\n",
        "    # Accepted Penalty\n",
        "    if play.find('PENALTY') != -1:\n",
        "      # accepted_penalty_play(df_run_plays, play, idx)\n",
        "      play_elements = play.split(\". \")\n",
        "      offensive_penalties = []\n",
        "      defensive_penalties = []\n",
        "      for i in play_elements:\n",
        "        if i.find('PENALTY') != -1:\n",
        "\n",
        "          # Here I will see whether it was an offensive or defensive penalty\n",
        "          penalty_player_team = re.findall(team_name_pattern, i)\n",
        "          if len(penalty_player_team) > 0:\n",
        "            if penalty_player_team[0] == df_run_plays['TeamWithPossession'].loc[idx]:\n",
        "              accepted_penalty_play_on_offense(df_run_plays, play, idx)\n",
        "              offensive_penalties.append(i)\n",
        "            else:\n",
        "              defensive_penalties.append(i)\n",
        "\n",
        "      df_plays.at[idx, 'OffensivePenalty'] = offensive_penalties\n",
        "      df_plays.at[idx, 'DefensivePenalty'] = defensive_penalties\n",
        "\n",
        "    # Declined Penalty\n",
        "    if play.find('Penalty') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      offensive_penalties = []\n",
        "      defensive_penalties = []\n",
        "      for i in play_elements:\n",
        "        if i.find('Penalty') != -1:\n",
        "          # Here I will see whether it was an offensive or defensive penalty\n",
        "          penalty_player_team = re.findall(team_name_pattern, i)\n",
        "          if len(penalty_player_team) > 0:\n",
        "            if penalty_player_team[0] == df_run_plays['TeamWithPossession'].loc[idx]:\n",
        "              offensive_penalties.append(i)\n",
        "            else:\n",
        "              defensive_penalties.append(i)\n",
        "\n",
        "      df_plays.at[idx, 'OffensivePenalty'] = offensive_penalties\n",
        "      df_plays.at[idx, 'DefensivePenalty'] = defensive_penalties\n",
        "\n",
        "    # Return if the last play has been cleaned in 'df_run_plays'\n",
        "    if df_run_plays.tail(1).index.tolist()[0] == idx:\n",
        "      return df_plays"
      ],
      "metadata": {
        "id": "HMtvtTeWxPLj"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2PT CONVERSIONS"
      ],
      "metadata": {
        "id": "oHh3e-2kHDIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I NEED A LARGER SAMPLE SIZE FOR MORE PLAYS\n",
        "# - I need a sample size that has fumbled plays (if that's possible?)\n",
        "# - I need a sample size that has interception (if that's possible?)\n",
        "# - I need a sample size with injuries (as dark as that may sound)\n",
        "\n",
        "def cleaning_2pt_conversion_plays(df_plays, index_start = None):\n",
        "\n",
        "  # Cut 'df_plays' to begin from 'index_start' to the last penalty play available in dataframe\n",
        "  if index_start != None:\n",
        "    df_plays_adjusted = df_plays.loc[index_start]\n",
        "    df_2pt_conversion_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('2PT Conversion', case=False)]\n",
        "  else:\n",
        "    df_2pt_conversion_plays = df_plays[df_plays['PlayOutcome'].str.contains('2PT Conversion', case=False)]\n",
        "\n",
        "  # Iterating through every penalty play within 'df_2pt_conversion_plays'\n",
        "  for idx, play in df_2pt_conversion_plays['PlayDescription'].items():\n",
        "\n",
        "    ###################\n",
        "    # PASSING ATTEMPT #\n",
        "    ###################\n",
        "\n",
        "    pass_2ptc = re.findall(tp_conversion_pass_pattern, play)\n",
        "    if len(pass_2ptc) > 0:\n",
        "      df_plays.loc[idx, 'Passer'] = pass_2ptc[0][0]\n",
        "      df_plays.loc[idx, 'Receiver'] = pass_2ptc[0][1]\n",
        "      df_plays.loc[idx, 'PlayType'] = '2PT Conversion Pass'\n",
        "\n",
        "    ###################\n",
        "    # RUSHING ATTEMPT #\n",
        "    ###################\n",
        "\n",
        "    rush_2ptc = re.findall(tp_conversion_rush_pattern, play)\n",
        "    if len(rush_2ptc) > 0:\n",
        "      df_plays.loc[idx, 'Rusher'] = rush_2ptc[0]\n",
        "      df_plays.loc[idx, 'PlayType'] = '2PT Conversion Run'\n",
        "      # Direction\n",
        "      rushing_directions = ['guard', 'middle', 'tackle', 'end', 'kneels']\n",
        "      for i in rushing_directions:\n",
        "        if play.find(i) != -1:\n",
        "          start = play.find('rushes') + len('rushes') + 1\n",
        "          end = play.find(i) + len(i)\n",
        "          df_plays.loc[idx, 'Direction'] = play[start:end]\n",
        "          break\n",
        "\n",
        "    #############\n",
        "    #  PENALTY  #\n",
        "    #############\n",
        "\n",
        "    # Accepted Penalty\n",
        "    if play.find('PENALTY') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      penalties = []\n",
        "      for i in play_elements:\n",
        "        if i.find('PENALTY') != -1:\n",
        "          penalties.append(i)\n",
        "      df_plays.at[idx, 'AcceptedPenalty'] = penalties\n",
        "\n",
        "    # Declined Penalty\n",
        "    if play.find('Penalty') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      penalties = []\n",
        "      for i in play_elements:\n",
        "        if i.find('Penalty') != -1:\n",
        "          penalties.append(i)\n",
        "      df_plays.at[idx, 'DeclinedPenalty'] = penalties\n",
        "\n",
        "  return df_plays"
      ],
      "metadata": {
        "id": "PIjLfa5XHIq8"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###DEFENSE CLEANING METHODS"
      ],
      "metadata": {
        "id": "TieP_Cy5rmj-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### INTERCEPTIONS"
      ],
      "metadata": {
        "id": "CZpJpikZCx--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PURPOSE:\n",
        "# - Clean intercepted plays\n",
        "# INPUT PARAMETERS:\n",
        "# df_plays    - dataframe - dataframe of plays\n",
        "# index_start -  integer  - the starting index of the associated input dataframe\n",
        "#                           to begin cleaning.\n",
        "# RETURN:\n",
        "# df_plays - dataframe - dataframe of plays that now has all useful intercepted play\n",
        "#                        data accessible and clean.\n",
        "\n",
        "# ROUGH DESGIN\n",
        "# 1. Narrow dataframe using 'index_start'\n",
        "#    - This is a recursive method, the narrowing will get smaller and\n",
        "#      smaller until all 'intercepted' type plays have been cleaned.\n",
        "# 2. Grab first 'intercepted' play from narrowed dataframe\n",
        "# 3. Create 2 single row dataframes.\n",
        "#    a. intended play\n",
        "#    b. yardage after interception\n",
        "# 4. Break down play into sentences and clean\n",
        "#    - Depending on the sentence within the play, will determine which\n",
        "#      single row dataframe it will go to.\n",
        "# 5. Combine both dataframes of cleaned data into one dataframe\n",
        "# 6. Replace old play row with new cleaned multi row\n",
        "# 7. return clean_interceped_plays( x , y)\n",
        "#    - x = updated df_plays\n",
        "#    - y = index directly after the last clean added row\n",
        "\n",
        "# Concerns:\n",
        "# ~ 1 ~\n",
        "# PLAY SNIP - \"(9:53) (Shotgun) D.Watson pass short left intended for E.Moore INTERCEPTED by D.Hill (Z.Carter) at CIN 30.\"\n",
        "# - The concern here is (Z.Carter)\n",
        "#   - I do not know what to categorize this player as? I believe that he had an impact on the play and could possibly be a reason\n",
        "#     that D.Hill was able to intercept the ball.\n",
        "#     - Should I create a feature called \"ImpactPlayer\" or something?\n",
        "# ~ 2 ~\n",
        "# PLAY SNIP - \"(4:16) (Shotgun) J.Allen pass deep middle intended for S.Diggs INTERCEPTED by J.Whitehead [Q.Williams] at NYJ -1. Touchback.\"\n",
        "# - The concern here is 'touchback'\n",
        "#   - I have no idea what to do with that\n",
        "# ~ 3 ~\n",
        "#`- I do not have anything set in play to handle fumbles? What happens if a QB fumbles, recovers, then throws an interception? -> Then player that intercepted fumbles?\n",
        "# ~ 4 ~\n",
        "# - There are 2 rows within this sinlge play. (Intended throwing play, yardage after interception)\n",
        "#   - For both of these rows that represent a single play, they both state that the throwing team has possession\n",
        "#     - I do not know how this is going to effect the future with analysis on data\n",
        "# - -----> GRAB DATA FOR TOUCHBACKS <-----\n",
        "# - -----> GRAB DATA FOR PLAYTYPE INTERCEPTION FOR YARDAGE <-----\n",
        "\n",
        "def clean_intercepted_plays(df_plays, index_start = None):\n",
        "\n",
        "  # Will cut df_plays starting from index_start (narrowing our search space)\n",
        "  if index_start != None:\n",
        "    df_plays_adjusted = df_plays.loc[index_start:]\n",
        "    df_intercepted_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('Interception')]\n",
        "  else:\n",
        "    df_intercepted_plays = df_plays[df_plays['PlayOutcome'].str.contains('Interception')]\n",
        "\n",
        "  # Exit case (If no more 'Interception' type plays are found)\n",
        "  if df_intercepted_plays.empty:\n",
        "    return df_plays\n",
        "\n",
        "  # Retrieve the index and 'PlayDescription' of the first intercepted play in 'df_intercepted_plays'\n",
        "  # - Process one play per iteration in the recursive method\n",
        "  idx = df_intercepted_plays.index[0]\n",
        "  play = df_plays['PlayDescription'].loc[idx]\n",
        "\n",
        "  ############\n",
        "  # REVERSES #\n",
        "  ############\n",
        "\n",
        "  # In 'PlayDescription' all information before the \"reversed\" sentence is not needed.\n",
        "  # - All information before is stored within 'ReverseDetails' and the remaining is cleaned.\n",
        "  if play.find('REVERSED') != -1:\n",
        "    play_elements = play.split(\". \")\n",
        "    for i in play_elements:\n",
        "      if i.find(\"REVERSED\") != -1:\n",
        "        df_plays.at[idx, 'ReverseDetails'] = play_elements[:play_elements.index(i) + 1]\n",
        "        play = \". \".join(play_elements[play_elements.index(i) + 1:])\n",
        "        break\n",
        "\n",
        "  # Create 2 single row dataframes.\n",
        "  # 1. intended play\n",
        "  df_intended_play = df_plays.loc[idx].copy()\n",
        "  df_intended_play = pd.DataFrame([df_intended_play], columns=df_plays.columns)\n",
        "  df_intended_play.reset_index(drop=True, inplace=True)\n",
        "  df_intended_play['PlayDescription'] = 'nan'\n",
        "  # 2. yardage after interception\n",
        "  df_yardage_after_interception = df_plays.loc[idx].copy()\n",
        "  df_yardage_after_interception = pd.DataFrame([df_yardage_after_interception], columns=df_plays.columns)\n",
        "  df_yardage_after_interception.reset_index(drop=True, inplace=True)\n",
        "  df_yardage_after_interception['PlayDescription'] = 'nan'\n",
        "\n",
        "  # break down play by sentences.\n",
        "  play_elements = play.split(\". \")\n",
        "\n",
        "  # Every sentence within 'PlayDescription' except yardage/touchdown after interception\n",
        "  intended_play_data = []\n",
        "\n",
        "  # iterate through play_elements\n",
        "  for i in play_elements:\n",
        "\n",
        "    ##############################\n",
        "    # YARDAGE AFTER INTERCEPTION #\n",
        "    ##############################\n",
        "\n",
        "    yardage_after_interception = re.findall(defensive_takeaway_run_pattern, i)\n",
        "    if len(yardage_after_interception) > 0:\n",
        "      df_yardage_after_interception['PlayDescription'] = i\n",
        "\n",
        "      # Player running after interception\n",
        "      df_yardage_after_interception['Rusher'] = yardage_after_interception[0]\n",
        "\n",
        "      # Playtype?\n",
        "      # - Should this be a new playtype? Something like \"RunAfterInterception\"?\n",
        "\n",
        "      # Yardage gained\n",
        "      yardage = re.findall(yardage_gained, i)\n",
        "      if len(yardage) > 0:\n",
        "        df_yardage_after_interception['Yardage'] = int(yardage[0])\n",
        "      else:\n",
        "        df_yardage_after_interception['Yardage'] = 0\n",
        "\n",
        "      # Who made tackle\n",
        "      tackler = re.findall(solo_tackle_pattern, i)\n",
        "      if len(tackler) > 0:\n",
        "        df_yardage_after_interception['SoloTackle'] = tackler[0]\n",
        "\n",
        "      continue\n",
        "\n",
        "    ################################\n",
        "    # TOUCHDOWN AFTER INTERCEPTION #\n",
        "    ################################\n",
        "\n",
        "    touchdown_after_interception_check = re.findall(touchdown_after_takeaway_pattern, i)\n",
        "    if len(touchdown_after_interception_check) > 0:\n",
        "      df_yardage_after_interception['PlayDescription'] = i\n",
        "\n",
        "      # Player running after interception\n",
        "      df_yardage_after_interception['Rusher'] = touchdown_after_interception_check[0]\n",
        "\n",
        "      # Yardage gained\n",
        "      yardage = re.findall(yardage_gained, i)\n",
        "      if len(yardage) > 0:\n",
        "        df_yardage_after_interception['Yardage'] = int(yardage[0])\n",
        "\n",
        "      # # PlayOutcome\n",
        "      # df_yardage_after_interception['PlayOutcome'] = 'Touchdown'\n",
        "\n",
        "      # IsScoringPlay\n",
        "      df_yardage_after_interception['IsScoringPlay'] = 1\n",
        "\n",
        "      continue\n",
        "\n",
        "    intended_play_data.append(i)\n",
        "\n",
        "  #################\n",
        "  # INTENDED PLAY #\n",
        "  #################\n",
        "\n",
        "  intended_play_playdescription = \". \".join(intended_play_data)\n",
        "\n",
        "  df_intended_play['PlayDescription'] = intended_play_playdescription\n",
        "\n",
        "  df_intended_play['PlayOutcome'] = 'Pass'\n",
        "  df_intended_play = clean_pass_plays(df_intended_play)\n",
        "  df_intended_play['PlayOutcome'] =  df_plays['PlayOutcome'].loc[idx]\n",
        "\n",
        "  # Intercepted by\n",
        "  intercepted_by = re.findall(interception_name_pattern, intended_play_playdescription)\n",
        "  if len(intercepted_by) > 0:\n",
        "    df_intended_play['InterceptedBy'] = intercepted_by[0]\n",
        "\n",
        "  #############################\n",
        "  # NEW REPLACEMENT DATAFRAME #\n",
        "  #############################\n",
        "\n",
        "  # combine both single row dataframes into one\n",
        "  if df_yardage_after_interception['PlayDescription'].iloc[0] == 'nan':\n",
        "    df_cleaned_replacement = df_intended_play\n",
        "  else:\n",
        "    df_cleaned_replacement = pd.concat([df_intended_play, df_yardage_after_interception], ignore_index=True)\n",
        "\n",
        "  # Replace old row with new cleaned dataframe\n",
        "  df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "  df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "  df_plays = pd.concat([df_before_row, df_cleaned_replacement, df_after_row], ignore_index=True)\n",
        "\n",
        "  # If this is the last play in the dataset\n",
        "  if df_intercepted_plays.tail(1).index.tolist()[0] == idx:\n",
        "    return df_plays\n",
        "  else:\n",
        "    return clean_intercepted_plays(df_plays, idx+len(df_cleaned_replacement))"
      ],
      "metadata": {
        "id": "2GEMXbRHjt1W"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SACKS\n"
      ],
      "metadata": {
        "id": "Rp-Bszm-B9rh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_sacked_plays(df_plays, index_start = None):\n",
        "\n",
        "  # Will cut df_plays starting from index_start (narrowing our search space)\n",
        "  if index_start != None:\n",
        "    df_plays_adjusted = df_plays.iloc[index_start:]\n",
        "    df_sacked_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('Sack')]\n",
        "  else:\n",
        "    df_sacked_plays = df_plays[df_plays['PlayOutcome'].str.contains('Sack')]\n",
        "\n",
        "  for idx, play in df_sacked_plays['PlayDescription'].items():\n",
        "\n",
        "    ################\n",
        "    # Play details #\n",
        "    ################\n",
        "\n",
        "    # TimeOnTheClock\n",
        "    TimeOnTheClock = re.findall(time_on_clock_pattern, play)\n",
        "    if len(TimeOnTheClock) > 0:\n",
        "      df_plays.loc[idx, 'TimeOnTheClock'] = TimeOnTheClock[0]\n",
        "\n",
        "    ###########\n",
        "    # FUMBLES #\n",
        "    ###########\n",
        "\n",
        "    if play.find('FUMBLES') != -1:\n",
        "\n",
        "      main_action_patterns = [passer_name_pattern, defensive_takeaway_run_pattern, touchdown_after_takeaway_pattern]\n",
        "      main_cleaning_method = clean_sacked_plays\n",
        "      df_replacement_rows = extract_fumble_data(df_plays, play, idx,\n",
        "                                                main_action_patterns,\n",
        "                                                main_cleaning_method)\n",
        "\n",
        "      # \"df_plays.index.tolist().index(idx)\" needed for method usage with slices of original dataframe.\n",
        "      df_before = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before, df_replacement_rows, df_after], ignore_index=True)\n",
        "      index_of_last_added_row = idx + len(df_replacement_rows) - 1\n",
        "      # returning row after the last index\n",
        "      if df_sacked_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_sacked_plays(df_plays, index_of_last_added_row + 1)\n",
        "\n",
        "    #############\n",
        "    #  OFFENSE  #\n",
        "    #############\n",
        "\n",
        "    # Formation\n",
        "    Formation = re.findall(formation, play)\n",
        "    if len(Formation) > 0:\n",
        "      if Formation[0] == 'Aborted':\n",
        "        pass\n",
        "      else:\n",
        "        df_plays.loc[idx, 'Formation'] = Formation[0]\n",
        "\n",
        "    # Sacked Passer\n",
        "    sacked_passer_name = re.findall(passer_name_pattern, play)\n",
        "    if len(sacked_passer_name) > 0:\n",
        "      df_plays.loc[idx, 'Passer'] = sacked_passer_name[0]\n",
        "\n",
        "    # Yardage lost\n",
        "    yardage = re.findall(yardage_from_sack, play)\n",
        "    if len(yardage) > 0:\n",
        "      df_plays.loc[idx, 'Yardage'] = int(yardage[0])\n",
        "\n",
        "    #############\n",
        "    #  DEFENSE  #\n",
        "    #############\n",
        "\n",
        "    # Solo sack (One person sacked the passer)\n",
        "    solo_sack = re.findall(defense_tackler_1_name_pattern, play)\n",
        "    if len(solo_sack) > 0:\n",
        "      df_plays.loc[idx, 'SackedBy'] = solo_sack[0]\n",
        "\n",
        "    # Split sack (A sack was given to the passer by multiple defenders)\n",
        "    split_sack = re.findall(split_sack_pattern, play)\n",
        "    if len(split_sack) > 0:\n",
        "      df_plays.at[idx, 'SackedBy'] = split_sack[0]\n",
        "\n",
        "    ##############\n",
        "    #  INJURIES  #\n",
        "    ##############\n",
        "\n",
        "    injuries = re.findall(injury_pattern, play)\n",
        "    if len(injuries) > 0:\n",
        "      df_plays.at[idx, 'InjuredPlayers'] = injuries\n",
        "\n",
        "    #############\n",
        "    #  PENALTY  #\n",
        "    #############\n",
        "\n",
        "    # Accepted Penalty\n",
        "    if play.find('PENALTY') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      penalties = []\n",
        "      for i in play_elements:\n",
        "        if i.find('PENALTY') != -1:\n",
        "          penalties.append(i)\n",
        "      df_plays.at[idx, 'AcceptedPenalty'] = penalties\n",
        "\n",
        "    # Declined Penalty\n",
        "    if play.find('Penalty') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      penalties = []\n",
        "      for i in play_elements:\n",
        "        if i.find('Penalty') != -1:\n",
        "          penalties.append(i)\n",
        "      df_plays.at[idx, 'DeclinedPenalty'] = penalties\n",
        "\n",
        "    if df_sacked_plays.tail(1).index.tolist()[0] == idx:\n",
        "      return df_plays"
      ],
      "metadata": {
        "id": "s8F6nfFsCG6B"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SPECIAL TEAMS CLEANING METHODS"
      ],
      "metadata": {
        "id": "eIX_e2jUrwdt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### PUNTS"
      ],
      "metadata": {
        "id": "Rt2DLo02qSa5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A punt playtype will be split into 2 or more rows\n",
        "#   1. The Punt\n",
        "#      - 'PlayType'\n",
        "#         - Punt\n",
        "#      - 'Punter'\n",
        "#      - 'LongSnapper'\n",
        "#   2. The Punt Return\n",
        "#      - 'PlayType'\n",
        "#         - Punt Return\n",
        "#      - 'PlayOutcome'\n",
        "#         - x yard punt return\n",
        "#         - fair catch\n",
        "#         - touchback\n",
        "#         - out of bounds\n",
        "#         - downed\n",
        "#      - 'Returner'\n",
        "#      - 'Receiver'\n",
        "#      - 'Yardage'\n",
        "#      - 'TackleBy1'\n",
        "#      - 'TackleBy2'\n",
        "#      - 'DownedBy'\n",
        "\n",
        "# I need to figure out a fake punt\n",
        "# I need to figure out a punt that has been blocked\n",
        "# I need to figure out what to do when a fumble happens\n",
        "# I need to figure out what to do when a touchdown happens\n",
        "# Maybe in the future, to make this more space friendly, I can combine features\n",
        "# - Such as 'Punter' & 'LongSnapper' OR 'TackleBy1' & 'DownedBy'\n",
        "#   OR 'Returner' & 'Receiver'\n",
        "\n",
        "def clean_punt_plays(df_plays, index_start = None):\n",
        "\n",
        "  # Will cut df_plays starting from index_start (narrowing our search space)\n",
        "  if index_start != None:\n",
        "    df_plays_adjusted = df_plays.loc[index_start:]\n",
        "    df_punt_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('Punt')]\n",
        "  else:\n",
        "    df_punt_plays = df_plays[df_plays['PlayOutcome'].str.contains('Punt')]\n",
        "\n",
        "  if df_punt_plays.empty:\n",
        "    return df_plays\n",
        "\n",
        "  # Retrieve the index and 'PlayDescription' of the first punt play in 'df_punt_plays'\n",
        "  # - Process one play per iteration in the recursive method\n",
        "  idx = df_punt_plays.index[0]\n",
        "  play = df_plays['PlayDescription'].loc[idx]\n",
        "  row_copy = df_plays.loc[idx].copy()\n",
        "\n",
        "  ############\n",
        "  # REVERSES #\n",
        "  ############\n",
        "\n",
        "  # In 'PlayDescription' all information before the \"reversed\" sentence is not needed.\n",
        "  # - All information before is stored within 'ReverseDetails' and the remaining is cleaned.\n",
        "  if play.find('REVERSED') != -1:\n",
        "    play_elements = play.split(\". \")\n",
        "    for i in play_elements:\n",
        "      if i.find(\"REVERSED\") != -1:\n",
        "        df_plays.at[idx, 'ReverseDetails'] = play_elements[:play_elements.index(i) + 1]\n",
        "        play = \". \".join(play_elements[play_elements.index(i) + 1:])\n",
        "        break\n",
        "\n",
        "  # Create 2 single row dataframes.\n",
        "  # 1. The Punt\n",
        "  df_punt = row_copy\n",
        "  df_punt = pd.DataFrame([df_punt], columns=df_plays.columns)\n",
        "  df_punt.reset_index(drop=True, inplace=True)\n",
        "  df_punt['PlayDescription'] = 'nan'\n",
        "  # 2. The Punt Return\n",
        "  df_punt_return = row_copy\n",
        "  df_punt_return = pd.DataFrame([df_punt_return], columns=df_plays.columns)\n",
        "  df_punt_return.reset_index(drop=True, inplace=True)\n",
        "  df_punt_return['PlayDescription'] = 'nan'\n",
        "\n",
        "  #############\n",
        "  # PLAY TIME #\n",
        "  #############\n",
        "\n",
        "  time = re.findall(time_on_clock_pattern, play)\n",
        "  if len(time) > 0:\n",
        "    df_punt.loc[0, 'TimeOnTheClock'] = time[0]\n",
        "\n",
        "  # break down play by sentences.\n",
        "  play_elements = play.split(\". \")\n",
        "\n",
        "  accepted_penalties = []\n",
        "  declined_penalties = []\n",
        "\n",
        "  for i in play_elements:\n",
        "\n",
        "    ########\n",
        "    # PUNT #\n",
        "    ########\n",
        "\n",
        "    # All data needed for first row in replacement dataframe\n",
        "    punt = re.findall(punting_pattern, i)\n",
        "    if len(punt) > 0:\n",
        "      df_punt['PlayType'] = 'Punt'\n",
        "      df_punt['PlayDescription'] = i\n",
        "      df_punt['Kicker'] = punt[0][0]\n",
        "      df_punt['Yardage'] = int(punt[0][1])\n",
        "      df_punt['LongSnapper'] = punt[0][2]\n",
        "      # Touchback\n",
        "      if i.find('Touchback') != -1:\n",
        "        df_punt['PlayOutcome'] = 'Touchback'\n",
        "        continue\n",
        "      # Out of bounds\n",
        "      if i.find('out of bounds') != -1:\n",
        "        df_punt['PlayOutcome'] = 'out of bounds'\n",
        "        continue\n",
        "      # Downed by\n",
        "      if i.find('downed by') != -1:\n",
        "        df_punt['PlayOutcome'] = 'downed'\n",
        "        downed_by = re.findall(kick_downed_by_pattern, i)\n",
        "        df_punt['DownedBy'] = downed_by[0][downed_by[0].find(\"-\")+1:] # Need to get abreviation of team name away from player name (e.g. IND-G.Stuard)\n",
        "        continue\n",
        "      # fair catch\n",
        "      if i.find('fair catch') != -1:\n",
        "        df_punt['PlayOutcome'] = 'fair catch'\n",
        "        fair_catch_by = re.findall(punt_fair_catch_pattern, i)\n",
        "        df_punt['Returner'] = fair_catch_by[0]\n",
        "        continue\n",
        "      continue\n",
        "\n",
        "    ######################################\n",
        "    # PUNT RETURN (Including touchdowns) #\n",
        "    ######################################\n",
        "\n",
        "    # All data needed for the second row within replacement dataframe\n",
        "    # - Second row only needed when there is a punt return for yardage\n",
        "    # - I think I am going to run into trouble if there is a fumble recovery for yardage\n",
        "    punt_return_patterns = [punt_return_pattern, touchdown_after_takeaway_pattern]\n",
        "    for return_pattern in punt_return_patterns:\n",
        "      punt_return = re.findall(return_pattern, i)\n",
        "      if len(punt_return) > 0:\n",
        "        df_punt_return['PlayDescription'] = i\n",
        "        df_punt_return['PlayOutcome'] = 'Run'\n",
        "        df_punt_return = clean_run_plays(df_punt_return)\n",
        "        df_punt_return['PlayOutcome'] = row_copy['PlayOutcome']\n",
        "        df_punt_return['PlayType'] = 'Punt Return'\n",
        "        df_punt_return['Rusher'] = 'nan'\n",
        "        df_punt_return['Returner'] = punt_return[0]\n",
        "        break\n",
        "\n",
        "    #############\n",
        "    #  PENALTY  #\n",
        "    #############\n",
        "\n",
        "    # Accepted Penalty\n",
        "    if i.find('PENALTY') != -1:\n",
        "      accepted_penalties.append(i)\n",
        "\n",
        "    # Declined Penalty\n",
        "    if i.find('Penalty') != -1:\n",
        "      declined_penalties.append(i)\n",
        "\n",
        "    # If playoutcome is the same as the original play, then run second sentence through\n",
        "    # run cleaning method.\n",
        "\n",
        "  if len(accepted_penalties) > 0:\n",
        "    df_punt.at[0, 'AcceptedPenalty'] = accepted_penalties\n",
        "  if len(declined_penalties) > 0:\n",
        "    df_punt.at[0, 'DeclinedPenalty'] = declined_penalties\n",
        "\n",
        "  #############################\n",
        "  # NEW REPLACEMENT DATAFRAME #\n",
        "  #############################\n",
        "\n",
        "  if df_punt_return['PlayDescription'].iloc[0] == 'nan':\n",
        "    df_replacement_rows = df_punt\n",
        "  else:\n",
        "    df_replacement_rows = pd.concat([df_punt, df_punt_return], ignore_index=True)\n",
        "\n",
        "  df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "  df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "  df_plays = pd.concat([df_before_row, df_replacement_rows, df_after_row], ignore_index=True)\n",
        "\n",
        "  if df_punt_plays.tail(1).index.tolist()[0] == idx:\n",
        "    return df_plays\n",
        "  else:\n",
        "    return clean_punt_plays(df_plays, idx+len(df_replacement_rows))"
      ],
      "metadata": {
        "id": "IL0XDsAyqWtO"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### KICKOFFS"
      ],
      "metadata": {
        "id": "yzGnlGvPZiZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A kickoff playtype will be split into 1 or more rows\n",
        "\n",
        "# I need to figure out an onside kick (recovered by kicking team)\n",
        "# I need to figure out fumbled kickoff returns\n",
        "# I need to figure out returns for a touchdown\n",
        "# injuries?\n",
        "\n",
        "# Method can mirror punts method.\n",
        "\n",
        "def clean_kickoff_plays(df_plays, index_start = None):\n",
        "\n",
        "  # Will cut df_plays starting from index_start (narrowing our search space)\n",
        "  if index_start != None:\n",
        "    df_plays_adjusted = df_plays.loc[index_start:]\n",
        "    df_kickoff_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('kickoff', case=False)]\n",
        "  else:\n",
        "    df_kickoff_plays = df_plays[df_plays['PlayOutcome'].str.contains('kickoff', case=False)]\n",
        "\n",
        "  # exit case\n",
        "  if df_kickoff_plays.empty:\n",
        "    return df_plays\n",
        "\n",
        "  # Retrieve the index and 'PlayDescription' of the first kickoff play in 'df_kickoff_plays'\n",
        "  # - Process one play per iteration in the recursive method\n",
        "  idx = df_kickoff_plays.index[0]\n",
        "  play = df_plays['PlayDescription'].loc[idx]\n",
        "\n",
        "  ############\n",
        "  # REVERSES #\n",
        "  ############\n",
        "\n",
        "  # In 'PlayDescription' all information before the \"reversed\" sentence is not needed.\n",
        "  # - All information before is stored within 'ReverseDetails' and the remaining is cleaned.\n",
        "  if play.find('REVERSED') != -1:\n",
        "    play_elements = play.split(\". \")\n",
        "    for i in play_elements:\n",
        "      if i.find(\"REVERSED\") != -1:\n",
        "        df_plays.at[idx, 'ReverseDetails'] = play_elements[:play_elements.index(i) + 1]\n",
        "        play = \". \".join(play_elements[play_elements.index(i) + 1:])\n",
        "        break\n",
        "\n",
        "  ###########\n",
        "  # FUMBLES #\n",
        "  ###########\n",
        "\n",
        "  if play.find('FUMBLES') != -1:\n",
        "    main_action_patterns = [kickoff_pattern, kick_return_pattern, defensive_takeaway_run_pattern, handoff_pattern]\n",
        "    main_cleaning_method = clean_kickoff_plays\n",
        "    df_replacement_rows = extract_fumble_data(df_plays, play, idx,\n",
        "                                              main_action_patterns,\n",
        "                                              main_cleaning_method)\n",
        "\n",
        "    df_before = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "    df_after = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "    df_plays = pd.concat([df_before, df_replacement_rows, df_after], ignore_index=True)\n",
        "    index_of_last_added_row = idx + len(df_replacement_rows) - 1\n",
        "\n",
        "    # returning row after the last index\n",
        "    if df_kickoff_plays.tail(1).index.tolist()[0] == idx:\n",
        "      return df_plays\n",
        "    else:\n",
        "      return clean_run_plays(df_plays, index_of_last_added_row + 1)\n",
        "\n",
        "  # Create 2 single row dataframes.\n",
        "  # 1. The Kickoff\n",
        "  df_kickoff = df_plays.loc[idx].copy()\n",
        "  df_kickoff = pd.DataFrame([df_kickoff], columns=df_plays.columns)\n",
        "  df_kickoff.reset_index(drop=True, inplace=True)\n",
        "  df_kickoff['PlayDescription'] = 'nan'\n",
        "  # 2. The Kickoff Return\n",
        "  df_kickoff_return = df_plays.loc[idx].copy()\n",
        "  df_kickoff_return = pd.DataFrame([df_kickoff_return], columns=df_plays.columns)\n",
        "  df_kickoff_return.reset_index(drop=True, inplace=True)\n",
        "  df_kickoff_return['PlayDescription'] = 'nan'\n",
        "\n",
        "  # break down play by sentences.\n",
        "  play_elements = play.split(\". \")\n",
        "\n",
        "  accepted_penalties = []\n",
        "  declined_penalties = []\n",
        "\n",
        "  for i in play_elements:\n",
        "\n",
        "    ###########\n",
        "    # KICKOFF #\n",
        "    ###########\n",
        "\n",
        "    kickoff = re.findall(kickoff_pattern, i)\n",
        "    if len(kickoff) > 0:\n",
        "      df_kickoff['PlayType'] = 'Kickoff'\n",
        "      df_kickoff['PlayDescription'] = i\n",
        "      df_kickoff['Kicker'] = kickoff[0][0]\n",
        "      df_kickoff['Yardage'] = int(kickoff[0][1])\n",
        "      if i.find('Touchback') != -1:\n",
        "        df_kickoff['PlayOutcome'] = 'Touchback'\n",
        "        continue\n",
        "      # I need to figure out what the difference will be when the kicking team recovers\n",
        "      if i.find('onside') != -1:\n",
        "        df_kickoff['PlayOutcome'] = 'onside'\n",
        "        downed_by = re.findall(kick_downed_by_pattern, i)\n",
        "        if len(downed_by) > 0:\n",
        "          df_kickoff['DownedBy'] = downed_by[0][downed_by[0].find(\"-\")+1:]\n",
        "        continue\n",
        "      continue\n",
        "\n",
        "    #########################################\n",
        "    # KICKOFF RETURN (Including touchdowns) #\n",
        "    #########################################\n",
        "\n",
        "    kick_return_patterns = [kick_return_pattern, touchdown_after_takeaway_pattern]\n",
        "    for return_pattern in kick_return_patterns:\n",
        "      kick_return = re.findall(return_pattern, i)\n",
        "      if len(kick_return) > 0:\n",
        "        df_kickoff_return['PlayDescription'] = i\n",
        "        df_kickoff_return['PlayOutcome'] = 'Run'\n",
        "        df_kickoff_return = clean_run_plays(df_kickoff_return)\n",
        "        df_kickoff_return['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "        df_kickoff_return['PlayType'] = 'Kickoff Return'\n",
        "        df_kickoff_return['Rusher'] = 'nan'\n",
        "        df_kickoff_return['Returner'] = kick_return[0][0] # I think this will be a problem once I get a dataset with kick return touchdowns\n",
        "        break\n",
        "\n",
        "    #############\n",
        "    #  PENALTY  #\n",
        "    #############\n",
        "\n",
        "    # Accepted Penalty\n",
        "    if i.find('PENALTY') != -1:\n",
        "      accepted_penalties.append(i)\n",
        "\n",
        "    # Declined Penalty\n",
        "    if i.find('Penalty') != -1:\n",
        "      declined_penalties.append(i)\n",
        "\n",
        "    # If playoutcome is the same as the original play, then run second sentence through\n",
        "    # run cleaning method.\n",
        "\n",
        "  if len(accepted_penalties) > 0:\n",
        "    df_kickoff.at[0, 'AcceptedPenalty'] = accepted_penalties\n",
        "  if len(declined_penalties) > 0:\n",
        "    df_kickoff.at[0, 'DeclinedPenalty'] = declined_penalties\n",
        "\n",
        "  #############################\n",
        "  # NEW REPLACEMENT DATAFRAME #\n",
        "  #############################\n",
        "\n",
        "  if df_kickoff_return['PlayDescription'].iloc[0] == 'nan':\n",
        "    df_replacement_rows = df_kickoff\n",
        "  else:\n",
        "    df_replacement_rows = pd.concat([df_kickoff, df_kickoff_return], ignore_index=True)\n",
        "\n",
        "  df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "  df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "  df_plays = pd.concat([df_before_row, df_replacement_rows, df_after_row], ignore_index=True)\n",
        "\n",
        "  if df_kickoff_plays.tail(1).index.tolist()[0] == idx:\n",
        "    return df_plays\n",
        "  else:\n",
        "    return clean_kickoff_plays(df_plays, idx+len(df_replacement_rows))"
      ],
      "metadata": {
        "id": "2EPzUDaYZl35"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SCORING CLEANING METHODS"
      ],
      "metadata": {
        "id": "xdlQ00Gxr216"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TOUCHDOWNS"
      ],
      "metadata": {
        "id": "5B4OEwz2AwnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Still need to figure out whether or not plays that have multiple rows will all have\n",
        "# 'IsScoringDrive' = 1, 'IsScoringDrive' = 1, 'PlayOutcome' = *teamname* Touchdown\n",
        "# - The reasoning to not have this is because if a qb was to throw a pick 6,\n",
        "#   it wouldn't count as a \"Scoring Drive\" for them but the opposing team.\n",
        "# - For consistency, I will have the entire play have\n",
        "#   'IsScoringDrive' = 1, 'IsScoringDrive' = 1, 'PlayOutcome' = *teamname* Touchdown\n",
        "# - Need larger dataset to include all other touchdown plays such as kickoff returns and field goal returns\n",
        "\n",
        "def clean_touchdown_plays(df_plays, index_start=None):\n",
        "\n",
        "  # Cut 'df_plays' to begin from 'index_start' to the last touchdown play available in dataframe\n",
        "  if index_start != None:\n",
        "    df_plays_adjusted = df_plays.loc[index_start:]\n",
        "    df_touchdown_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('Touchdown')]\n",
        "  else:\n",
        "    df_touchdown_plays = df_plays[df_plays['PlayOutcome'].str.contains('Touchdown')]\n",
        "\n",
        "  # Iterating through every touchdown play within 'df_touchdown_plays'\n",
        "  for idx, play in df_touchdown_plays['PlayDescription'].items():\n",
        "\n",
        "    # - Once i figure out what kind of touchdown it was, then I will be able to\n",
        "    #   determine the 'PlayType'\n",
        "\n",
        "    ######################\n",
        "    # PASSING TOUCHDOWNS #\n",
        "    ######################\n",
        "\n",
        "    # If a play has a passer throwing the ball, I am assuming it is a passing play\n",
        "    passing_play = re.findall(passer_name_pattern, play)\n",
        "    if len(passing_play) > 0 and play.find(\"sacked\") == -1 and play.find(\"INTERCEPTED\") == -1:\n",
        "\n",
        "      # creating a copy of the passing touchdown play row and cleaning the copy\n",
        "      passing_touchdown_row = df_plays.loc[idx].copy()\n",
        "      passing_touchdown_row['PlayType'] = 'Pass'\n",
        "      passing_touchdown_row['PlayOutcome'] = 'Pass'\n",
        "      passing_touchdown_row['IsScoringPlay'] = 1\n",
        "      passing_touchdown_row = pd.DataFrame([passing_touchdown_row], columns=df_plays.columns)\n",
        "      passing_touchdown_row = clean_pass_plays(passing_touchdown_row)\n",
        "      passing_touchdown_row['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "\n",
        "      # Replacing old row with cleaned row\n",
        "      df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before_row, passing_touchdown_row, df_after_row], ignore_index=True)\n",
        "\n",
        "      # Recursion to update 'df_plays'\n",
        "      if df_touchdown_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_touchdown_plays(df_plays, idx+len(passing_touchdown_row))\n",
        "\n",
        "    ######################\n",
        "    # RUSHING TOUCHDOWNS #\n",
        "    ######################\n",
        "\n",
        "    # Rusher\n",
        "    rusher_patterns = [rusher_pattern, defensive_takeaway_run_pattern]\n",
        "    # Loop through patterns and find the first match\n",
        "    for pattern in rusher_patterns:\n",
        "      rusher = re.findall(pattern, play)\n",
        "      if len(rusher) > 0:\n",
        "        # creating a copy of the rushing touchdown play row and cleaning the copy\n",
        "        rushing_touchdown_row = df_plays.loc[idx].copy()\n",
        "        rushing_touchdown_row['PlayType'] = 'Run'\n",
        "        rushing_touchdown_row['PlayOutcome'] = 'Run'\n",
        "        rushing_touchdown_row['IsScoringPlay'] = 1\n",
        "        rushing_touchdown_row = pd.DataFrame([rushing_touchdown_row], columns=df_plays.columns)\n",
        "        rushing_touchdown_row = clean_run_plays(rushing_touchdown_row)\n",
        "        rushing_touchdown_row['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "\n",
        "        # Replacing old row with cleaned row\n",
        "        df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "        df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "        df_plays = pd.concat([df_before_row, rushing_touchdown_row, df_after_row], ignore_index=True)\n",
        "\n",
        "        # Recursion to update 'df_plays'\n",
        "        if df_touchdown_plays.tail(1).index.tolist()[0] == idx:\n",
        "          return df_plays\n",
        "        else:\n",
        "          return clean_touchdown_plays(df_plays, idx+len(rushing_touchdown_row))\n",
        "\n",
        "    ##########################\n",
        "    # INTERCEPTED TOUCHDOWNS #\n",
        "    ##########################\n",
        "\n",
        "    # Still need to clean intercepted play types\n",
        "    if play.find(\"INTERCEPTED\") != -1:\n",
        "\n",
        "      # creating a copy of the incercepted touchdown play and cleaning the copy\n",
        "      intercepted_touchdown_row = df_plays.loc[idx].copy()\n",
        "      intercepted_touchdown_row['PlayOutcome'] = 'Interception'\n",
        "      intercepted_touchdown_row['IsScoringPlay'] = 1 # This will only be the value for the team that threw the interception\n",
        "      intercepted_touchdown_row = pd.DataFrame([intercepted_touchdown_row], columns=df_plays.columns)\n",
        "      intercepted_touchdown_row.reset_index(drop=True, inplace=True)\n",
        "      intercepted_touchdown_row = clean_intercepted_plays(intercepted_touchdown_row)\n",
        "      intercepted_touchdown_row['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "\n",
        "      #################################################################################################### Under Construction\n",
        "      # Change feature 'TeamWithPossession' for each play in drive\n",
        "      # - Raw data states that the team that intercepted the ball for a touchdown had possession for each play\n",
        "      #   within drive. The correct value for this feature for each play in drive is the team that threw\n",
        "      #   the interception.\n",
        "\n",
        "      wrong_team_with_possession = df_plays['TeamWithPossession'].loc[idx]\n",
        "      if wrong_team_with_possession == dict_teams.get(df_plays['HomeTeam'].loc[idx]):\n",
        "        correct_team_with_possession = dict_teams.get(df_plays['AwayTeam'].loc[idx])\n",
        "      else:\n",
        "        correct_team_with_possession = dict_teams.get(df_plays['HomeTeam'].loc[idx])\n",
        "\n",
        "      # HERE I NEED TO CHANGE ALL 'TEAMWITHPOSSESSION' FEATURES FOR EVERY PLAY IN DRIVE\n",
        "      # I need to figure out how to efficiently grab every play in drive.\n",
        "      intercepted_touchdown_row['TeamWithPossession'] = correct_team_with_possession\n",
        "      conditions_for_unique_drive = ((df_plays['Season'] == df_plays['Season'].loc[idx]) &\n",
        "      (df_plays['Week'] == df_plays['Week'].loc[idx]) &\n",
        "      (df_plays['AwayTeam'] == df_plays['AwayTeam'].loc[idx]) &\n",
        "      (df_plays['HomeTeam'] == df_plays['HomeTeam'].loc[idx]) &\n",
        "      (df_plays['Quarter'] == df_plays['Quarter'].loc[idx]) &\n",
        "      (df_plays['DriveNumber'] == df_plays['DriveNumber'].loc[idx]))\n",
        "\n",
        "      df_plays.loc[conditions_for_unique_drive, 'TeamWithPossession'] = correct_team_with_possession\n",
        "\n",
        "      ####################################################################################################\n",
        "\n",
        "      # Replacing old row with cleaned row\n",
        "      df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before_row, intercepted_touchdown_row, df_after_row], ignore_index=True)\n",
        "\n",
        "      # Recursion to update 'df_plays'\n",
        "      if df_touchdown_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_touchdown_plays(df_plays, idx+len(intercepted_touchdown_row))\n",
        "\n",
        "    #####################################\n",
        "    # SACKED FUMBLE RECOVERY TOUCHDOWNS #\n",
        "    #####################################\n",
        "\n",
        "    if play.find(\"sacked\") != -1:\n",
        "      # print(idx)\n",
        "\n",
        "      # creating a copy of the sack touchdown play and cleaning the copy\n",
        "      sacked_touchdown_row = df_plays.loc[idx].copy()\n",
        "      sacked_touchdown_row['PlayOutcome'] = 'Sack'\n",
        "      sacked_touchdown_row['IsScoringPlay'] = 1\n",
        "      sacked_touchdown_row = pd.DataFrame([sacked_touchdown_row], columns=df_plays.columns)\n",
        "      sacked_touchdown_row.reset_index(drop=True, inplace=True)\n",
        "      sacked_touchdown_row = clean_sacked_plays(sacked_touchdown_row)\n",
        "      sacked_touchdown_row['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "\n",
        "      #################################################################################################### Under Construction\n",
        "      # Change feature 'TeamWithPossession' for each play in drive\n",
        "      # - Raw data states that the team that recovered the ball for a touchdown had possession for each play\n",
        "      #   within drive. The correct value for this feature for each play in drive is the team that fumbled.\n",
        "\n",
        "      wrong_team_with_possession = df_plays['TeamWithPossession'].loc[idx]\n",
        "      if wrong_team_with_possession == dict_teams.get(df_plays['HomeTeam'].loc[idx]):\n",
        "        correct_team_with_possession = dict_teams.get(df_plays['AwayTeam'].loc[idx])\n",
        "      else:\n",
        "        correct_team_with_possession = dict_teams.get(df_plays['HomeTeam'].loc[idx])\n",
        "\n",
        "      # HERE I NEED TO CHANGE ALL 'TEAMWITHPOSSESSION' FEATURES FOR EVERY PLAY IN DRIVE\n",
        "      # I need to figure out how to efficiently grab every play in drive.\n",
        "      sacked_touchdown_row['TeamWithPossession'] = correct_team_with_possession\n",
        "      conditions_for_unique_drive = ((df_plays['Season'] == df_plays['Season'].loc[idx]) &\n",
        "      (df_plays['Week'] == df_plays['Week'].loc[idx]) &\n",
        "      (df_plays['AwayTeam'] == df_plays['AwayTeam'].loc[idx]) &\n",
        "      (df_plays['HomeTeam'] == df_plays['HomeTeam'].loc[idx]) &\n",
        "      (df_plays['Quarter'] == df_plays['Quarter'].loc[idx]) &\n",
        "      (df_plays['DriveNumber'] == df_plays['DriveNumber'].loc[idx]))\n",
        "\n",
        "      df_plays.loc[conditions_for_unique_drive, 'TeamWithPossession'] = correct_team_with_possession\n",
        "\n",
        "      ####################################################################################################\n",
        "\n",
        "      # Replacing old row with cleaned row (Original row can sometimes be replaced with multiple rows)\n",
        "      df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before_row, sacked_touchdown_row, df_after_row], ignore_index=True)\n",
        "\n",
        "      # Recursion to update 'df_plays'\n",
        "      if df_touchdown_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_touchdown_plays(df_plays, idx+len(sacked_touchdown_row))\n",
        "\n",
        "    ##########################\n",
        "    # PUNT RETURN TOUCHDOWNS #\n",
        "    ##########################\n",
        "\n",
        "    punt_play = re.findall(punting_pattern, play)\n",
        "    if len(punt_play) > 0:\n",
        "\n",
        "      # creating a copy of the punt touchdown play and cleaning the copy\n",
        "      punt_touchdown_row = df_plays.loc[idx].copy()\n",
        "      punt_touchdown_row['PlayOutcome'] = 'Punt'\n",
        "      punt_touchdown_row['IsScoringPlay'] = 1 # This will only be the value for the team that punted the ball\n",
        "      punt_touchdown_row = pd.DataFrame([punt_touchdown_row], columns=df_plays.columns)\n",
        "      punt_touchdown_row.reset_index(drop=True, inplace=True)\n",
        "      punt_touchdown_row = clean_punt_plays(punt_touchdown_row)\n",
        "      punt_touchdown_row['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "\n",
        "      # Replacing old row with cleaned row\n",
        "      df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before_row, punt_touchdown_row, df_after_row], ignore_index=True)\n",
        "\n",
        "      # Recursion to update 'df_plays'\n",
        "      if df_touchdown_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_touchdown_plays(df_plays, idx+len(punt_touchdown_row))\n",
        "\n",
        "    #################################\n",
        "    # BLOCKED FIELD GOAL TOUCHDOWNS #\n",
        "    #################################\n",
        "\n",
        "    field_goal_blocked = re.findall(field_goal_blocked_pattern, play)\n",
        "    if len(field_goal_blocked) > 0:\n",
        "      print(idx)\n",
        "\n",
        "      # creating a copy of recovered blocked field goal touchdown play and cleaning the copy\n",
        "      blocked_fg_touchdown_row = df_plays.loc[idx].copy()\n",
        "      blocked_fg_touchdown_row['PlayOutcome'] = 'Field Goal'\n",
        "      blocked_fg_touchdown_row['IsScoringPlay'] = 1 # This will only be the value for the team that attempted the field goal\n",
        "      blocked_fg_touchdown_row = pd.DataFrame([blocked_fg_touchdown_row], columns=df_plays.columns)\n",
        "      blocked_fg_touchdown_row.reset_index(drop=True, inplace=True)\n",
        "      blocked_fg_touchdown_row = clean_field_goal_plays(blocked_fg_touchdown_row)\n",
        "      blocked_fg_touchdown_row['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "\n",
        "      #################################################################################################### Under Construction\n",
        "      # Change feature 'TeamWithPossession' for each play in drive\n",
        "      # - Raw data states that the team that blocked the field goal attempt and recovered for a touchdown had possession for each play\n",
        "      #   within drive. The correct value for this feature for each play in drive is the team that threw\n",
        "      #   the interception.\n",
        "\n",
        "      wrong_team_with_possession = df_plays['TeamWithPossession'].loc[idx]\n",
        "      if wrong_team_with_possession == dict_teams.get(df_plays['HomeTeam'].loc[idx]):\n",
        "        correct_team_with_possession = dict_teams.get(df_plays['AwayTeam'].loc[idx])\n",
        "      else:\n",
        "        correct_team_with_possession = dict_teams.get(df_plays['HomeTeam'].loc[idx])\n",
        "\n",
        "      # HERE I NEED TO CHANGE ALL 'TEAMWITHPOSSESSION' FEATURES FOR EVERY PLAY IN DRIVE\n",
        "      # I need to figure out how to efficiently grab every play in drive.\n",
        "      blocked_fg_touchdown_row['TeamWithPossession'] = correct_team_with_possession\n",
        "      conditions_for_unique_drive = ((df_plays['Season'] == df_plays['Season'].loc[idx]) &\n",
        "      (df_plays['Week'] == df_plays['Week'].loc[idx]) &\n",
        "      (df_plays['AwayTeam'] == df_plays['AwayTeam'].loc[idx]) &\n",
        "      (df_plays['HomeTeam'] == df_plays['HomeTeam'].loc[idx]) &\n",
        "      (df_plays['Quarter'] == df_plays['Quarter'].loc[idx]) &\n",
        "      (df_plays['DriveNumber'] == df_plays['DriveNumber'].loc[idx]))\n",
        "\n",
        "      df_plays.loc[conditions_for_unique_drive, 'TeamWithPossession'] = correct_team_with_possession\n",
        "\n",
        "      ####################################################################################################\n",
        "\n",
        "      # Replacing old row with cleaned row\n",
        "      df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before_row, blocked_fg_touchdown_row, df_after_row], ignore_index=True)\n",
        "\n",
        "      # Recursion to update 'df_plays'\n",
        "      if df_touchdown_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_touchdown_plays(df_plays, idx+len(blocked_fg_touchdown_row))"
      ],
      "metadata": {
        "id": "GjW0FNUyOSVx"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### FIELD GOALS"
      ],
      "metadata": {
        "id": "5TZ3ncsLtBrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I need an example of when a player returns the field goal for yardage\n",
        "# I need a larger sample size for \"Blocked\" field goals\n",
        "# I need to figure out what to do if someone fumbles a recovery\n",
        "# I need to figure out what to do on a trick play (e.i. holder runs out with the ball)\n",
        "# - INCOMPLETE. NEED LARGER SAMPLE SIZE\n",
        "\n",
        "def clean_field_goal_plays(df_plays, index_start = None):\n",
        "\n",
        "  # Adjusting df_plays to start cleaning at a specified index (index_start)\n",
        "  if index_start != None:\n",
        "    df_plays_adjusted = df_plays.loc[index_start:]\n",
        "    # Locating all field goal plays within dataframe\n",
        "    df_field_goal_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('Field Goal')]\n",
        "  else:\n",
        "    # Locating all field goal plays within dataframe\n",
        "    df_field_goal_plays = df_plays[df_plays['PlayOutcome'].str.contains('Field Goal')]\n",
        "\n",
        "  for idx, play in df_field_goal_plays['PlayDescription'].items():\n",
        "\n",
        "    play_elements = play.split(\". \")\n",
        "\n",
        "    ###################\n",
        "    # EXTRA PLAY DATA #\n",
        "    ###################\n",
        "\n",
        "    # I may have the change this later.\n",
        "    # I think I will have to move this towards the end.\n",
        "\n",
        "    if len(play_elements) > 1:\n",
        "\n",
        "      accepted_penalties = []\n",
        "      declined_penalties = []\n",
        "      injured_players = []\n",
        "\n",
        "      for i in play_elements:\n",
        "\n",
        "        # Accepted Penalty\n",
        "        if i.find('PENALTY') != -1:\n",
        "          accepted_penalties.append(i)\n",
        "\n",
        "        # Declined Penalty\n",
        "        if i.find('Penalty') != -1:\n",
        "          declined_penalties.append(i)\n",
        "\n",
        "        # Injuries\n",
        "        injury_on_play = re.findall(injury_pattern, i)\n",
        "        if len(injury_on_play) > 0:\n",
        "          injured_players.append(injury_on_play[0])\n",
        "\n",
        "      if len(accepted_penalties) > 0:\n",
        "        df_plays.at[idx, 'AcceptedPenalty'] = accepted_penalties\n",
        "      if len(declined_penalties) > 0:\n",
        "        df_plays.at[idx, 'DeclinedPenalty'] = declined_penalties\n",
        "      if len(injured_players) > 0:\n",
        "        df_plays.at[idx, 'InjuredPlayers'] = injured_players\n",
        "\n",
        "    # Time of play\n",
        "    time_on_clock = re.findall(time_on_clock_pattern, play)\n",
        "    if len(time_on_clock) > 0:\n",
        "      df_plays.loc[idx, 'TimeOnTheClock'] = time_on_clock[0]\n",
        "\n",
        "    #########################\n",
        "    # FIELD GOAL SITUATIONS #\n",
        "    #########################\n",
        "\n",
        "    # Field goal good\n",
        "    field_goal_good = re.findall(field_goal_good_pattern, play)\n",
        "    if len(field_goal_good) > 0:\n",
        "      df_plays.loc[idx, 'PlayOutcome'] = 'Field Goal Good'\n",
        "      df_plays.loc[idx, 'PlayType'] = 'Field Goal'\n",
        "      df_plays.loc[idx, 'Kicker'] = field_goal_good[0][0]\n",
        "      df_plays.loc[idx, 'Yardage'] = int(field_goal_good[0][1])\n",
        "      df_plays.loc[idx, 'LongSnapper'] = field_goal_good[0][2]\n",
        "      df_plays.loc[idx, 'Holder'] = field_goal_good[0][3]\n",
        "      continue\n",
        "\n",
        "    # Field goal no good\n",
        "    field_goal_no_good = re.findall(field_goal_no_good_pattern, play)\n",
        "    if len(field_goal_no_good) > 0:\n",
        "      df_plays.loc[idx, 'PlayOutcome'] = 'Field Goal No Good'\n",
        "      df_plays.loc[idx, 'PlayType'] = 'Field Goal'\n",
        "      df_plays.loc[idx, 'Kicker'] = field_goal_no_good[0][0]\n",
        "      df_plays.loc[idx, 'Yardage'] = int(field_goal_no_good[0][1])\n",
        "      df_plays.loc[idx, 'Direction'] = field_goal_no_good[0][2]\n",
        "      df_plays.loc[idx, 'LongSnapper'] = field_goal_no_good[0][3]\n",
        "      df_plays.loc[idx, 'Holder'] = field_goal_no_good[0][4]\n",
        "      continue\n",
        "\n",
        "    # - Going to treat this as a fumble. Will use helper method 'extract_fumble_data'\n",
        "    # - Should I create a feature for those who recovered the ball?\n",
        "\n",
        "    # Field goal blocked\n",
        "    # I NEED A LARGER SAMPLE SIZE TO CORRECTLY CLEAN THESE\n",
        "    field_goal_blocked = re.findall(field_goal_blocked_pattern, play)\n",
        "    if len(field_goal_blocked) > 0:\n",
        "\n",
        "      # What should I do here?\n",
        "      # - Should I clean the main play here and send everything else\n",
        "      #   to the fumble helper method?\n",
        "      #   - I think I am going to try this. I think it will work.\n",
        "      # - I will have to grab all sentences leading up to main field goal sentence.\n",
        "      # - I will have to grab all sentences after and send them to the fumble helper method.\n",
        "      #   - main_cleaning_method parameter will be the clean_run_plays.\n",
        "\n",
        "      # 1. check to see if play has more than 1 sentence.\n",
        "      # 2. create if statement (if more than 1):\n",
        "      #    a. find where initial field goal attempt is\n",
        "      #    b. wrap all sentences following initial field goal attempt together.\n",
        "      #    c. clean wrapped sentence together using 'extract_fumble_data'\n",
        "      #       - use 'clean_run_plays' method for this.\n",
        "      #    NOTE: at this point, we should now have the back half of the play cleaned\n",
        "      #          and inside a df. We now need to clean the front half and attach to\n",
        "      #          the back half and replace original play df row with this new df set of rows.\n",
        "      #           - Maybe I can replace the contents of the original row and add the cleaned back half?\n",
        "      #             - I like this idea.\n",
        "\n",
        "      # STEPS:\n",
        "      # 1. if play is multiple sentences (after field goal attempt?)\n",
        "      #    a. find all sentences following the sentence explaining field goal attempt.\n",
        "      #    b. clean back half of play\n",
        "      #    c. add cleaned back half to original df of plays (after original play)\n",
        "      # 2. clean first half of play (replace original play row)\n",
        "      #    - I think I have to clean first half of play first.\n",
        "\n",
        "      # I think I will only use \"extract fumble data\" if there is actually a fumble\n",
        "      # - I think I should use \"clean_fumble_run\" data to clean a normal recovery for yardage or touchdown.\n",
        "\n",
        "      # GOALS:\n",
        "      # - Clean normal attempted field goal that was blocked\n",
        "      # - create split for recovery for yardage\n",
        "      #   - regular yardage\n",
        "      #   - yardage for touchdown\n",
        "      # - check for fumbles here?\n",
        "\n",
        "      # STEPS:\n",
        "      # 1. separate play\n",
        "      #    a. field goal attempt that was blocked\n",
        "      #       - I think I may want extra data here? such as penalties and injuries?\n",
        "      #    b. everything that follows after (should only be 1 sentence without fumble or handoff)\n",
        "      # 2. if there is more than the field goal attempt:\n",
        "      #    - isolate field goal attempt\n",
        "      #      - clean field goal attempt here?\n",
        "      #    - clean yardage after recovery\n",
        "      #      - should i look for fumbles here?\n",
        "      #    - combine cleaned actions\n",
        "      #    - put into original plays dataframe\n",
        "      #    - recursion from there\n",
        "      # 3. clean field goal attempt\n",
        "\n",
        "      # Need to locate field goal attempt within play description\n",
        "      play_elements = play.split(\". \")\n",
        "      if len(play_elements) > 1:\n",
        "        for i in play_elements:\n",
        "          # Locating which sentence contains the field goal attempt\n",
        "          field_goal_blocked = re.findall(field_goal_blocked_pattern, i)\n",
        "          if len(field_goal_blocked) > 0:\n",
        "            # Grabbing field goal attempt that was blocked\n",
        "            field_goal_attempt = i\n",
        "\n",
        "            # Grabbing all actions that followed the field goal attempt (should be things such as recovery for yardage, fumbles, recovery for touchdown, etc.)\n",
        "            field_goal_blocked_recovery_actions = play_elements[play_elements.index(i)+1::]\n",
        "            field_goal_blocked_recovery_actions = \". \".join(field_goal_blocked_recovery_actions)\n",
        "\n",
        "            # create empty dataframe with recovery data as 'PlayDescription'\n",
        "            # - probably should make this a copy of the original play to keep consistent\n",
        "            df_recovery_yardage_rows = df_plays.loc[idx].copy()\n",
        "            df_recovery_yardage_rows['PlayDescription'] = field_goal_blocked_recovery_actions\n",
        "            df_recovery_yardage_rows['PlayOutcome'] = 'Run'\n",
        "            df_recovery_yardage_rows = clean_run_plays(df_recovery_yardage_rows)\n",
        "\n",
        "\n",
        "            # LEFT OFF HERE.\n",
        "\n",
        "\n",
        "            # combine cleaned actions\n",
        "            # put into original plays dataframe\n",
        "            # recursion\n",
        "            df_before = df_plays.iloc[:df_plays.index.tolist().index(idx)+1]\n",
        "            df_after = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "            df_plays = pd.concat([df_before, df_add_on_rows, df_after], ignore_index=True)\n",
        "            index_of_last_added_row = idx + len(df_add_on_rows)\n",
        "\n",
        "            if df_field_goal_plays.tail(1).index.tolist()[0] == idx:\n",
        "              return df_plays\n",
        "            else:\n",
        "              return clean_field_goal_plays(df_plays, index_of_last_added_row + 1)\n",
        "\n",
        "            break\n",
        "\n",
        "      # if play.lower().find('recovered') != -1:\n",
        "      #   main_action_patterns = [field_goal_blocked_pattern, defensive_takeaway_run_pattern, touchdown_after_takeaway_pattern]\n",
        "      #   main_cleaning_method = clean_field_goal_plays\n",
        "      #   df_replacement_rows = extract_fumble_data(df_plays, play, idx,\n",
        "      #                                             main_action_patterns,\n",
        "      #                                             main_cleaning_method)\n",
        "\n",
        "\n",
        "      #   # Use this when initial play and following actions have been cleaned.\n",
        "      #   df_before = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      #   df_after = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      #   df_plays = pd.concat([df_before, df_replacement_rows, df_after], ignore_index=True)\n",
        "      #   index_of_last_added_row = idx + len(df_replacement_rows) - 1\n",
        "\n",
        "        if df_field_goal_plays.tail(1).index.tolist()[0] == idx:\n",
        "          return df_plays\n",
        "        else:\n",
        "          return clean_field_goal_plays(df_plays, index_of_last_added_row + 1)\n",
        "\n",
        "      df_plays.loc[idx, 'PlayOutcome'] = 'Field Goal Blocked'\n",
        "      df_plays.loc[idx, 'PlayType'] = 'Field Goal'\n",
        "      df_plays.loc[idx, 'Kicker'] = field_goal_blocked[0][0]\n",
        "      df_plays.loc[idx, 'Yardage'] = int(field_goal_blocked[0][1])\n",
        "      df_plays.loc[idx, 'BlockedBy'] = field_goal_blocked[0][2]\n",
        "      df_plays.loc[idx, 'LongSnapper'] = field_goal_blocked[0][3]\n",
        "      df_plays.loc[idx, 'Holder'] = field_goal_blocked[0][4]\n",
        "      continue\n",
        "\n",
        "  return df_plays"
      ],
      "metadata": {
        "id": "VnHezsPttNG0"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####EXTRA POINT"
      ],
      "metadata": {
        "id": "dhsLNvcBA9uW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_extra_point_plays(df_plays, index_start = None):\n",
        "\n",
        "  # Adjusting df_plays to start cleaning at a specified index (index_start)\n",
        "  if index_start != None:\n",
        "    df_plays_adjusted = df_plays.loc[index_start:]\n",
        "    # Locating all extra point plays within dataframe\n",
        "    df_extra_point_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('Extra Point')]\n",
        "  else:\n",
        "    # Locating all extra point plays within dataframe\n",
        "    df_field_goal_plays = df_plays[df_plays['PlayOutcome'].str.contains('Extra Point')]\n",
        "\n",
        "  for idx, play in df_field_goal_plays['PlayDescription'].items():\n",
        "\n",
        "    play_elements = play.split(\". \")\n",
        "\n",
        "    ###################\n",
        "    # EXTRA PLAY DATA #\n",
        "    ###################\n",
        "\n",
        "    if len(play_elements) > 1:\n",
        "\n",
        "      accepted_penalties = []\n",
        "      declined_penalties = []\n",
        "      injured_players = []\n",
        "\n",
        "      for i in play_elements:\n",
        "\n",
        "        # Accepted Penalty\n",
        "        if i.find('PENALTY') != -1:\n",
        "          accepted_penalties.append(i)\n",
        "\n",
        "        # Declined Penalty\n",
        "        if i.find('Penalty') != -1:\n",
        "          declined_penalties.append(i)\n",
        "\n",
        "        # Injuries\n",
        "        injury_on_play = re.findall(injury_pattern, i)\n",
        "        if len(injury_on_play) > 0:\n",
        "          injured_players.append(injury_on_play[0])\n",
        "\n",
        "      if len(accepted_penalties) > 0:\n",
        "        df_plays.at[idx, 'AcceptedPenalty'] = accepted_penalties\n",
        "      if len(declined_penalties) > 0:\n",
        "        df_plays.at[idx, 'DeclinedPenalty'] = declined_penalties\n",
        "      if len(injured_players) > 0:\n",
        "        df_plays.at[idx, 'InjuredPlayers'] = injured_players\n",
        "\n",
        "    ##########################\n",
        "    # EXTRA POINT SITUATIONS #\n",
        "    ##########################\n",
        "\n",
        "    # Extra point good\n",
        "    extra_point_good = re.findall(extra_point_good_pattern, play)\n",
        "    if len(extra_point_good) > 0:\n",
        "      df_plays.loc[idx, 'PlayOutcome'] = 'Extra Point Good'\n",
        "      df_plays.loc[idx, 'PlayType'] = 'Extra Point'\n",
        "      df_plays.loc[idx, 'Kicker'] = extra_point_good[0][0]\n",
        "      df_plays.loc[idx, 'LongSnapper'] = extra_point_good[0][1]\n",
        "      df_plays.loc[idx, 'Holder'] = extra_point_good[0][2]\n",
        "      continue\n",
        "\n",
        "    # Extra point no good\n",
        "    extra_point_no_good = re.findall(extra_point_no_good_pattern, play)\n",
        "    if len(extra_point_no_good) > 0:\n",
        "      df_plays.loc[idx, 'PlayOutcome'] = 'Extra Point No Good'\n",
        "      df_plays.loc[idx, 'PlayType'] = 'Extra Point'\n",
        "      df_plays.loc[idx, 'Kicker'] = extra_point_no_good[0][0]\n",
        "      df_plays.loc[idx, 'Direction'] = extra_point_no_good[0][1]\n",
        "      df_plays.loc[idx, 'LongSnapper'] = extra_point_no_good[0][2]\n",
        "      df_plays.loc[idx, 'Holder'] = extra_point_no_good[0][3]\n",
        "      continue\n",
        "\n",
        "  return df_plays"
      ],
      "metadata": {
        "id": "GfgZ5xQTA9B2"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###OTHER CLEANING METHODS"
      ],
      "metadata": {
        "id": "I_uTKSIZsZDi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### FUMBLE PLAYS"
      ],
      "metadata": {
        "id": "9A1yQxl0kmLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What about punt returns?\n",
        "# Might need more data on 'Aborted' fumbled plays. Currently it does not show who fumbled the ball.\n",
        "\n",
        "def clean_fumble_plays(df_plays, index_start=None):\n",
        "\n",
        "  # Cut 'df_plays' to begin from 'index_start' to the last penalty play available in dataframe\n",
        "  if index_start != None:\n",
        "    df_plays_adjusted = df_plays.loc[index_start:]\n",
        "    df_fumble_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('fumble', case=False)]\n",
        "  else:\n",
        "    df_fumble_plays = df_plays[df_plays['PlayOutcome'].str.contains('fumble', case=False)]\n",
        "\n",
        "  for idx, play in df_fumble_plays['PlayDescription'].items():\n",
        "\n",
        "    ############\n",
        "    # REVERSES #\n",
        "    ############\n",
        "\n",
        "    # In 'PlayDescription' all information before the \"reversed\" sentence is not needed.\n",
        "    # - All information before is stored within 'ReverseDetails' and the remaining is cleaned.\n",
        "    if play.find('REVERSED') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      for i in play_elements:\n",
        "        if i.find(\"REVERSED\") != -1:\n",
        "          df_plays.at[idx, 'ReverseDetails'] = play_elements[:play_elements.index(i) + 1]\n",
        "          play = \". \".join(play_elements[play_elements.index(i) + 1:])\n",
        "          break\n",
        "\n",
        "    ############################\n",
        "    # REPORTING IN AS ELIGIBLE #\n",
        "    ############################\n",
        "\n",
        "    # I do not think this contains any useful data so I am going to exclude it.\n",
        "    if play.find('reported in as eligible') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      for i in play_elements:\n",
        "        if i.find('reported in as eligible') != -1:\n",
        "          play = \". \".join(play_elements[play_elements.index(i) + 1:])\n",
        "          break\n",
        "\n",
        "    initial_action = play.split(\". \")[0]\n",
        "\n",
        "    ##################\n",
        "    # PASSING FUMBLE #\n",
        "    ##################\n",
        "\n",
        "    fumble_pass = re.findall(receiver_pattern, initial_action)\n",
        "    if len(fumble_pass) > 0:\n",
        "\n",
        "      # creating a copy of the passing fumbled play row and cleaning the copy\n",
        "      passing_fumble_row = df_plays.loc[idx].copy()\n",
        "      passing_fumble_row['PlayOutcome'] = 'Pass'\n",
        "      passing_fumble_row = pd.DataFrame([passing_fumble_row], columns=df_plays.columns)\n",
        "      passing_fumble_row = clean_pass_plays(passing_fumble_row)\n",
        "      # passing_fumble_row['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "\n",
        "      # Record whether the pass was complete or incomplete.\n",
        "      if play.find('pass incomplete') != -1:\n",
        "        passing_fumble_row['PlayOutcome'] = f\"{df_plays['PlayOutcome'].loc[idx]} (I)\"\n",
        "      else:\n",
        "        passing_fumble_row['PlayOutcome'] = f\"{df_plays['PlayOutcome'].loc[idx]} (C)\"\n",
        "\n",
        "      # Replacing old row with cleaned row\n",
        "      df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before_row, passing_fumble_row, df_after_row], ignore_index=True)\n",
        "\n",
        "      # Recursion to update 'df_plays'\n",
        "      if df_fumble_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_fumble_plays(df_plays, idx+len(passing_fumble_row))\n",
        "\n",
        "    ##################\n",
        "    # RUSHING FUMBLE #\n",
        "    ##################\n",
        "\n",
        "    fumble_rush = re.findall(rusher_pattern, initial_action)\n",
        "    qb_fumble = re.findall(qb_fumble_pattern, initial_action)\n",
        "    fumble_aborted = initial_action.find('Aborted')\n",
        "    if len(fumble_rush) > 0 or fumble_aborted != -1 or len(qb_fumble) > 0:\n",
        "\n",
        "      # creating a copy of the rushing fumbled play row and cleaning the copy\n",
        "      rushing_fumble_row = df_plays.loc[idx].copy()\n",
        "      rushing_fumble_row['PlayOutcome'] = 'Run'\n",
        "      rushing_fumble_row = pd.DataFrame([rushing_fumble_row], columns=df_plays.columns)\n",
        "      rushing_fumble_row = clean_run_plays(rushing_fumble_row)\n",
        "      rushing_fumble_row['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "\n",
        "      # Replacing old row with cleaned row\n",
        "      df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before_row, rushing_fumble_row, df_after_row], ignore_index=True)\n",
        "\n",
        "      # Recursion to update 'df_plays'\n",
        "      if df_fumble_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_fumble_plays(df_plays, idx+len(rushing_fumble_row))\n",
        "\n",
        "    #################\n",
        "    # SACKED FUMBLE #\n",
        "    #################\n",
        "\n",
        "    if initial_action.find('sacked') != -1:\n",
        "\n",
        "      # creating a copy of the sacked fumble play row and cleaning the copy\n",
        "      sacked_fumble_row = df_plays.loc[idx].copy()\n",
        "      sacked_fumble_row['PlayOutcome'] = 'Sack'\n",
        "      sacked_fumble_row = pd.DataFrame([sacked_fumble_row], columns=df_plays.columns)\n",
        "      sacked_fumble_row = clean_sacked_plays(sacked_fumble_row)\n",
        "      sacked_fumble_row['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "\n",
        "      # Replacing old row with cleaned row\n",
        "      df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before_row, sacked_fumble_row, df_after_row], ignore_index=True)\n",
        "\n",
        "      # Recursion to update 'df_plays'\n",
        "      if df_fumble_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_fumble_plays(df_plays, idx+len(sacked_fumble_row))\n",
        "\n",
        "    ##################\n",
        "    # KICKOFF FUMBLE #\n",
        "    ##################\n",
        "\n",
        "    kickoff_fumble = re.findall(kickoff_pattern, initial_action)\n",
        "    if len(kickoff_fumble) > 0:\n",
        "\n",
        "      # creating a copy of the passing fumbled play row and cleaning the copy\n",
        "      kickoff_fumble_row = df_plays.loc[idx].copy()\n",
        "      kickoff_fumble_row['PlayOutcome'] = 'kickoff'\n",
        "      kickoff_fumble_row = pd.DataFrame([kickoff_fumble_row], columns=df_plays.columns)\n",
        "      kickoff_fumble_row = clean_kickoff_plays(kickoff_fumble_row)\n",
        "      kickoff_fumble_row['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "\n",
        "      # Replacing old row with cleaned row\n",
        "      df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before_row, kickoff_fumble_row, df_after_row], ignore_index=True)\n",
        "\n",
        "      # Recursion to update 'df_plays'\n",
        "      if df_fumble_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_fumble_plays(df_plays, idx+len(kickoff_fumble_row))\n",
        "\n",
        "  return df_plays"
      ],
      "metadata": {
        "id": "u-HHSAiskq1X"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### PENALTY PLAYS"
      ],
      "metadata": {
        "id": "9M6XwDERno2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This probably does not cover every possible penalty play.\n",
        "# For example, in this sample of plays there are no penalties during kickoffs\n",
        "# when penalties during kickoffs are 100% possible.\n",
        "\n",
        "def clean_penalty_plays(df_plays, index_start=None):\n",
        "\n",
        "  # Cut 'df_plays' to begin from 'index_start' to the last penalty play available in dataframe\n",
        "  if index_start != None:\n",
        "    df_plays_adjusted = df_plays.loc[index_start:]\n",
        "    df_plays_adjusted = df_plays.iloc[df_plays.index.tolist().index(index_start):]\n",
        "    df_penalty_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('penalty', case=False)]\n",
        "  else:\n",
        "    df_penalty_plays = df_plays[df_plays['PlayOutcome'].str.contains('penalty', case=False)]\n",
        "\n",
        "  # Iterating through every penalty play within 'df_penalty_plays'\n",
        "  for idx, play in df_penalty_plays['PlayDescription'].items():\n",
        "\n",
        "    ############\n",
        "    # REVERSES #\n",
        "    ############\n",
        "\n",
        "    # In 'PlayDescription' all information before the \"reversed\" sentence is not needed.\n",
        "    # - All information before is stored within 'ReverseDetails' and the remaining is cleaned.\n",
        "    if play.find('REVERSED') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      for i in play_elements:\n",
        "        if i.find(\"REVERSED\") != -1:\n",
        "          df_plays.at[idx, 'ReverseDetails'] = play_elements[:play_elements.index(i) + 1]\n",
        "          play = \". \".join(play_elements[play_elements.index(i) + 1:])\n",
        "          break\n",
        "\n",
        "    ############################\n",
        "    # REPORTING IN AS ELIGIBLE #\n",
        "    ############################\n",
        "\n",
        "    # I do not think this contains any useful data so I am going to exclude it.\n",
        "    if play.find('reported in as eligible') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      for i in play_elements:\n",
        "        if i.find('reported in as eligible') != -1:\n",
        "          play = \". \".join(play_elements[play_elements.index(i) + 1:])\n",
        "          break\n",
        "\n",
        "    initial_action = play.split(\". \")[0]\n",
        "\n",
        "    ###############################\n",
        "    # PENALTY DURING PASSING PLAY #\n",
        "    ###############################\n",
        "\n",
        "    penalty_pass = re.findall(receiver_pattern, initial_action)\n",
        "    if len(penalty_pass) > 0 or play.find('pass incomplete') != -1:\n",
        "\n",
        "      # creating a copy of the passing penalty play row and cleaning the copy\n",
        "      passing_penalty_row = df_plays.loc[idx].copy()\n",
        "      passing_penalty_row['PlayOutcome'] = 'Pass'\n",
        "      passing_penalty_row = pd.DataFrame([passing_penalty_row], columns=df_plays.columns)\n",
        "      passing_penalty_row = clean_pass_plays(passing_penalty_row)\n",
        "      passing_penalty_row['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "      passing_penalty_row['PlayType'] = 'No Play'\n",
        "\n",
        "      # Replacing old row with cleaned row\n",
        "      df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before_row, passing_penalty_row, df_after_row], ignore_index=True)\n",
        "\n",
        "      # Recursion to update 'df_plays'\n",
        "      if df_penalty_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_penalty_plays(df_plays, idx+len(passing_penalty_row))\n",
        "\n",
        "    ###############################\n",
        "    # PENALTY DURING RUSHING PLAY #\n",
        "    ###############################\n",
        "\n",
        "    penalty_rush = re.findall(rusher_pattern, initial_action)\n",
        "    if len(penalty_rush) > 0 or play.find('Aborted') != -1:\n",
        "\n",
        "      # creating a copy of the rushing penalty play row and cleaning the copy\n",
        "      rushing_penalty_row = df_plays.loc[idx].copy()\n",
        "      rushing_penalty_row['PlayOutcome'] = 'Run'\n",
        "      rushing_penalty_row = pd.DataFrame([rushing_penalty_row], columns=df_plays.columns)\n",
        "      rushing_penalty_row = clean_run_plays(rushing_penalty_row)\n",
        "      rushing_penalty_row['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "      rushing_penalty_row['PlayType'] = 'No Play'\n",
        "\n",
        "      # Replacing old row with cleaned row\n",
        "      df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before_row, rushing_penalty_row, df_after_row], ignore_index=True)\n",
        "\n",
        "      # Recursion to update 'df_plays'\n",
        "      if df_penalty_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_penalty_plays(df_plays, idx+len(rushing_penalty_row))\n",
        "\n",
        "    ######################################\n",
        "    # PENALTY DURING 2PT CONVERSION PLAY #\n",
        "    ######################################\n",
        "\n",
        "    if play.find('TWO-POINT CONVERSION ATTEMPT') != -1:\n",
        "\n",
        "      # creating a copy of the 2pt conversion penalty play row and cleaning the copy\n",
        "      two_pt_conversion_penalty_row = df_plays.loc[idx].copy()\n",
        "      two_pt_conversion_penalty_row['PlayOutcome'] = '2PT Conversion'\n",
        "      two_pt_conversion_penalty_row = pd.DataFrame([two_pt_conversion_penalty_row], columns=df_plays.columns)\n",
        "      two_pt_conversion_penalty_row = cleaning_2pt_conversion_plays(two_pt_conversion_penalty_row)\n",
        "      two_pt_conversion_penalty_row['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "      two_pt_conversion_penalty_row['PlayType'] = 'No Play'\n",
        "\n",
        "      # Replacing old row with cleaned row\n",
        "      df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before_row, two_pt_conversion_penalty_row, df_after_row], ignore_index=True)\n",
        "\n",
        "      # Recursion to update 'df_plays'\n",
        "      if df_penalty_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_penalty_plays(df_plays, idx+len(two_pt_conversion_penalty_row))\n",
        "\n",
        "    #################\n",
        "    # SACKED FUMBLE #\n",
        "    #################\n",
        "\n",
        "    if initial_action.find('sacked') != -1:\n",
        "\n",
        "      # creating a copy of the sacked fumble play row and cleaning the copy\n",
        "      sacked_penalty_row = df_plays.loc[idx].copy()\n",
        "      sacked_penalty_row['PlayOutcome'] = 'Sack'\n",
        "      sacked_penalty_row = pd.DataFrame([sacked_penalty_row], columns=df_plays.columns)\n",
        "      sacked_penalty_row = clean_sacked_plays(sacked_penalty_row)\n",
        "      sacked_penalty_row['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "      sacked_penalty_row['PlayType'] = 'No Play'\n",
        "\n",
        "      # Replacing old row with cleaned row\n",
        "      df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before_row, sacked_penalty_row, df_after_row], ignore_index=True)\n",
        "\n",
        "      # Recursion to update 'df_plays'\n",
        "      if df_penalty_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_penalty_plays(df_plays, idx+len(sacked_penalty_row))\n",
        "\n",
        "    #########################\n",
        "    # PENALTY (False Start) #\n",
        "    #########################\n",
        "\n",
        "    # Will use 'clean_run_plays' method to clean these\n",
        "    # All other penalty plays (e.i. False Start, Delay of Game, Offside, Neutral Zone Infraction, Too Many Men on Field, Encroachment, Taunting)\n",
        "\n",
        "    # if play.find('False Start') != -1 or play.find('Delay of Game') != -1:\n",
        "\n",
        "    # TimeOnTheClock\n",
        "    TimeOnTheClock = re.findall(time_on_clock_pattern, play)\n",
        "    if len(TimeOnTheClock) > 0:\n",
        "      df_plays.loc[idx, 'TimeOnTheClock'] = TimeOnTheClock[0]\n",
        "\n",
        "    # Formation\n",
        "    Formation = re.findall(formation, play)\n",
        "    if len(Formation) > 0:\n",
        "      if Formation[0] == 'Aborted':\n",
        "        pass\n",
        "      else:\n",
        "        df_plays.loc[idx, 'Formation'] = Formation[0]\n",
        "\n",
        "    df_plays.at[idx, 'AcceptedPenalty'] = play\n",
        "    df_plays.at[idx, 'PlayType'] = 'No Play'\n",
        "\n",
        "  return df_plays"
      ],
      "metadata": {
        "id": "2IOjdt8dn7Vo"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TURNOVER ON DOWNS"
      ],
      "metadata": {
        "id": "LOqTmdy5ldib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Looks like either a pass / run / sack play\n",
        "\n",
        "def clean_turnover_on_downs_plays(df_plays, index_start=None):\n",
        "\n",
        "  # Cut 'df_plays' to begin from 'index_start' to the last penalty play available in dataframe\n",
        "  if index_start != None:\n",
        "    df_plays_adjusted = df_plays.loc[index_start:]\n",
        "    df_turnover_on_downs_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('Turnover on Downs', case=False)]\n",
        "  else:\n",
        "    df_turnover_on_downs_plays = df_plays[df_plays['PlayOutcome'].str.contains('Turnover on Downs', case=False)]\n",
        "\n",
        "  # Iterating through every penalty play within 'df_turnover_on_downs_plays'\n",
        "  for idx, play in df_turnover_on_downs_plays['PlayDescription'].items():\n",
        "\n",
        "    ############################\n",
        "    # TURNOVER ON DOWNS (PASS) #\n",
        "    ############################\n",
        "\n",
        "    passing_play = re.findall(passer_name_pattern, play)\n",
        "    if len(passing_play) > 0 and play.find(\"sacked\") == -1:\n",
        "\n",
        "      passing_turnover_on_downs = df_plays.loc[idx].copy()\n",
        "      passing_turnover_on_downs['PlayOutcome'] = 'Pass'\n",
        "      passing_turnover_on_downs = pd.DataFrame([passing_turnover_on_downs], columns=df_plays.columns)\n",
        "      passing_turnover_on_downs = clean_pass_plays(passing_turnover_on_downs)\n",
        "\n",
        "      # Record whether the pass was complete or incomplete.\n",
        "      if play.find('pass incomplete') != -1:\n",
        "        passing_turnover_on_downs['PlayOutcome'] = f\"{df_plays['PlayOutcome'].loc[idx]} (I)\"\n",
        "      else:\n",
        "        passing_turnover_on_downs['PlayOutcome'] = f\"{df_plays['PlayOutcome'].loc[idx]} (C)\"\n",
        "\n",
        "      # Replacing old row with cleaned row\n",
        "      df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before_row, passing_turnover_on_downs, df_after_row], ignore_index=True)\n",
        "\n",
        "      # Recursion to update 'df_plays'\n",
        "      if df_turnover_on_downs_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_turnover_on_downs_plays(df_plays, idx+len(passing_turnover_on_downs))\n",
        "\n",
        "    ############################\n",
        "    # TURNOVER ON DOWNS (RUSH) #\n",
        "    ############################\n",
        "\n",
        "    rushing_play = re.findall(rusher_pattern, play)\n",
        "    if len(rushing_play) > 0:\n",
        "\n",
        "      rushing_turnover_on_downs = df_plays.loc[idx].copy()\n",
        "      rushing_turnover_on_downs['PlayOutcome'] = 'Run'\n",
        "      rushing_turnover_on_downs = pd.DataFrame([rushing_turnover_on_downs], columns=df_plays.columns)\n",
        "      rushing_turnover_on_downs = clean_run_plays(rushing_turnover_on_downs)\n",
        "      rushing_turnover_on_downs['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "\n",
        "      df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before_row, rushing_turnover_on_downs, df_after_row], ignore_index=True)\n",
        "\n",
        "      if df_turnover_on_downs_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_turnover_on_downs_plays(df_plays, idx+len(rushing_turnover_on_downs))\n",
        "\n",
        "    ##############################\n",
        "    # TURNOVER ON DOWNS (SACKED) #\n",
        "    ##############################\n",
        "\n",
        "    if play.find(\"sacked\") != -1:\n",
        "\n",
        "      sacked_turnover_on_downs = df_plays.loc[idx].copy()\n",
        "      sacked_turnover_on_downs['PlayOutcome'] = 'Sack'\n",
        "      sacked_turnover_on_downs = pd.DataFrame([sacked_turnover_on_downs], columns=df_plays.columns)\n",
        "      sacked_turnover_on_downs.reset_index(drop=True, inplace=True)\n",
        "      sacked_turnover_on_downs = clean_sacked_plays(sacked_turnover_on_downs)\n",
        "      sacked_turnover_on_downs['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "\n",
        "      # Replacing old row with cleaned row\n",
        "      df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before_row, sacked_turnover_on_downs, df_after_row], ignore_index=True)\n",
        "\n",
        "      # Recursion to update 'df_plays'\n",
        "      if df_turnover_on_downs_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_turnover_on_downs_plays(df_plays, idx+len(sacked_turnover_on_downs))"
      ],
      "metadata": {
        "id": "Qq4L0BYwmrrF"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. PIPELINE MAIN METHOD"
      ],
      "metadata": {
        "id": "i0nkzhWl5FEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PURPOSE:\n",
        "# - Accept a dataframe of plays (dataframes formatted by NFL_Scrapers) and\n",
        "#   return a cleaned dataframe of those plays.\n",
        "# INPUT PARAMTERS:\n",
        "# df_all_plays         - dataframe - all plays in raw form from NFL_Scraper that user\n",
        "#                                    would like to clean.\n",
        "# OUTPUT:\n",
        "# df_all_plays_cleaned - dataframe - all plays from 'df_all_plays' cleaned and data\n",
        "#                                    dispersed into individual new features.\n",
        "\n",
        "# CURRENT DESIGN PLAN:\n",
        "# 1. Use uniquely designed methods for each play type to clean within dataframe\n",
        "#    - (e.g. pass, run, touchdown, punt, sack, ... )\n",
        "# 2. Repeat until all plays within dataframe have been cleaned.\n",
        "#   NOTE:\n",
        "#   - It is important to fully clean a play type before moving to the next\n",
        "#      because sometimes cleaning could involve adding a new row to the dataframe,\n",
        "#      causing a reset to the dataframes indexing.\n",
        "#      - If we were to separate all play types from the beginning, the indexes\n",
        "#        could shift around causing, for example, an index that might originally\n",
        "#        point to a run play to now instead point at a pass play.\n",
        "\n",
        "# NOTES:\n",
        "# - I think \"PlayOutcomes\" is what determines the yardage gained on an intended play?\n",
        "#   - This does not seem right to me.\n",
        "#   - EXAMPLE:\n",
        "#     - (9:54) Bre.Hall left end to BUF 22 for -1 yards (G.Rousseau)\n",
        "#       FUMBLES (G.Rousseau), ball out of bounds at BUF 25.\n",
        "#       - I would think that Bre.Hall would get docked -1 yards for his run.\n",
        "#         - But I believe that he is actually docked -4\n",
        "#           - 'PlayStart' = 2nd & 9 at BUF 21\n",
        "#           - The play ends at BUF 25\n",
        "#             - In my opinion and how I am going to track yardage is based on\n",
        "#               possession of the ball. So I will track this as -1 yard not -4.\n",
        "\n",
        "def clean_dataframe_of_plays(df_all_plays):\n",
        "\n",
        "  ################################\n",
        "  # RAW DATA COLUMN DESCRIPTIONS #\n",
        "  ################################\n",
        "  # TeamWithPossession - Team that STARTED with the ball during the play. (The team that was on offense)\n",
        "\n",
        "  ###########################\n",
        "  # NEW COLUMN DESCRIPTIONS #\n",
        "  ###########################\n",
        "\n",
        "  # PlayType           - The type of play (e.g. pass/run)\n",
        "  # TimeOnTheClock     - The time that was on the clock when the play started\n",
        "  # Formation          - Play formation\n",
        "  # Passer             - Player that threw the ball (mostly the quarterback)\n",
        "  # Rusher             - Player that ran the ball (mostly the runningback)\n",
        "  # Receiver           - Player on the same team as the passer that caught the ball\n",
        "  # PassType           - Whether the pass was a deep or short pass?\n",
        "  # Direction          - Where the ball is going during the play\n",
        "  # Yardage            - Yards gained during the play\n",
        "  # TackleBy1          - Main tackler on the play (could be solo or could be with someone else)\n",
        "  # TackleBy2          - Assisted tackler1\n",
        "  # PressureBy         - Defender that applied pressure to the passer\n",
        "  # InterceptedBy      - Defender that intercepted the passing play\n",
        "  # FumbleDetails      - A list that has what happened after the fumble\n",
        "  #                      - [forced fumble by, recovered by, yards gained, tackled by]\n",
        "  # ReverseDetails     - A list having plays leading up to play reversal\n",
        "  # InjuredPlayers     - Players that were injured during the play\n",
        "  # PenaltyDescription - If there is a penalty, gives a description of it\n",
        "  #                      - [who caused the penalty, what was the penalty, yards lost if penalty accepted]\n",
        "\n",
        "  # new_columns = [\"PlayType\", \"TimeOnTheClock\", \"Formation\", \"Passer\", \"Rusher\", \"Receiver\", \"Direction\", \"Yardage\",\n",
        "  #               \"TackleBy1\", \"TackleBy2\", \"PressureBy\", \"InterceptedBy\", \"SackedBy\", \"ForcedFumbleBy\",\n",
        "  #               \"FumbleDetails\", \"ReverseDetails\",\n",
        "  #               \"InjuredPlayers\", \"AcceptedPenalty\", \"DeclinedPenalty\",\n",
        "  #               \"Kicker\", \"LongSnapper\", \"Returner\", \"DownedBy\", \"Holder\", \"BlockedBy\"]\n",
        "\n",
        "  # string_columns = [\"PlayType\", \"TimeOnTheClock\", \"Formation\", \"Passer\", \"Rusher\", \"Receiver\", \"Direction\",\n",
        "  #                   \"TackleBy1\", \"TackleBy2\", \"PressureBy\", \"InterceptedBy\", \"SackedBy\", \"ForcedFumbleBy\",\n",
        "  #                   \"FumbleDetails\", \"ReverseDetails\",\n",
        "  #                   \"InjuredPlayers\", \"AcceptedPenalty\", \"DeclinedPenalty\",\n",
        "  #                   \"Kicker\", \"LongSnapper\", \"Returner\", \"DownedBy\", \"Holder\", \"BlockedBy\"]\n",
        "\n",
        "  # int_columns = [\"Yardage\"]\n",
        "\n",
        "\n",
        "  # new_columns = [\"PlayType\", \"TimeOnTheClock\", \"Formation\", \"Passer\", \"Rusher\", \"Receiver\", \"Direction\", \"Yardage\",\n",
        "  #               \"SoloTackle\", \"AssistedTackle\", \"SharedTackle\", \"PressureBy\", \"InterceptedBy\", \"SackedBy\", \"ForcedFumbleBy\",\n",
        "  #               \"FumbleDetails\", \"ReverseDetails\",\n",
        "  #               \"InjuredPlayers\", \"AcceptedPenalty\", \"DeclinedPenalty\",\n",
        "  #               \"Kicker\", \"LongSnapper\", \"Returner\", \"DownedBy\", \"Holder\", \"BlockedBy\"]\n",
        "\n",
        "  new_columns = [\"PlayType\", \"TimeOnTheClock\", \"Formation\", \"Passer\", \"Rusher\", \"Receiver\", \"Direction\", \"Yardage\",\n",
        "                \"SoloTackle\", \"AssistedTackle\", \"SharedTackle\", \"PressureBy\", \"InterceptedBy\", \"SackedBy\", \"ForcedFumbleBy\",\n",
        "                \"FumbleDetails\", \"ReverseDetails\",\n",
        "                \"InjuredPlayers\", \"OffensivePenalty\", \"DefensivePenalty\",\n",
        "                \"Kicker\", \"LongSnapper\", \"Returner\", \"DownedBy\", \"Holder\", \"BlockedBy\"]\n",
        "\n",
        "  # string_columns = [\"PlayType\", \"TimeOnTheClock\", \"Formation\", \"Passer\", \"Rusher\", \"Receiver\", \"Direction\",\n",
        "  #                   \"SoloTackle\", \"AssistedTackle\", \"SharedTackle\", \"PressureBy\", \"InterceptedBy\", \"SackedBy\", \"ForcedFumbleBy\",\n",
        "  #                   \"FumbleDetails\", \"ReverseDetails\",\n",
        "  #                   \"InjuredPlayers\", \"AcceptedPenalty\", \"DeclinedPenalty\",\n",
        "  #                   \"Kicker\", \"LongSnapper\", \"Returner\", \"DownedBy\", \"Holder\", \"BlockedBy\"]\n",
        "\n",
        "  string_columns = [\"PlayType\", \"TimeOnTheClock\", \"Formation\", \"Passer\", \"Rusher\", \"Receiver\", \"Direction\",\n",
        "                    \"SoloTackle\", \"AssistedTackle\", \"SharedTackle\", \"PressureBy\", \"InterceptedBy\", \"SackedBy\", \"ForcedFumbleBy\",\n",
        "                    \"FumbleDetails\", \"ReverseDetails\",\n",
        "                    \"InjuredPlayers\", \"OffensivePenalty\", \"DefensivePenalty\",\n",
        "                    \"Kicker\", \"LongSnapper\", \"Returner\", \"DownedBy\", \"Holder\", \"BlockedBy\"]\n",
        "\n",
        "  int_columns = [\"Yardage\"]\n",
        "\n",
        "  ########################################\n",
        "  # RETURN DATAFRAME WITH ADDED FEATURES #\n",
        "  ########################################\n",
        "\n",
        "  df_all_plays_cleaned = df_all_plays.copy()\n",
        "  df_all_plays_cleaned = df_all_plays_cleaned.reindex(columns=df_all_plays_cleaned.columns.tolist() + new_columns)\n",
        "  df_all_plays_cleaned[string_columns] = df_all_plays_cleaned[string_columns].astype(str)\n",
        "  df_all_plays_cleaned[int_columns] = df_all_plays_cleaned[int_columns].astype(float)\n",
        "\n",
        "  ########################################\n",
        "  # GETTING PLAY CATEGORIES AND CLEANING #\n",
        "  ########################################\n",
        "\n",
        "  # TOUCHDOWNS MUST BE CLEANED FIRST\n",
        "  # - Any touchdown resulting from a change in possession (e.g. Interception for Touchdown)\n",
        "  #   raw data states that the team on defense had possession the entire drive.\n",
        "  #   - So all plays leading up to the touchdown state that the defense has possession.\n",
        "  df_all_plays_cleaned = clean_touchdown_plays(df_all_plays_cleaned)\n",
        "  # df_all_plays_cleaned = clean_run_plays(df_all_plays_cleaned)\n",
        "  # df_all_plays_cleaned = clean_pass_plays(df_all_plays_cleaned)\n",
        "  # df_all_plays_cleaned = cleaning_2pt_conversion_plays(df_all_plays_cleaned)\n",
        "  # df_all_plays_cleaned = clean_intercepted_plays(df_all_plays_cleaned)\n",
        "  # df_all_plays_cleaned = clean_sacked_plays(df_all_plays_cleaned)\n",
        "  # df_all_plays_cleaned = clean_punt_plays(df_all_plays_cleaned)\n",
        "  # df_all_plays_cleaned = clean_kickoff_plays(df_all_plays_cleaned)\n",
        "  # df_all_plays_cleaned = clean_field_goal_plays(df_all_plays_cleaned)\n",
        "  # df_all_plays_cleaned = clean_extra_point_plays(df_all_plays_cleaned)\n",
        "  # df_all_plays_cleaned = clean_fumble_plays(df_all_plays_cleaned)\n",
        "  # df_all_plays_cleaned = clean_penalty_plays(df_all_plays_cleaned)\n",
        "  # df_all_plays_cleaned = clean_turnover_on_downs_plays(df_all_plays_cleaned)\n",
        "\n",
        "  return df_all_plays_cleaned"
      ],
      "metadata": {
        "id": "7cbY2K4pyH8d"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TESTING (Helper Methods)"
      ],
      "metadata": {
        "id": "U7HnZWShxAX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PURPOSE:\n",
        "# - A tool that can be used to compare original plays and their cleaned versions\n",
        "\n",
        "# I would like to return a map that has:\n",
        "# KEY: index of original unclean play\n",
        "# VALUE: index(es) of cleaned play\n",
        "\n",
        "def unclean_clean_matches(df_unclean_plays, df_clean_plays):\n",
        "\n",
        "  my_map = {}\n",
        "\n",
        "  # This group of features is unique to each play\n",
        "  # - Both the unclean and cleaned versions of the plays have these\n",
        "  # - These features will be used to find the matching plays between the unclean df and the cleaned df\n",
        "  matching_features = ['Season', 'Week', 'Date', 'AwayTeam', 'HomeTeam', 'Quarter', 'DriveNumber', 'TeamWithPossession', 'PlayNumberInDrive']\n",
        "\n",
        "  # Iterate through each row of the dataframe of unclean plays\n",
        "  for u_row in df_unclean_plays.itertuples(index=True):\n",
        "    u_features = [getattr(u_row, col) for col in matching_features]\n",
        "\n",
        "    matching_indexes = []\n",
        "    matches_found = False\n",
        "\n",
        "    # Iterate through each row of the dataframe of cleaned plays\n",
        "    # - The starting index will be the index of the unclean play within the main original dataframe of plays\n",
        "    #   - The matching cleaned pair will either be at the exact same location or higher\n",
        "    for c_row in df_clean_plays[u_row.Index::].itertuples(index=True):\n",
        "      c_features = [getattr(c_row, col) for col in matching_features]\n",
        "\n",
        "      # If a match is found, check for consective rows of matches because some uncleaned plays needed to be cleaned using multiple rows\n",
        "      # - Once a row that does not match follows one that does, will break the loop because the one play match has been found.\n",
        "      if u_features == c_features:\n",
        "        matching_indexes.append(c_row.Index)\n",
        "        matches_found = True\n",
        "      elif matches_found:\n",
        "        my_map[u_row.Index] = matching_indexes\n",
        "        break\n",
        "\n",
        "  return my_map"
      ],
      "metadata": {
        "id": "RzaGgriDS9Js"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TESTING AREA"
      ],
      "metadata": {
        "id": "FN4kSTEvpiHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_week1_plays_cleaned = clean_dataframe_of_plays(week1_2023_plays_modified)"
      ],
      "metadata": {
        "id": "WneGzl-4StKu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "a5ef4380-07f8-49c5-99d9-75c9c4c2da6d"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "832\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "cannot concatenate object of type '<class 'str'>'; only Series and DataFrame objs are valid",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-6a1a85421f1f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_week1_plays_cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_dataframe_of_plays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweek1_2023_plays_modified\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-36-e488259ffdc9>\u001b[0m in \u001b[0;36mclean_dataframe_of_plays\u001b[0;34m(df_all_plays)\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;31m#   raw data states that the team on defense had possession the entire drive.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[0;31m#   - So all plays leading up to the touchdown state that the defense has possession.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m   \u001b[0mdf_all_plays_cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_touchdown_plays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_all_plays_cleaned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m   \u001b[0;31m# df_all_plays_cleaned = clean_run_plays(df_all_plays_cleaned)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m   \u001b[0;31m# df_all_plays_cleaned = clean_pass_plays(df_all_plays_cleaned)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2404356cddbf>\u001b[0m in \u001b[0;36mclean_touchdown_plays\u001b[0;34m(df_plays, index_start)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf_plays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mclean_touchdown_plays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_plays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassing_touchdown_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m######################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2404356cddbf>\u001b[0m in \u001b[0;36mclean_touchdown_plays\u001b[0;34m(df_plays, index_start)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf_plays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mclean_touchdown_plays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_plays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassing_touchdown_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m######################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2404356cddbf>\u001b[0m in \u001b[0;36mclean_touchdown_plays\u001b[0;34m(df_plays, index_start)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf_plays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mclean_touchdown_plays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_plays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpunt_touchdown_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;31m#################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2404356cddbf>\u001b[0m in \u001b[0;36mclean_touchdown_plays\u001b[0;34m(df_plays, index_start)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf_plays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mclean_touchdown_plays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_plays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassing_touchdown_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m######################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2404356cddbf>\u001b[0m in \u001b[0;36mclean_touchdown_plays\u001b[0;34m(df_plays, index_start)\u001b[0m\n\u001b[1;32m     78\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mdf_plays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mclean_touchdown_plays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_plays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrushing_touchdown_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m##########################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2404356cddbf>\u001b[0m in \u001b[0;36mclean_touchdown_plays\u001b[0;34m(df_plays, index_start)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf_plays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mclean_touchdown_plays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_plays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassing_touchdown_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m######################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2404356cddbf>\u001b[0m in \u001b[0;36mclean_touchdown_plays\u001b[0;34m(df_plays, index_start)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf_plays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mclean_touchdown_plays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_plays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassing_touchdown_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m######################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2404356cddbf>\u001b[0m in \u001b[0;36mclean_touchdown_plays\u001b[0;34m(df_plays, index_start)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf_plays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mclean_touchdown_plays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_plays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintercepted_touchdown_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;31m#####################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2404356cddbf>\u001b[0m in \u001b[0;36mclean_touchdown_plays\u001b[0;34m(df_plays, index_start)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf_plays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mclean_touchdown_plays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_plays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassing_touchdown_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m######################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2404356cddbf>\u001b[0m in \u001b[0;36mclean_touchdown_plays\u001b[0;34m(df_plays, index_start)\u001b[0m\n\u001b[1;32m     78\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mdf_plays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mclean_touchdown_plays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_plays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrushing_touchdown_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m##########################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2404356cddbf>\u001b[0m in \u001b[0;36mclean_touchdown_plays\u001b[0;34m(df_plays, index_start)\u001b[0m\n\u001b[1;32m     78\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mdf_plays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mclean_touchdown_plays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_plays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrushing_touchdown_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m##########################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2404356cddbf>\u001b[0m in \u001b[0;36mclean_touchdown_plays\u001b[0;34m(df_plays, index_start)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf_plays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mclean_touchdown_plays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_plays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassing_touchdown_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m######################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2404356cddbf>\u001b[0m in \u001b[0;36mclean_touchdown_plays\u001b[0;34m(df_plays, index_start)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf_plays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mclean_touchdown_plays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_plays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msacked_touchdown_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;31m##########################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2404356cddbf>\u001b[0m in \u001b[0;36mclean_touchdown_plays\u001b[0;34m(df_plays, index_start)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf_plays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mclean_touchdown_plays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_plays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassing_touchdown_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m######################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2404356cddbf>\u001b[0m in \u001b[0;36mclean_touchdown_plays\u001b[0;34m(df_plays, index_start)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf_plays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mclean_touchdown_plays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_plays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassing_touchdown_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m######################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2404356cddbf>\u001b[0m in \u001b[0;36mclean_touchdown_plays\u001b[0;34m(df_plays, index_start)\u001b[0m\n\u001b[1;32m     78\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mdf_plays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mclean_touchdown_plays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_plays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrushing_touchdown_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m##########################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2404356cddbf>\u001b[0m in \u001b[0;36mclean_touchdown_plays\u001b[0;34m(df_plays, index_start)\u001b[0m\n\u001b[1;32m     78\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mdf_plays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mclean_touchdown_plays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_plays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrushing_touchdown_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m##########################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2404356cddbf>\u001b[0m in \u001b[0;36mclean_touchdown_plays\u001b[0;34m(df_plays, index_start)\u001b[0m\n\u001b[1;32m     78\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mdf_plays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mclean_touchdown_plays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_plays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrushing_touchdown_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m##########################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2404356cddbf>\u001b[0m in \u001b[0;36mclean_touchdown_plays\u001b[0;34m(df_plays, index_start)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf_plays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mclean_touchdown_plays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_plays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassing_touchdown_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m######################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2404356cddbf>\u001b[0m in \u001b[0;36mclean_touchdown_plays\u001b[0;34m(df_plays, index_start)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf_plays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mclean_touchdown_plays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_plays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassing_touchdown_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m######################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2404356cddbf>\u001b[0m in \u001b[0;36mclean_touchdown_plays\u001b[0;34m(df_plays, index_start)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf_plays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mclean_touchdown_plays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_plays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassing_touchdown_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m######################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2404356cddbf>\u001b[0m in \u001b[0;36mclean_touchdown_plays\u001b[0;34m(df_plays, index_start)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf_plays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mclean_touchdown_plays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_plays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassing_touchdown_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m######################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2404356cddbf>\u001b[0m in \u001b[0;36mclean_touchdown_plays\u001b[0;34m(df_plays, index_start)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf_plays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mclean_touchdown_plays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_plays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintercepted_touchdown_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;31m#####################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2404356cddbf>\u001b[0m in \u001b[0;36mclean_touchdown_plays\u001b[0;34m(df_plays, index_start)\u001b[0m\n\u001b[1;32m     78\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mdf_plays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mclean_touchdown_plays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_plays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrushing_touchdown_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m##########################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2404356cddbf>\u001b[0m in \u001b[0;36mclean_touchdown_plays\u001b[0;34m(df_plays, index_start)\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mblocked_fg_touchdown_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblocked_fg_touchdown_row\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_plays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m       \u001b[0mblocked_fg_touchdown_row\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m       \u001b[0mblocked_fg_touchdown_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_field_goal_plays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocked_fg_touchdown_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m       \u001b[0mblocked_fg_touchdown_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PlayOutcome'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_plays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PlayOutcome'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-70-9df162743d53>\u001b[0m in \u001b[0;36mclean_field_goal_plays\u001b[0;34m(df_plays, index_start)\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mdf_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_plays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdf_plays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mdf_after\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_plays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_plays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0mdf_plays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_before\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_add_on_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_after\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m             \u001b[0mindex_of_last_added_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_add_on_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m     op = _Concatenator(\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;31m# figure out what our result ndim is going to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m         \u001b[0mndims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_ndims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m         \u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sample_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m_get_ndims\u001b[0;34m(self, objs)\u001b[0m\n\u001b[1;32m    487\u001b[0m                     \u001b[0;34m\"only Series and DataFrame objs are valid\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                 )\n\u001b[0;32m--> 489\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mndims\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'str'>'; only Series and DataFrame objs are valid"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_week1_plays_cleaned.shape"
      ],
      "metadata": {
        "id": "l79N87_MWkzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PLAYTYPE OBSERVATIONS\n",
        "- Looking at each play from each playtype"
      ],
      "metadata": {
        "id": "p3xBIferz67H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Passing plays"
      ],
      "metadata": {
        "id": "VYVhXDgbC3m3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of passing type plays during 2023, Week 1\n",
        "\n",
        "df_unclean_pass_plays = week1_2023_plays_modified.loc[week1_2023_plays_modified['PlayOutcome'].str.contains('Pass')]\n",
        "\n",
        "map_passing_plays = unclean_clean_matches(df_unclean_pass_plays, df_week1_plays_cleaned)\n",
        "\n",
        "len(map_passing_plays.keys())"
      ],
      "metadata": {
        "id": "AnnrktjKJu3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Every unclean passing play and their associated cleaned play breakdown\n",
        "\n",
        "for i in map_passing_plays.keys():\n",
        "  print(f\"({i}, {map_passing_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "zNtZrXPKno2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# passing type plays during 2023, Week 1 that have been spiked\n",
        "\n",
        "df_unclean_pass_plays_spiked = week1_2023_plays_modified.loc[(week1_2023_plays_modified['PlayOutcome'].str.contains('Pass')) &\n",
        "                                                             (week1_2023_plays_modified['PlayDescription'].str.contains('spiked', case=False))]\n",
        "\n",
        "map_passing_spiked_plays = unclean_clean_matches(df_unclean_pass_plays_spiked, df_week1_plays_cleaned)\n",
        "\n",
        "for i in map_passing_spiked_plays.keys():\n",
        "  print(f\"({i}, {map_passing_spiked_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "kofdUBx2kLuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# passing type plays during 2023, Week 1 that result in touchdown\n",
        "\n",
        "df_unclean_pass_plays_touchdown = week1_2023_plays_modified.loc[(week1_2023_plays_modified['PlayOutcome'].str.contains('touchdown', case=False)) &\n",
        "                                                                (week1_2023_plays_modified['PlayDescription'].str.contains('pass', case=False))]\n",
        "\n",
        "map_passing_touchdown_plays = unclean_clean_matches(df_unclean_pass_plays_touchdown, df_week1_plays_cleaned)\n",
        "\n",
        "for i in map_passing_touchdown_plays.keys():\n",
        "  print(f\"({i}, {map_passing_touchdown_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "yOb_Z_X_gECI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# passing type plays during 2023, Week 1 that result in touchdown\n",
        "\n",
        "df_unclean_pass_plays_touchdown = week1_2023_plays_modified.loc[(week1_2023_plays_modified['PlayOutcome'].str.contains('touchdown', case=False)) &\n",
        "                                                                (week1_2023_plays_modified['PlayDescription'].str.contains('PENALTY', case=False))]\n",
        "\n",
        "map_passing_touchdown_plays = unclean_clean_matches(df_unclean_pass_plays_touchdown, df_week1_plays_cleaned)\n",
        "\n",
        "for i in map_passing_touchdown_plays.keys():\n",
        "  print(f\"({i}, {map_passing_touchdown_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "1NSr2Lxzlt08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# every passing play that resulted in a fumble (including fumble recoveries resulting in a touchdown)\n",
        "\n",
        "df_unclean_pass_fumble_plays = week1_2023_plays_modified.loc[((week1_2023_plays_modified['PlayOutcome'].str.contains('Pass')) |\n",
        "                                                             ((week1_2023_plays_modified['PlayDescription'].str.contains('Touchdown', case=False)) &\n",
        "                                                              (week1_2023_plays_modified['PlayOutcome'].str.contains('Pass')))) &\n",
        "                                                              (week1_2023_plays_modified['PlayDescription'].str.contains('fumbles', case=False))]\n",
        "\n",
        "for i in unclean_clean_matches(df_unclean_pass_fumble_plays, df_week1_plays_cleaned).items():\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "aM4Flk8_SmK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_unclean_to_clean_pass_fumble_plays = unclean_clean_matches(df_unclean_pass_fumble_plays, df_week1_plays_cleaned)\n",
        "\n",
        "for i in dict_unclean_to_clean_pass_fumble_plays.keys():\n",
        "  # print(i)\n",
        "  print(f\"({i}, {dict_unclean_to_clean_pass_fumble_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "srpeGK1JS1pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rushing plays"
      ],
      "metadata": {
        "id": "01U2No85CuOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of running type plays during 2023, Week 1\n",
        "\n",
        "df_unclean_run_plays = week1_2023_plays_modified.loc[week1_2023_plays_modified['PlayOutcome'].str.contains('Run')]\n",
        "\n",
        "map_run_plays = unclean_clean_matches(df_unclean_run_plays, df_week1_plays_cleaned)\n",
        "\n",
        "len(map_run_plays.keys())"
      ],
      "metadata": {
        "id": "0CLnY7a5zKLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Every unclean passing play and their associated cleaned play breakdown\n",
        "\n",
        "for i in map_run_plays.keys():\n",
        "  print(f\"({i}, {map_run_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "3trhAkLPzjH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty rushing plays\n",
        "\n",
        "df_unclean_rush_penalty_plays = week1_2023_plays_modified.loc[(week1_2023_plays_modified['PlayOutcome'].str.contains('Run')) &\n",
        "                                                              (week1_2023_plays_modified['PlayDescription'].str.contains('penalty', case=False))]\n",
        "\n",
        "dict_unclean_rush_penalty_plays = unclean_clean_matches(df_unclean_rush_penalty_plays, df_week1_plays_cleaned)\n",
        "\n",
        "for i in dict_unclean_rush_penalty_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_rush_penalty_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "6X0YtJuOmkMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fumbled rushing plays (not including touchdowns)\n",
        "\n",
        "df_unclean_rush_fumble_plays = week1_2023_plays_modified.loc[(week1_2023_plays_modified['PlayOutcome'].str.contains('Run')) &\n",
        "                                                             (week1_2023_plays_modified['PlayDescription'].str.contains('fumbles', case=False))]\n",
        "\n",
        "for i in unclean_clean_matches(df_unclean_rush_fumble_plays, df_week1_plays_cleaned).items():\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "tmK9dsi9Vc6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_unclean_to_clean_rush_fumble_plays = unclean_clean_matches(df_unclean_rush_fumble_plays, df_week1_plays_cleaned)\n",
        "\n",
        "for i in dict_unclean_to_clean_rush_fumble_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_rush_fumble_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "pGNT0pxIWS6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All rushing touchdowns\n",
        "\n",
        "df_unclean_pass_plays_touchdown = week1_2023_plays_modified.loc[(week1_2023_plays_modified['PlayOutcome'].str.contains('touchdown', case=False))]\n",
        "\n",
        "list_all_touchdown_rushing_plays = []\n",
        "\n",
        "for idx, play in df_unclean_pass_plays_touchdown['PlayDescription'].items():\n",
        "  run_play = re.findall(rusher_pattern, play)\n",
        "  if len(run_play) > 0:\n",
        "    list_all_touchdown_rushing_plays.append(idx)\n",
        "\n",
        "map_rushing_touchdown_plays = unclean_clean_matches(week1_2023_plays_modified.loc[list_all_touchdown_rushing_plays], df_week1_plays_cleaned)\n",
        "\n",
        "for i in map_rushing_touchdown_plays.keys():\n",
        "  print(f\"({i}, {map_rushing_touchdown_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "8zLi4gJHb21u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2pt Conversions"
      ],
      "metadata": {
        "id": "wMTxhm9K2gY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All extra point plays\n",
        "\n",
        "df_unclean_2pt_conversion_week1 = week1_2023_plays_modified[week1_2023_plays_modified['PlayOutcome'].str.contains('2PT Conversion')]\n",
        "\n",
        "dict_unclean_to_clean_2ptc = unclean_clean_matches(df_unclean_2pt_conversion_week1, df_week1_plays_cleaned)\n",
        "\n",
        "print(f\"{len(dict_unclean_to_clean_2ptc)} number of 2pt conversion attempts\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_2ptc.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_2ptc.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "RhtqlOup2oTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All passing 2PT conversion attempts\n",
        "\n",
        "index_pass_2ptc = []\n",
        "\n",
        "for i in list(df_unclean_2pt_conversion_week1.index):\n",
        "  pass_2ptc = re.findall(tp_conversion_pass_pattern, week1_2023_plays_modified['PlayDescription'].iloc[i])\n",
        "  if len(pass_2ptc) > 0:\n",
        "    index_pass_2ptc.append(i)\n",
        "\n",
        "dict_unclean_to_clean_pass_2ptc = unclean_clean_matches(week1_2023_plays_modified.iloc[index_pass_2ptc], df_week1_plays_cleaned)\n",
        "\n",
        "print(f\"{len(dict_unclean_to_clean_pass_2ptc)} number of 2pt conversion pass attempts\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_pass_2ptc.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_pass_2ptc.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "AbasinI35YsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All rushing 2PT conversion attempts\n",
        "\n",
        "index_rush_2ptc = []\n",
        "\n",
        "for i in list(df_unclean_2pt_conversion_week1.index):\n",
        "  rush_2ptc = re.findall(tp_conversion_rush_pattern, week1_2023_plays_modified['PlayDescription'].iloc[i])\n",
        "  if len(rush_2ptc) > 0:\n",
        "    index_rush_2ptc.append(i)\n",
        "\n",
        "dict_unclean_to_clean_rush_2ptc = unclean_clean_matches(week1_2023_plays_modified.iloc[index_rush_2ptc], df_week1_plays_cleaned)\n",
        "\n",
        "print(f\"{len(dict_unclean_to_clean_rush_2ptc)} number of 2pt conversion attempts\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_rush_2ptc.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_rush_2ptc.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "wIIVcqU-6WzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Intercepted plays"
      ],
      "metadata": {
        "id": "56zcEqI4C9NQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_unclean_intercepted_plays = week1_2023_plays_modified.loc[(week1_2023_plays_modified['PlayDescription'].str.contains('INTERCEPTED', case=False)) |\n",
        "                                                             (week1_2023_plays_modified['PlayOutcome'].str.contains('Interception', case=False))]\n",
        "\n",
        "dict_unclean_to_clean_intercepted_plays = unclean_clean_matches(df_unclean_intercepted_plays, df_week1_plays_cleaned)\n",
        "\n",
        "for i in dict_unclean_to_clean_intercepted_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_intercepted_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "CqpFWV9MC-vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All interceptions resulting in a touchdown\n",
        "\n",
        "df_unclean_intercepted_touchdown_plays = week1_2023_plays_modified.loc[(week1_2023_plays_modified['PlayDescription'].str.contains('INTERCEPTED', case=False)) &\n",
        "                                                                       (week1_2023_plays_modified['PlayOutcome'].str.contains('touchdown', case=False))]\n",
        "\n",
        "dict_unclean_to_clean_intercepted_touchdown_plays = unclean_clean_matches(df_unclean_intercepted_touchdown_plays, df_week1_plays_cleaned)\n",
        "\n",
        "for i in dict_unclean_to_clean_intercepted_touchdown_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_intercepted_touchdown_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "am3SJi6-QssS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sacked Plays"
      ],
      "metadata": {
        "id": "F09Qp3xQ9oq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_unclean_sacked_plays = week1_2023_plays_modified.loc[(week1_2023_plays_modified['PlayOutcome'].str.contains('Sack', case=False))]\n",
        "\n",
        "dict_unclean_to_clean_sacked_plays = unclean_clean_matches(df_unclean_sacked_plays, df_week1_plays_cleaned)\n",
        "\n",
        "for i in dict_unclean_to_clean_sacked_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_sacked_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "Y_sHtdif9taC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All sacked plays resulting in a touchdown\n",
        "\n",
        "df_unclean_sacked_touchdown_plays = week1_2023_plays_modified.loc[(week1_2023_plays_modified['PlayOutcome'].str.contains('touchdown', case=False)) &\n",
        "                                                                  (week1_2023_plays_modified['PlayDescription'].str.contains('sack', case=False))]\n",
        "\n",
        "dict_unclean_to_clean_sacked_touchdown_plays = unclean_clean_matches(df_unclean_sacked_touchdown_plays, df_week1_plays_cleaned)\n",
        "\n",
        "for i in dict_unclean_to_clean_sacked_touchdown_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_sacked_touchdown_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "cd5hJRiTNtA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Punt Plays"
      ],
      "metadata": {
        "id": "vMM5uVTFyDYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_unclean_punt_plays = week1_2023_plays_modified.loc[week1_2023_plays_modified['PlayDescription'].str.contains('punts', case=False)]\n",
        "\n",
        "dict_unclean_to_clean_punt_plays = unclean_clean_matches(df_unclean_punt_plays, df_week1_plays_cleaned)\n",
        "\n",
        "for i in dict_unclean_to_clean_punt_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_punt_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "tm2bsr5GyClu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All punt return touchdown plays\n",
        "\n",
        "df_unclean_punt_touchdown_plays = week1_2023_plays_modified.loc[week1_2023_plays_modified['PlayDescription'].str.contains('punts', case=False) &\n",
        "                                                                week1_2023_plays_modified['PlayDescription'].str.contains('touchdown', case=False)]\n",
        "\n",
        "dict_unclean_to_clean_punt_touchdown_plays = unclean_clean_matches(df_unclean_punt_touchdown_plays, df_week1_plays_cleaned)\n",
        "\n",
        "for i in dict_unclean_to_clean_punt_touchdown_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_punt_touchdown_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "G61pNfiuMBs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Kickoffs"
      ],
      "metadata": {
        "id": "m-sl_mhsaHWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All kickoff plays\n",
        "\n",
        "df_unclean_kickoff_plays = week1_2023_plays_modified.loc[week1_2023_plays_modified['PlayOutcome'].str.contains('kickoff', case=False)]\n",
        "\n",
        "dict_unclean_to_clean_kickoff_plays = unclean_clean_matches(df_unclean_kickoff_plays, df_week1_plays_cleaned)\n",
        "\n",
        "for i in dict_unclean_to_clean_kickoff_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_kickoff_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "v3xyxhdmaJNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All onside kicks\n",
        "\n",
        "df_unclean_kickoff_onside_plays = week1_2023_plays_modified.loc[week1_2023_plays_modified['PlayOutcome'].str.contains('kickoff', case=False) &\n",
        "                                                                week1_2023_plays_modified['PlayDescription'].str.contains('onside', case=False)]\n",
        "\n",
        "dict_unclean_to_clean_kickoff_onside_plays = unclean_clean_matches(df_unclean_kickoff_onside_plays, df_week1_plays_cleaned)\n",
        "\n",
        "for i in dict_unclean_to_clean_kickoff_onside_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_kickoff_onside_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "kNwyWsNpxZoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Touchdown plays"
      ],
      "metadata": {
        "id": "3i6ytmPQ5463"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All touchdown plays\n",
        "\n",
        "df_unclean_touchdown_plays = week1_2023_plays_modified.loc[week1_2023_plays_modified['PlayOutcome'].str.contains('touchdown', case=False)]\n",
        "\n",
        "dict_unclean_to_clean_touchdown_plays = unclean_clean_matches(df_unclean_touchdown_plays, df_week1_plays_cleaned)\n",
        "\n",
        "for i in dict_unclean_to_clean_touchdown_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_touchdown_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "VSyeKr6X596o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Field goals"
      ],
      "metadata": {
        "id": "btd2EUHxtbL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All field goal plays\n",
        "\n",
        "df_unclean_fieldgoal_week1 = week1_2023_plays_modified[week1_2023_plays_modified['PlayOutcome'].str.contains('Field Goal')]\n",
        "\n",
        "dict_unclean_to_clean_field_goal_plays = unclean_clean_matches(df_unclean_fieldgoal_week1, df_week1_plays_cleaned)\n",
        "\n",
        "# Number of field goal plays\n",
        "print(f\"{len(dict_unclean_to_clean_field_goal_plays)} number of field goal plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_field_goal_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_field_goal_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "pqBe7NSa3Jlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All field goal plays (good)\n",
        "\n",
        "made_field_goal_play_indexes = []\n",
        "\n",
        "for i in list(df_2023_fieldgoal_week1.index):\n",
        "  made_field_goal = re.findall(field_goal_good_pattern, week1_2023_plays_modified['PlayDescription'].iloc[i])\n",
        "  if len(made_field_goal) > 0:\n",
        "    made_field_goal_play_indexes.append(i)\n",
        "\n",
        "dict_unclean_to_clean_good_field_goals = unclean_clean_matches(week1_2023_plays_modified.iloc[made_field_goal_play_indexes], df_week1_plays_cleaned)\n",
        "\n",
        "# Number of field goal plays\n",
        "print(f\"{len(dict_unclean_to_clean_good_field_goals)} number of good field goal plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_good_field_goals.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_good_field_goals.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "Gji9ZboHcBQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All field goal plays (no good)\n",
        "\n",
        "no_good_field_goal_play_indexes = []\n",
        "\n",
        "for i in list(df_2023_fieldgoal_week1.index):\n",
        "  made_field_goal = re.findall(field_goal_no_good_pattern, week1_2023_plays_modified['PlayDescription'].iloc[i])\n",
        "  if len(made_field_goal) > 0:\n",
        "    no_good_field_goal_play_indexes.append(i)\n",
        "\n",
        "dict_unclean_to_clean_no_good_field_goals = unclean_clean_matches(week1_2023_plays_modified.iloc[no_good_field_goal_play_indexes], df_week1_plays_cleaned)\n",
        "\n",
        "# Number of field goal plays\n",
        "print(f\"{len(dict_unclean_to_clean_no_good_field_goals)} number of no good field goal plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_no_good_field_goals.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_no_good_field_goals.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "-P5Mz-AfdgxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All field goal plays (special)\n",
        "\n",
        "special_field_goal_play_indexes = []\n",
        "\n",
        "special_field_goal_play_indexes = list(df_2023_fieldgoal_week1.index)\n",
        "\n",
        "for i in made_field_goal_play_indexes:\n",
        "  special_field_goal_play_indexes.pop(special_field_goal_play_indexes.index(i))\n",
        "\n",
        "for i in no_good_field_goal_play_indexes:\n",
        "  special_field_goal_play_indexes.pop(special_field_goal_play_indexes.index(i))\n",
        "\n",
        "\n",
        "dict_unclean_to_clean_special_field_goals = unclean_clean_matches(week1_2023_plays_modified.iloc[special_field_goal_play_indexes], df_week1_plays_cleaned)\n",
        "\n",
        "# Number of field goal plays\n",
        "print(f\"{len(dict_unclean_to_clean_special_field_goals)} number of special field goal plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_special_field_goals.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_special_field_goals.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "h-vMwKQWgN27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extra Points"
      ],
      "metadata": {
        "id": "QHp6b-_SqOw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All extra point plays\n",
        "\n",
        "df_unclean_extrapoint_week1 = week1_2023_plays_modified[week1_2023_plays_modified['PlayOutcome'].str.contains('Extra Point')]\n",
        "\n",
        "dict_unclean_to_clean_extrapoint = unclean_clean_matches(df_unclean_extrapoint_week1, df_week1_plays_cleaned)\n",
        "\n",
        "print(f\"{len(dict_unclean_to_clean_extrapoint)} number of field goal plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_extrapoint.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_extrapoint.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "BzJ6erNaqT9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All extra point plays (good)\n",
        "\n",
        "extra_point_good_index_list = []\n",
        "\n",
        "for i in list(df_2023_extrapoint_week1.index):\n",
        "  made_extra_point = re.findall(extra_point_good_pattern, week1_2023_plays_modified['PlayDescription'].iloc[i])\n",
        "  if len(made_extra_point) > 0:\n",
        "    extra_point_good_index_list.append(i)\n",
        "\n",
        "dict_unclean_to_clean_extrapoint_good = unclean_clean_matches(week1_2023_plays_modified.iloc[extra_point_good_index_list], df_week1_plays_cleaned)\n",
        "\n",
        "print(f\"{len(dict_unclean_to_clean_extrapoint_good)} number of field goal plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_extrapoint_good.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_extrapoint_good.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "vt8dClZ3r6mL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All extra point plays (no good)\n",
        "\n",
        "extra_point_no_good_index_list = []\n",
        "\n",
        "for i in list(df_2023_extrapoint_week1.index):\n",
        "  no_good_extra_point = re.findall(extra_point_no_good_pattern, week1_2023_plays_modified['PlayDescription'].iloc[i])\n",
        "  if len(no_good_extra_point) > 0:\n",
        "    extra_point_no_good_index_list.append(i)\n",
        "\n",
        "dict_unclean_to_clean_extrapoint_no_good = unclean_clean_matches(week1_2023_plays_modified.iloc[extra_point_no_good_index_list], df_week1_plays_cleaned)\n",
        "\n",
        "print(f\"{len(dict_unclean_to_clean_extrapoint_no_good)} number of field goal plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_extrapoint_no_good.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_extrapoint_no_good.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "F8lRaoqjt_ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Blocked extra point?"
      ],
      "metadata": {
        "id": "1tEwEZbeu_dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fumbles"
      ],
      "metadata": {
        "id": "MGd9pIPpvtL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All fumbled plays\n",
        "\n",
        "df_unclean_fumble_plays = week1_2023_plays_modified.loc[week1_2023_plays_modified['PlayOutcome'].str.contains('fumble', case=False)]\n",
        "\n",
        "dict_unclean_to_clean_fumble_plays = unclean_clean_matches(df_unclean_fumble_plays, df_week1_plays_cleaned)\n",
        "\n",
        "print(f\"{len(dict_unclean_to_clean_fumble_plays)} number of fumbled plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_fumble_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_fumble_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "ND23U1givw4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All passing fumble plays\n",
        "\n",
        "index_fumble_pass_plays = []\n",
        "\n",
        "for i in list(df_unclean_fumble_plays.index):\n",
        "  fumble_pass = re.findall(receiver_pattern, week1_2023_plays_modified['PlayDescription'].iloc[i])\n",
        "  if len(fumble_pass) > 0:\n",
        "    index_fumble_pass_plays.append(i)\n",
        "\n",
        "dict_unclean_to_clean_fumble_pass = unclean_clean_matches(week1_2023_plays_modified.iloc[index_fumble_pass_plays], df_week1_plays_cleaned)\n",
        "\n",
        "print(f\"{len(dict_unclean_to_clean_fumble_pass)} number of passing fumble plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_fumble_pass.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_fumble_pass.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "QmW0-6AQCRWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All rushing fumble plays\n",
        "\n",
        "index_fumble_run_plays = []\n",
        "\n",
        "for i in list(df_unclean_fumble_plays.index):\n",
        "  fumble_pass = re.findall(rusher_pattern, week1_2023_plays_modified['PlayDescription'].iloc[i])\n",
        "  if len(fumble_pass) > 0:\n",
        "    index_fumble_run_plays.append(i)\n",
        "\n",
        "dict_unclean_to_clean_fumble_run = unclean_clean_matches(week1_2023_plays_modified.iloc[index_fumble_run_plays], df_week1_plays_cleaned)\n",
        "\n",
        "print(f\"{len(dict_unclean_to_clean_fumble_run)} number of rushing fumble plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_fumble_run.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_fumble_run.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "1lk810wiLm9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All sacked fumble plays\n",
        "\n",
        "index_fumble_sacked_plays = []\n",
        "\n",
        "for i in list(df_unclean_fumble_plays.index):\n",
        "  if week1_2023_plays_modified['PlayDescription'].iloc[i].find('sacked') != -1:\n",
        "    index_fumble_sacked_plays.append(i)\n",
        "\n",
        "dict_unclean_to_clean_sacked_fumble = unclean_clean_matches(week1_2023_plays_modified.iloc[index_fumble_sacked_plays], df_week1_plays_cleaned)\n",
        "\n",
        "print(f\"{len(dict_unclean_to_clean_sacked_fumble)} number of sacked fumble plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_sacked_fumble.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_sacked_fumble.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "gNczGRV1OXrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All Aborted fumbled plays\n",
        "\n",
        "# week1_2023_plays['PlayOutcome'].str.contains('fumble', case=False)\n",
        "\n",
        "index_fumble_aborted_plays = []\n",
        "\n",
        "for i in list(df_unclean_fumble_plays.index):\n",
        "  if week1_2023_plays_modified['PlayDescription'].iloc[i].find('Aborted') != -1:\n",
        "    index_fumble_aborted_plays.append(i)\n",
        "\n",
        "dict_unclean_to_clean_aborted_fumble = unclean_clean_matches(week1_2023_plays_modified.iloc[index_fumble_aborted_plays], df_week1_plays_cleaned)\n",
        "\n",
        "print(f\"{len(dict_unclean_to_clean_aborted_fumble)} number of aborted fumble plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_aborted_fumble.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_aborted_fumble.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "H2wwjFbnMiL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All special fumbled plays\n",
        "\n",
        "index_fumble_special_plays = list(df_unclean_fumble_plays.index)\n",
        "\n",
        "for i in index_fumble_pass_plays:\n",
        "  index_fumble_special_plays.pop(index_fumble_special_plays.index(i))\n",
        "\n",
        "for i in index_fumble_run_plays:\n",
        "  index_fumble_special_plays.pop(index_fumble_special_plays.index(i))\n",
        "\n",
        "for i in index_fumble_sacked_plays:\n",
        "  index_fumble_special_plays.pop(index_fumble_special_plays.index(i))\n",
        "\n",
        "for i in index_fumble_aborted_plays:\n",
        "  index_fumble_special_plays.pop(index_fumble_special_plays.index(i))\n",
        "\n",
        "dict_unclean_to_clean_fumble_special = unclean_clean_matches(week1_2023_plays_modified.iloc[index_fumble_special_plays], df_week1_plays_cleaned)\n",
        "\n",
        "print(f\"{len(dict_unclean_to_clean_fumble_special)} number of special fumble plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_fumble_special.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_fumble_special.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "iADR1LRbMaUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Penalties"
      ],
      "metadata": {
        "id": "Qh-8uXf-lvh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the difference between these penalties and penalties in other play outcomes?\n",
        "\n",
        "# All plays with \"penalty\" outcomes\n",
        "\n",
        "df_unclean_penalty_plays = week1_2023_plays_modified.loc[week1_2023_plays_modified['PlayOutcome'].str.contains('penalty', case=False)]\n",
        "\n",
        "dict_unclean_to_clean_penalty_plays = unclean_clean_matches(df_unclean_penalty_plays, df_week1_plays_cleaned)\n",
        "\n",
        "# Number of penalty plays\n",
        "print(f\"{len(df_unclean_penalty_plays)} number of penalty plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_penalty_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_penalty_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "pHVJ2VCGlz15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All passing plays with \"penalty\" outcomes\n",
        "\n",
        "# Grabbing all penalty plays within original dataframe\n",
        "df_unclean_penalty_plays = week1_2023_plays_modified.loc[week1_2023_plays_modified['PlayOutcome'].str.contains('penalty', case=False)]\n",
        "\n",
        "# List for all indexes that are passing play type penalty plays\n",
        "list_unclean_penalty_passing_plays = []\n",
        "\n",
        "for idx, play in df_unclean_penalty_plays['PlayDescription'].items():\n",
        "  passing_play = re.findall(receiver_pattern, play)\n",
        "  if len(passing_play) > 0 or play.find('pass incomplete') != -1:\n",
        "    list_unclean_penalty_passing_plays.append(idx)\n",
        "\n",
        "# Dataframe of all passing plays with \"penalty\" outcomes\n",
        "df_unclean_penalty_passing_plays = week1_2023_plays_modified.iloc[list_unclean_penalty_passing_plays]\n",
        "\n",
        "dict_unclean_to_clean_penalty_passing_plays = unclean_clean_matches(df_unclean_penalty_passing_plays, df_week1_plays_cleaned)\n",
        "\n",
        "# Number of passing penalty plays\n",
        "print(f\"{len(list_unclean_penalty_passing_plays)} number of passing penalty plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_penalty_passing_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_penalty_passing_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "OZSjt3sOAiGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All rushing plays with \"penalty\" outcomes\n",
        "\n",
        "# Grabbing all penalty plays within original dataframe\n",
        "df_unclean_penalty_plays = week1_2023_plays_modified.loc[week1_2023_plays_modified['PlayOutcome'].str.contains('penalty', case=False)]\n",
        "\n",
        "# List for all indexes that are passing play type penalty plays\n",
        "list_unclean_penalty_rushing_plays = []\n",
        "\n",
        "for idx, play in df_unclean_penalty_plays['PlayDescription'].items():\n",
        "  passing_play = re.findall(rusher_pattern, play)\n",
        "  if len(passing_play) > 0 or play.find('Aborted') != -1:\n",
        "    list_unclean_penalty_rushing_plays.append(idx)\n",
        "\n",
        "# Dataframe of all passing plays with \"penalty\" outcomes\n",
        "df_unclean_penalty_rushing_plays = week1_2023_plays_modified.iloc[list_unclean_penalty_rushing_plays]\n",
        "\n",
        "dict_unclean_to_clean_penalty_rushing_plays = unclean_clean_matches(df_unclean_penalty_rushing_plays, df_week1_plays_cleaned)\n",
        "\n",
        "# Number of rushing penalty plays\n",
        "print(f\"{len(list_unclean_penalty_rushing_plays)} number of passing penalty plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_penalty_rushing_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_penalty_rushing_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "5Qpv1m_vL25t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All \"False Start\" or \"Delay of Game\" plays with \"penalty\" outcomes\n",
        "\n",
        "# Grabbing all penalty plays within original dataframe\n",
        "df_unclean_penalty_plays = week1_2023_plays_modified.loc[week1_2023_plays_modified['PlayOutcome'].str.contains('penalty', case=False)]\n",
        "\n",
        "# List for all indexes that are passing play type penalty plays\n",
        "list_unclean_penalty_false_start_plays = []\n",
        "\n",
        "for idx, play in df_unclean_penalty_plays['PlayDescription'].items():\n",
        "  if play.find('False Start') != -1 or play.find('Delay of Game') != -1:\n",
        "    list_unclean_penalty_false_start_plays.append(idx)\n",
        "\n",
        "dict_unclean_to_clean_penalty_false_start_plays = unclean_clean_matches(week1_2023_plays_modified.iloc[list_unclean_penalty_false_start_plays], df_week1_plays_cleaned)\n",
        "\n",
        "# Number of rushing penalty plays\n",
        "print(f\"{len(list_unclean_penalty_false_start_plays)} number of false start plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_penalty_false_start_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_penalty_false_start_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "30VBAHc2llk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All sacked plays with \"penalty\" outcomes\n",
        "\n",
        "# Grabbing all penalty plays within original dataframe\n",
        "df_unclean_penalty_plays = week1_2023_plays_modified.loc[week1_2023_plays_modified['PlayOutcome'].str.contains('penalty', case=False)]\n",
        "\n",
        "# List for all indexes that are passing play type penalty plays\n",
        "list_unclean_penalty_sacked_plays = []\n",
        "\n",
        "for idx, play in df_unclean_penalty_plays['PlayDescription'].items():\n",
        "  if play.find('sacked') != -1:\n",
        "    list_unclean_penalty_sacked_plays.append(idx)\n",
        "\n",
        "dict_unclean_to_clean_penalty_sacked_plays = unclean_clean_matches(week1_2023_plays_modified.iloc[list_unclean_penalty_sacked_plays], df_week1_plays_cleaned)\n",
        "\n",
        "# Number of rushing penalty plays\n",
        "print(f\"{len(list_unclean_penalty_sacked_plays)} number of false start plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_penalty_sacked_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_penalty_sacked_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "UMVplg6mfw6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All TWO-POINT CONVERSION ATTEMPT plays with \"penalty\" outcomes\n",
        "\n",
        "# Grabbing all penalty plays within original dataframe\n",
        "df_unclean_penalty_plays = week1_2023_plays_modified.loc[week1_2023_plays_modified['PlayOutcome'].str.contains('penalty', case=False)]\n",
        "\n",
        "# List for all indexes that are passing play type penalty plays\n",
        "list_unclean_penalty_2pt_plays = []\n",
        "\n",
        "for idx, play in df_unclean_penalty_plays['PlayDescription'].items():\n",
        "  if play.find('TWO-POINT CONVERSION ATTEMPT') != -1:\n",
        "    list_unclean_penalty_2pt_plays.append(idx)\n",
        "\n",
        "dict_unclean_to_clean_penalty_2pt_plays = unclean_clean_matches(week1_2023_plays_modified.iloc[list_unclean_penalty_2pt_plays], df_week1_plays_cleaned)\n",
        "\n",
        "# Number of rushing penalty plays\n",
        "print(f\"{len(list_unclean_penalty_2pt_plays)} number of false start plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_penalty_2pt_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_penalty_2pt_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "QEH-KU0arHXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All special plays with \"penalty\" outcomes\n",
        "\n",
        "# Grabbing all penalty plays within original dataframe\n",
        "df_unclean_penalty_plays = week1_2023_plays_modified.loc[week1_2023_plays_modified['PlayOutcome'].str.contains('penalty', case=False)]\n",
        "\n",
        "# List for all indexes that are passing play type penalty plays\n",
        "list_unclean_penalty_special_plays = list(df_unclean_penalty_plays.index)\n",
        "\n",
        "for i in list_unclean_penalty_passing_plays:\n",
        "  list_unclean_penalty_special_plays.pop(list_unclean_penalty_special_plays.index(i))\n",
        "\n",
        "for i in list_unclean_penalty_rushing_plays:\n",
        "  list_unclean_penalty_special_plays.pop(list_unclean_penalty_special_plays.index(i))\n",
        "\n",
        "for i in list_unclean_penalty_false_start_plays:\n",
        "  list_unclean_penalty_special_plays.pop(list_unclean_penalty_special_plays.index(i))\n",
        "\n",
        "for i in list_unclean_penalty_sacked_plays:\n",
        "  list_unclean_penalty_special_plays.pop(list_unclean_penalty_special_plays.index(i))\n",
        "\n",
        "for i in list_unclean_penalty_2pt_plays:\n",
        "  list_unclean_penalty_special_plays.pop(list_unclean_penalty_special_plays.index(i))\n",
        "\n",
        "dict_unclean_to_clean_penalty_special_plays = unclean_clean_matches(week1_2023_plays_modified.iloc[list_unclean_penalty_special_plays], df_week1_plays_cleaned)\n",
        "\n",
        "# Number of rushing penalty plays\n",
        "print(f\"{len(list_unclean_penalty_special_plays)} number of passing penalty plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_penalty_special_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_penalty_special_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "hIrreRJvMffs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Turnover On Downs"
      ],
      "metadata": {
        "id": "I4cK_IySHwL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All turnover on downs\n",
        "\n",
        "df_unclean_turnover_on_downs_week1 = week1_2023_plays_modified[week1_2023_plays_modified['PlayOutcome'].str.contains('Turnover on Downs')]\n",
        "\n",
        "dict_unclean_to_clean_turnover_on_downs = unclean_clean_matches(df_unclean_turnover_on_downs_week1, df_week1_plays_cleaned)\n",
        "\n",
        "print(f\"{len(dict_unclean_to_clean_turnover_on_downs)} number of field goal plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_turnover_on_downs.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_turnover_on_downs.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "1jlEnCQ0H1PV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Index searching"
      ],
      "metadata": {
        "id": "JdoApDwkC6RV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "week1_2023_plays_modified.iloc[0]"
      ],
      "metadata": {
        "id": "fXLWIM32UKmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_week1_plays_cleaned.iloc[379]\n",
        "df_week1_plays_cleaned.iloc[833]\n",
        "# df_week1_plays_cleaned['PlayDescription'].iloc[832]"
      ],
      "metadata": {
        "id": "Gn363g0xpdHH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4210098e-af36-46a9-8fef-dc044dfd81ca"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Season                                                  2023\n",
              "Week                                                  Week 1\n",
              "Day                                                      SUN\n",
              "Date                                                   09/10\n",
              "AwayTeam                                             Cowboys\n",
              "HomeTeam                                              Giants\n",
              "Quarter                                                    1\n",
              "DriveNumber                                                1\n",
              "TeamWithPossession                                       NYG\n",
              "IsScoringDrive                                             1\n",
              "PlayNumberInDrive                                         13\n",
              "IsScoringPlay                                              1\n",
              "PlayOutcome                                Touchdown Cowboys\n",
              "PlayDescription       N.Igbinoghene for 58 yards, TOUCHDOWN.\n",
              "PlayStart                                 4th & 21 at DAL 27\n",
              "PlayType                                                 nan\n",
              "TimeOnTheClock                                          8:14\n",
              "Formation                                                nan\n",
              "Passer                                                   nan\n",
              "Rusher                                                   nan\n",
              "Receiver                                                 nan\n",
              "Direction                                                nan\n",
              "Yardage                                                  NaN\n",
              "SoloTackle                                               nan\n",
              "AssistedTackle                                           nan\n",
              "SharedTackle                                             nan\n",
              "PressureBy                                               nan\n",
              "InterceptedBy                                            nan\n",
              "SackedBy                                                 nan\n",
              "ForcedFumbleBy                                           nan\n",
              "FumbleDetails         N.Igbinoghene for 58 yards, TOUCHDOWN.\n",
              "ReverseDetails                                           nan\n",
              "InjuredPlayers                                           nan\n",
              "OffensivePenalty                                         nan\n",
              "DefensivePenalty                                         nan\n",
              "Kicker                                                   nan\n",
              "LongSnapper                                              nan\n",
              "Returner                                                 nan\n",
              "DownedBy                                                 nan\n",
              "Holder                                                   nan\n",
              "BlockedBy                                                nan\n",
              "AcceptedPenalty                                          NaN\n",
              "DeclinedPenalty                                          NaN\n",
              "Name: 833, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>833</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Season</th>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Week</th>\n",
              "      <td>Week 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Day</th>\n",
              "      <td>SUN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <td>09/10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AwayTeam</th>\n",
              "      <td>Cowboys</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HomeTeam</th>\n",
              "      <td>Giants</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Quarter</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DriveNumber</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TeamWithPossession</th>\n",
              "      <td>NYG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IsScoringDrive</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PlayNumberInDrive</th>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IsScoringPlay</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PlayOutcome</th>\n",
              "      <td>Touchdown Cowboys</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PlayDescription</th>\n",
              "      <td>N.Igbinoghene for 58 yards, TOUCHDOWN.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PlayStart</th>\n",
              "      <td>4th &amp; 21 at DAL 27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PlayType</th>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TimeOnTheClock</th>\n",
              "      <td>8:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Formation</th>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Passer</th>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Rusher</th>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Receiver</th>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Direction</th>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Yardage</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SoloTackle</th>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AssistedTackle</th>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SharedTackle</th>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PressureBy</th>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>InterceptedBy</th>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SackedBy</th>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ForcedFumbleBy</th>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FumbleDetails</th>\n",
              "      <td>N.Igbinoghene for 58 yards, TOUCHDOWN.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ReverseDetails</th>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>InjuredPlayers</th>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OffensivePenalty</th>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DefensivePenalty</th>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Kicker</th>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LongSnapper</th>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Returner</th>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DownedBy</th>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Holder</th>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BlockedBy</th>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AcceptedPenalty</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DeclinedPenalty</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CLEANED DATASET OBSERVATIONS\n",
        "- Attempting to grab basic stats on players for a single game"
      ],
      "metadata": {
        "id": "TrudwcGMsfXh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Methods"
      ],
      "metadata": {
        "id": "sGpFgVAxl6Zd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get rid of duplicate rows (for play's that have multiple rows)\n",
        "\n",
        "def no_duplicates(df_with_duplicates, index_start=None):\n",
        "\n",
        "  # exit case\n",
        "  # - The last element has been grabbed\n",
        "  if df_with_duplicates.tail(1).index[0] == index_start:\n",
        "    return df_with_duplicates\n",
        "\n",
        "  if index_start == None:\n",
        "    index_start = df_with_duplicates.index[0]\n",
        "\n",
        "  first_element = df_with_duplicates.loc[index_start]\n",
        "\n",
        "  second_element = df_with_duplicates.iloc[df_with_duplicates.index.tolist().index(index_start)+1]\n",
        "\n",
        "  # Features that will decipher whether the two rows are apart of the same play\n",
        "  matching_features = ['Season', 'Week', 'Date', 'AwayTeam', 'HomeTeam', 'Quarter', 'DriveNumber', 'TeamWithPossession', 'PlayNumberInDrive']\n",
        "\n",
        "  # - Check to see if 1st and 2nd elements are match\n",
        "  if first_element[matching_features].equals(second_element[matching_features]):\n",
        "    # 1. remove 2nd element\n",
        "    df_with_duplicates = df_with_duplicates.drop(df_with_duplicates.index[df_with_duplicates.index.tolist().index(index_start)+1], inplace=False)\n",
        "    # 2. run method starting search from 1st element\n",
        "    #    - This is in case more matches to 1st element\n",
        "    return no_duplicates(df_with_duplicates, index_start)\n",
        "  else:\n",
        "    # 1. run method starting search from 2nd element\n",
        "    #    - 2nd element will become '1st element'\n",
        "    #    - after 2nd element will become '2nd element'\n",
        "    return no_duplicates(df_with_duplicates, df_with_duplicates.index[df_with_duplicates.index.tolist().index(index_start)+1])"
      ],
      "metadata": {
        "id": "LPch-YQYl9it"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Table Creation**\n",
        "- Goal is to mirror tables on NFL.com for testing purposes"
      ],
      "metadata": {
        "id": "IADrQKYwERwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the scoring table for a specified game.\n",
        "\n",
        "def score_table(away_team, home_team, df_cleaned_plays, dict_of_teams):\n",
        "  df_all_plays_in_game = df_cleaned_plays.loc[(df_cleaned_plays['HomeTeam'] == home_team) &\n",
        "                                              (df_cleaned_plays['AwayTeam'] == away_team)]\n",
        "\n",
        "  df_all_plays_in_game = no_duplicates(df_all_plays_in_game)\n",
        "\n",
        "  teams = [[away_team],[home_team]]\n",
        "\n",
        "  for i in range(len(teams)):\n",
        "    total_score = 0\n",
        "    for quarter in df_all_plays_in_game['Quarter'].unique():\n",
        "      quarter_score = 0\n",
        "\n",
        "      # touchdowns\n",
        "      df_touchdowns_in_quarter = df_all_plays_in_game.loc[(df_all_plays_in_game['PlayOutcome'].str.contains(f'touchdown {teams[i]}', case=False)) &\n",
        "                                                          (df_all_plays_in_game['Quarter'] == quarter)]\n",
        "      quarter_score += df_touchdowns_in_quarter.shape[0] * 6\n",
        "\n",
        "      # PAT\n",
        "      df_extra_points_in_quarter = df_all_plays_in_game.loc[(df_all_plays_in_game['PlayOutcome'].str.contains('Extra Point Good', case=False)) &\n",
        "                                                            (df_all_plays_in_game['Quarter'] == quarter) &\n",
        "                                                            (df_all_plays_in_game['TeamWithPossession'] == dict_of_teams.get(teams[i][0]))]\n",
        "      quarter_score += df_extra_points_in_quarter.shape[0] * 1\n",
        "\n",
        "      # field goals\n",
        "      df_field_goals_in_quarter = df_all_plays_in_game.loc[(df_all_plays_in_game['PlayOutcome'].str.contains('Field Goal Good', case = False)) &\n",
        "                                                          (df_all_plays_in_game['Quarter'] == quarter) &\n",
        "                                                          (df_all_plays_in_game['TeamWithPossession'] == dict_of_teams.get(teams[i][0]))]\n",
        "      quarter_score += df_field_goals_in_quarter.shape[0] * 3\n",
        "\n",
        "      teams[i].append(quarter_score)\n",
        "      total_score += quarter_score\n",
        "\n",
        "    teams[i].append(total_score)\n",
        "    teams[i].pop(0)\n",
        "\n",
        "  scoring_columns = df_all_plays_in_game['Quarter'].unique().tolist()\n",
        "\n",
        "  scoring_columns.append(\"Total\")\n",
        "\n",
        "  return pd.DataFrame(teams, columns = scoring_columns, index=[dict_of_teams.get(away_team), dict_of_teams.get(home_team)])"
      ],
      "metadata": {
        "id": "2DeKkFFpqIAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display Quarterback stats for a specified game\n",
        "\n",
        "def quarterback_table(away_team, home_team, df_cleaned_plays, dict_acronym_to_team):\n",
        "\n",
        "  # All plays within game\n",
        "  df_all_plays_in_game = df_cleaned_plays.loc[(df_cleaned_plays['HomeTeam'] == home_team) &\n",
        "                                              (df_cleaned_plays['AwayTeam'] == away_team)]\n",
        "\n",
        "  # list of quarterbacks in game\n",
        "  list_qbs = df_all_plays_in_game['Passer'].unique().tolist()\n",
        "  if 'nan' in list_qbs:\n",
        "    list_qbs.pop(list_qbs.index('nan'))\n",
        "\n",
        "  #   key: quarterback\n",
        "  # value: team\n",
        "  dict_qbs_to_team = {}\n",
        "  for qb in list_qbs:\n",
        "    dict_qbs_to_team[qb] = dict_acronym_to_team.get(df_all_plays_in_game['TeamWithPossession'].loc[df_all_plays_in_game['Passer'] == qb].value_counts().index[0])\n",
        "\n",
        "  df_quarterback_data = pd.DataFrame(columns=[\"CP/ATT\", \"YDS\", \"TD\", \"INT\"], index = list(dict_qbs_to_team.keys()))\n",
        "\n",
        "  # Grabbing data for each quarterback in game\n",
        "  for qb in df_quarterback_data.index:\n",
        "\n",
        "    passing_attempts = df_all_plays_in_game.loc[(df_all_plays_in_game['Passer'] == qb) &\n",
        "                                                (df_all_plays_in_game['PlayType'] == \"Pass\")]\n",
        "\n",
        "    passing_completions = passing_attempts.loc[(passing_attempts['PlayOutcome'].str.contains('yard pass', case=False)) |\n",
        "                                               (passing_attempts['PlayOutcome'].str.contains(f'touchdown {dict_qbs_to_team.get(qb)}', case=False)) |\n",
        "                                               (passing_attempts['PlayOutcome'].str.contains(\"Turnover On Downs \\(C\\)\", case=False)) |\n",
        "                                               (passing_attempts['PlayOutcome'].str.contains(\"Pass for No Gain\", case=False)) |\n",
        "                                               (passing_attempts['PlayOutcome'].str.contains(\"Fumble \\(C\\)\", case=False))]\n",
        "\n",
        "    df_quarterback_data.loc[qb, 'CP/ATT'] = f\"{passing_completions.shape[0]}/{passing_attempts.shape[0]}\"\n",
        "\n",
        "    df_quarterback_data.loc[qb, 'YDS'] = int(passing_completions['Yardage'].sum())\n",
        "\n",
        "    total_touchdowns = passing_completions.loc[passing_completions['PlayOutcome'].str.contains(f'touchdown {dict_qbs_to_team.get(qb)}', case=False)]\n",
        "\n",
        "    df_quarterback_data.loc[qb, 'TD'] = total_touchdowns.shape[0]\n",
        "\n",
        "    total_interceptions = passing_attempts.loc[passing_attempts['PlayDescription'].str.contains('intercepted', case=False)]\n",
        "\n",
        "    df_quarterback_data.loc[qb, 'INT'] = total_interceptions.shape[0]\n",
        "\n",
        "  return df_quarterback_data"
      ],
      "metadata": {
        "id": "HltCrmDut2pV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Home and Away teams (Week 1, 2023)"
      ],
      "metadata": {
        "id": "lXOsRYYuiXxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Season 2023 Week 1 schedule\n",
        "\n",
        "df_2023_week1_schedule = df_week1_plays_cleaned[['HomeTeam', 'AwayTeam', 'Season', 'Date', 'Day']].drop_duplicates().sort_values(by='Date').reset_index(drop=True)\n",
        "\n",
        "df_2023_week1_schedule"
      ],
      "metadata": {
        "id": "B6IG2fOYiKXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_teams = {\n",
        "    'Cardinals': 'ARI', 'Falcons': 'ATL', 'Ravens': 'BAL', 'Bills': 'BUF', 'Panthers': 'CAR', 'Bears': 'CHI',\n",
        "    'Bengals': 'CIN', 'Browns': 'CLE', 'Cowboys': 'DAL', 'Broncos': 'DEN', 'Lions': 'DET', 'Packers': 'GB',\n",
        "    'Texans': 'HOU', 'Colts': 'IND', 'Jaguars': 'JAX', 'Chiefs': 'KC', 'Raiders': 'LV', 'Chargers': 'LAC',\n",
        "    'Rams': 'LAR', 'Dolphins': 'MIA', 'Vikings': 'MIN', 'Patriots': 'NE', 'Saints': 'NO', 'Giants': 'NYG',\n",
        "    'Jets': 'NYJ', 'Eagles': 'PHI', 'Steelers': 'PIT', '49ers': 'SF', 'Seahawks': 'SEA', 'Buccaneers': 'TB',\n",
        "    'Titans': 'TEN', 'Commanders': 'WAS'\n",
        "}"
      ],
      "metadata": {
        "id": "9sfGIEjQpVm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_teams_2 = {\n",
        "    'ARI': 'Cardinals', 'ATL': 'Falcons', 'BAL': 'Ravens', 'BUF': 'Bills', 'CAR': 'Panthers', 'CHI': 'Bears',\n",
        "    'CIN': 'Bengals', 'CLE': 'Browns', 'DAL': 'Cowboys', 'DEN': 'Broncos', 'DET': 'Lions', 'GB': 'Packers',\n",
        "    'HOU': 'Texans', 'IND': 'Colts', 'JAX': 'Jaguars', 'KC': 'Chiefs', 'LV': 'Raiders', 'LAC': 'Chargers',\n",
        "    'LAR': 'Rams', 'MIA': 'Dolphins', 'MIN': 'Vikings', 'NE': 'Patriots', 'NO': 'Saints', 'NYG': 'Giants',\n",
        "    'NYJ': 'Jets', 'PHI': 'Eagles', 'PIT': 'Steelers', 'SF': '49ers', 'SEA': 'Seahawks', 'TB': 'Buccaneers',\n",
        "    'TEN': 'Titans', 'WAS': 'Commanders'\n",
        "}"
      ],
      "metadata": {
        "id": "4pRagKkwJJYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scoring Table\n",
        "COLUMNS:\n",
        "- Each quarter of the game\n",
        "ROW:\n",
        "- Each team playing in game"
      ],
      "metadata": {
        "id": "IbnuMAHp2Pvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Some games may not have every play recorded.\n",
        "# (Week 1 2023, Game 1, 3rd quarter)\n",
        "# - A field goal was supposed to be recorded after the interception touchdown but\n",
        "#   was not.\n",
        "\n",
        "game_num = 10\n",
        "\n",
        "away_team = df_2023_week1_schedule['AwayTeam'].iloc[game_num]\n",
        "home_team = df_2023_week1_schedule['HomeTeam'].iloc[game_num]\n",
        "\n",
        "score_table(away_team, home_team, df_week1_plays_cleaned, dict_teams)"
      ],
      "metadata": {
        "id": "mXun6Zd1Chv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Passing Table\n",
        "\n",
        "INDEX:\n",
        "- Each quarterback that played in game\n",
        "COLUMNS:\n",
        "- CP/ATT - completions / pass attempts\n",
        "- YDS - total passing yards\n",
        "- TD - total touchdowns thrown\n",
        "- INT - total interceptions thrown"
      ],
      "metadata": {
        "id": "Kdc7wdnwTtn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "game_num = 10\n",
        "\n",
        "away_team = df_2023_week1_schedule['AwayTeam'].iloc[game_num]\n",
        "home_team = df_2023_week1_schedule['HomeTeam'].iloc[game_num]\n",
        "\n",
        "quarterback_table(away_team, home_team, df_week1_plays_cleaned, dict_teams_2)"
      ],
      "metadata": {
        "id": "SGD3bhunlUXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rushing Table"
      ],
      "metadata": {
        "id": "xW16zozSakCk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "game_num = 1\n",
        "\n",
        "away_team = df_2023_week1_schedule['AwayTeam'].iloc[game_num]\n",
        "home_team = df_2023_week1_schedule['HomeTeam'].iloc[game_num]\n",
        "\n",
        "df_all_plays_in_game = df_week1_plays_cleaned.loc[(df_week1_plays_cleaned['HomeTeam'] == home_team) &\n",
        "                                                  (df_week1_plays_cleaned['AwayTeam'] == away_team)]\n",
        "\n",
        "df_home_rushing_plays = df_all_plays_in_game.loc[(df_all_plays_in_game['PlayType'].str.contains('run', case=False)) &\n",
        "                                                 (df_all_plays_in_game['TeamWithPossession'] == dict_teams.get(home_team))]\n",
        "\n",
        "df_away_rushing_plays = df_all_plays_in_game.loc[(df_all_plays_in_game['PlayType'].str.contains('run', case=False)) &\n",
        "                                                 (df_all_plays_in_game['TeamWithPossession'] == dict_teams.get(away_team))]\n",
        "\n",
        "home_team_rushers = df_home_rushing_plays['Rusher'].unique().tolist()\n",
        "\n",
        "if 'nan' in home_team_rushers:\n",
        "  home_team_rushers.pop(home_team_rushers.index('nan'))\n",
        "\n",
        "away_team_rushers = df_away_rushing_plays['Rusher'].unique().tolist()\n",
        "\n",
        "if 'nan' in away_team_rushers:\n",
        "  away_team_rushers.pop(away_team_rushers.index('nan'))"
      ],
      "metadata": {
        "id": "H7tYT4NTa19i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# home\n",
        "\n",
        "df_rusher_data = pd.DataFrame(columns=[\"CAR\", \"YDS\", \"TD\", \"AVG\"], index = home_team_rushers)\n",
        "\n",
        "for rb in df_rusher_data.index:\n",
        "  rusher_plays = df_home_rushing_plays.loc[df_home_rushing_plays['Rusher'] == rb]\n",
        "  df_rusher_data.loc[rb, 'CAR'] = rusher_plays.shape[0]\n",
        "  df_rusher_data.loc[rb, 'YDS'] = int(rusher_plays['Yardage'].sum())\n",
        "  df_rusher_data.loc[rb, 'TD'] = rusher_plays.loc[rusher_plays['PlayOutcome'].str.contains('touchdown', case=False)].shape[0]\n",
        "  df_rusher_data.loc[rb, 'AVG'] = round(rusher_plays['Yardage'].mean(), 2)\n",
        "\n",
        "df_rusher_data.sort_values(by=\"YDS\", ascending=False, inplace=True)\n",
        "df_rusher_data"
      ],
      "metadata": {
        "id": "Mg3FyXBdhY2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# away\n",
        "\n",
        "df_rusher_data = pd.DataFrame(columns=[\"CAR\", \"YDS\", \"TD\", \"AVG\"], index = away_team_rushers)\n",
        "\n",
        "for rb in df_rusher_data.index:\n",
        "  rusher_plays = df_away_rushing_plays.loc[df_away_rushing_plays['Rusher'] == rb]\n",
        "  df_rusher_data.loc[rb, 'CAR'] = rusher_plays.shape[0]\n",
        "  df_rusher_data.loc[rb, 'YDS'] = int(rusher_plays['Yardage'].sum())\n",
        "  df_rusher_data.loc[rb, 'TD'] = rusher_plays.loc[rusher_plays['PlayOutcome'].str.contains('touchdown', case=False)].shape[0]\n",
        "  df_rusher_data.loc[rb, 'AVG'] = round(rusher_plays['Yardage'].mean(), 2)\n",
        "\n",
        "df_rusher_data.sort_values(by=\"YDS\", ascending=False, inplace=True)\n",
        "df_rusher_data"
      ],
      "metadata": {
        "id": "D-foyMHxsgtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rusher_plays = df_away_rushing_plays.loc[df_away_rushing_plays['Rusher'].str.contains('A.Dillon')]\n",
        "\n",
        "for idx, play in rusher_plays['PlayDescription'].items():\n",
        "  print(idx)\n",
        "  play_split = play.split(\". \")\n",
        "  for i in play_split:\n",
        "    print(i)\n",
        "  print()"
      ],
      "metadata": {
        "id": "RHF0yNLvzoeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Receiving Table"
      ],
      "metadata": {
        "id": "_9zT4AJh88P6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check game 0. Need to work on offensive and defensive penalties.\n",
        "\n",
        "game_num = 1\n",
        "\n",
        "away_team = df_2023_week1_schedule['AwayTeam'].iloc[game_num]\n",
        "home_team = df_2023_week1_schedule['HomeTeam'].iloc[game_num]\n",
        "\n",
        "df_all_plays_in_game = df_week1_plays_cleaned.loc[(df_week1_plays_cleaned['HomeTeam'] == home_team) &\n",
        "                                                  (df_week1_plays_cleaned['AwayTeam'] == away_team)]\n",
        "\n",
        "df_home_receiving_plays = df_all_plays_in_game.loc[(df_all_plays_in_game['PlayType'].str.contains('pass', case=False)) &\n",
        "                                                 (df_all_plays_in_game['TeamWithPossession'] == dict_teams.get(home_team))]\n",
        "\n",
        "df_away_receiving_plays = df_all_plays_in_game.loc[(df_all_plays_in_game['PlayType'].str.contains('pass', case=False)) &\n",
        "                                                 (df_all_plays_in_game['TeamWithPossession'] == dict_teams.get(away_team))]\n",
        "\n",
        "home_team_receivers = df_home_receiving_plays['Receiver'].unique().tolist()\n",
        "\n",
        "if 'nan' in home_team_receivers:\n",
        "  home_team_receivers.pop(home_team_receivers.index('nan'))\n",
        "\n",
        "away_team_receivers = df_away_receiving_plays['Receiver'].unique().tolist()\n",
        "\n",
        "if 'nan' in away_team_receivers:\n",
        "  away_team_receivers.pop(away_team_receivers.index('nan'))"
      ],
      "metadata": {
        "id": "I2bV6mU_9FQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# home\n",
        "\n",
        "df_receiver_data = pd.DataFrame(columns=[\"REC\", \"YDS\", \"TD\", \"TGTS\"], index = home_team_receivers)\n",
        "\n",
        "for receiver in df_receiver_data.index:\n",
        "  receiver_plays = df_home_receiving_plays.loc[df_home_receiving_plays['Receiver'] == receiver]\n",
        "  df_receiver_data.loc[receiver, 'REC'] = receiver_plays.loc[(receiver_plays['PlayOutcome'].str.contains('yard pass', case=False)) |\n",
        "                                                             (receiver_plays['PlayOutcome'].str.contains(f'touchdown', case=False)) |\n",
        "                                                             (receiver_plays['PlayOutcome'].str.contains(\"Turnover On Downs \\(C\\)\", case=False)) |\n",
        "                                                             (receiver_plays['PlayOutcome'].str.contains(\"Pass for No Gain\", case=False)) |\n",
        "                                                             (receiver_plays['PlayOutcome'].str.contains(\"Fumble \\(C\\)\", case=False))].shape[0]\n",
        "  df_receiver_data.loc[receiver, 'YDS'] = int(receiver_plays['Yardage'].sum())\n",
        "  df_receiver_data.loc[receiver, 'TD'] = receiver_plays.loc[receiver_plays['PlayOutcome'].str.contains(f'touchdown {home_team}', case=False)].shape[0]\n",
        "  df_receiver_data.loc[receiver, 'TGTS'] = receiver_plays.shape[0]\n",
        "\n",
        "df_receiver_data.sort_values(by=\"YDS\", ascending=False, inplace=True)\n",
        "df_receiver_data"
      ],
      "metadata": {
        "id": "MR80t7op9sio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# away\n",
        "\n",
        "df_receiver_data = pd.DataFrame(columns=[\"REC\", \"YDS\", \"TD\", \"TGTS\"], index = away_team_receivers)\n",
        "\n",
        "for receiver in df_receiver_data.index:\n",
        "  receiver_plays = df_away_receiving_plays.loc[df_away_receiving_plays['Receiver'] == receiver]\n",
        "  df_receiver_data.loc[receiver, 'REC'] = receiver_plays.loc[(receiver_plays['PlayOutcome'].str.contains('yard pass', case=False)) |\n",
        "                                                             (receiver_plays['PlayOutcome'].str.contains(f'touchdown', case=False)) |\n",
        "                                                             (receiver_plays['PlayOutcome'].str.contains(\"Turnover On Downs \\(C\\)\", case=False)) |\n",
        "                                                             (receiver_plays['PlayOutcome'].str.contains(\"Pass for No Gain\", case=False)) |\n",
        "                                                             (receiver_plays['PlayOutcome'].str.contains(\"Fumble \\(C\\)\", case=False))].shape[0]\n",
        "  df_receiver_data.loc[receiver, 'YDS'] = int(receiver_plays['Yardage'].sum())\n",
        "  df_receiver_data.loc[receiver, 'TD'] = receiver_plays.loc[receiver_plays['PlayOutcome'].str.contains(f'touchdown {away_team}', case=False)].shape[0]\n",
        "  df_receiver_data.loc[receiver, 'TGTS'] = receiver_plays.shape[0]\n",
        "\n",
        "df_receiver_data.sort_values(by=\"YDS\", ascending=False, inplace=True)\n",
        "df_receiver_data"
      ],
      "metadata": {
        "id": "TX7rM72m2bvz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}