{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KeoniM/NFL_Data_Cleaning/blob/main/NFL_Plays_Week2_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDIp3ojKOdg2"
      },
      "source": [
        "**PURPOSE:**\n",
        "- Accurately clean a week's worth of play data\n",
        "  - Season 2023 -> Week 2\n",
        "\n",
        "**THOUGHTS, CONCERNS AND IDEAS FOR LATER:**\n",
        "\n",
        "*General*\n",
        "\n",
        "1. Players with the same name\n",
        "  - I do think that the raw data has naming conventions to decipher between two players with the exact same name but not 100% sure.\n",
        "\n",
        "2. Cleaning check (TESTING)\n",
        "  - I need a method that will help decern whether these plays have been cleaned correctly. Currently I am manually checking but this is not sustainable or efficient.\n",
        "    - **IDEA:** Cross reference recorded NFL stats with stats here and compare likeness. (maybe return a df that highlights differences?)\n",
        "    - **PROBLEM:** There are differences one how different organizations(?) record stats for players. For example, NFL.com and espn.com are not the same on what they consider a solo tackle or an assisted tackle.\n",
        "    - **PROBLEM 2:** NFL.com does not have every play recorded on their website. So far I have found that it is common for a game to miss at least 1 play.\n",
        "      - What do I do about this?\n",
        "\n",
        "3. Adjust features (PlayOutcomes/PlayTypes/IsScoringDrive/etc...) for plays that have been split up into multiple rows (Fumble Recoveries, Interceptions, etc...).\n",
        "  - EXAMPLE: Any fumble recovery that is not the runningback on an intended running play should not count as rushing yards for the player who recovered the fumble.\n",
        "    - IDEA: Should I broaden 'playtypes' to include:\n",
        "      1. yardage after fumble (Currently have it as 'Run' playtype)\n",
        "          - UPDATE: All recoveries after a fumble for yardage is under the umbrella playtype 'Fumble Return'\n",
        "      2. yardage after interception (Currently have it as 'Interception')\n",
        "          - UPDATE: All interceptions for yardage is under the umbrella playtype 'Run After Interception'\n",
        "  - EXAMPLE: If a team throws an interception and that interception results in a touchdown for the opposing team, I do not think it should be considered as a 'scoring drive' for the team that threw the interception.\n",
        "    - IDEA: For the category \"isScoringDrive\" the categories could be:\n",
        "      1. 0 - Is not a scoring drive\n",
        "      2. 1 - Is scoring drive for team on offense\n",
        "      3. 2 - Is scoring drive for team on defense\n",
        "      - ^^^ SHOULD IMPLEMENT ^^^\n",
        "\n",
        "4. I need to add to 'dict_names'. The Rams have 2 different values for accronyms. they have 1. 'LAR' and 2. 'LA'.\n",
        "  - This impacts a bit of code in here becaues now I will have to adjust for dictionaries to have possible list type values.\n",
        "\n",
        "5. I am 1000000% sure that there are many ways to make this code more efficient, clean and easier to read.\n",
        "\n",
        "*Offense*\n",
        "\n",
        "1. Trick plays\n",
        "  - Need a larger sample size that contains more trick plays\n",
        "\n",
        "2. Handoffs\n",
        "  - Need a larger sample size that contains more handoffs\n",
        "    - (Only one has been found within the dataset \"Season 2023 Week 1\", it was handled for that specific play type but have not implement for all)\n",
        "      - IDEA: Implement 'Handoff' into cleaning method for run plays. I believe the only time that you would be able to handoff the ball to someone is during a run play.\n",
        "\n",
        "*Defense*\n",
        "\n",
        "1. Nuance of players recorded for sacks & forced fumbles\n",
        "  - Look under sack play type cleaning method\n",
        "    - The formatting of multiple defending players in on a fumbled play may cause wrong recording of data (e.i. player who assisted in tackle may be credited for the forced fumble)\n",
        "\n",
        "2. SUBJECTIVE DEFENSIVE STAT RECORDING\n",
        "  - Depending on where you look for your defensive stats, their recordings may be different. For example, a solo tackle for one company recording stats may be an assisted tackle for another. (e.g. 'NFL.com' <-> 'espn.com')\n",
        "    - In my opinion, I think there are times where both of them have errors in their stat tables.\n",
        "      - EXAMPLE:\n",
        "        - \"(7:54) (Shotgun) D.Jones sacked at NYG 15 for -10 yards (M.Parsons)\"\n",
        "          - M.Parsons - awarded 1 sack & 1 TFL\n",
        "        - \"(5:27) (No Huddle, Shotgun) D.Jones sacked at NYG 34 for -8 yards (C.Golston)\"\n",
        "          - C.Golston - awarded 1 sack & 0 TFL\n",
        "        - This is shown in both NFL.com & espn.com\n",
        "  - Another example, an assisted tackle for loss may count as a TFL for that player by one stat crew but another may record that the player just had an assisted tackle.\n",
        "  - I have made tables to try and mimic both 'NFL.com' and 'espn.com' but the dataset is flexable and can be adjusted towards preference.\n",
        "    - ';' means solo and assisted tackle\n",
        "    - ',' means 0.5 tackle\n",
        "      - From what I have seen, the ordering matters when it comes to awarding defensive players a solo tackle vs. an assisted vs. awarding them anything at all.\n",
        "\n",
        "3. Safety\n",
        "  - I have not come across safeties yet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciN_CS4bOcpV"
      },
      "source": [
        "# MOUNTING AND IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZS3J98keONRD",
        "outputId": "81f4e03c-1b80-4119-f6ab-6bc50860fa7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gLupTRXO5gw",
        "outputId": "c5ed3f9d-cb5e-48e9-f6a6-c5d020ccd362"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authenticated\n"
          ]
        }
      ],
      "source": [
        "# Used to access personal google cloud services\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "1YadW6p7O7Lf"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "# For math (currently only using to check for 'nan' or 'NaN' values)\n",
        "import math\n",
        "\n",
        "# Data manipulation\n",
        "import pandas as pd\n",
        "\n",
        "# Regular expressions\n",
        "import re\n",
        "\n",
        "# Grab data from database\n",
        "from google.cloud import bigquery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "jKpGDloBiQN8"
      },
      "outputs": [],
      "source": [
        "# # debugger (maybe use in the future)\n",
        "# %pdb on"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTlTgrlpO_q1"
      },
      "source": [
        "# LOADING DATA (BigQuery queries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "W05L1TH6PAcb"
      },
      "outputs": [],
      "source": [
        "# Client connect to bigquery project\n",
        "client = bigquery.Client('nfl-data-430702')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPdKuDJJPIUZ"
      },
      "source": [
        "## Season 2023 Week 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnOg_zdhPLHi",
        "outputId": "8204eae4-01cf-4381-d1ea-e9a3f88fd5fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This query will process 575639 bytes.\n"
          ]
        }
      ],
      "source": [
        "# Grabbing all plays from 2023 Week 2 NFL Sesason\n",
        "week2_2023_plays_query = \"\"\"\n",
        "                         SELECT *\n",
        "                         FROM `nfl-data-430702.NFL_Scores.NFL-Plays-Week2_2023`\n",
        "                         \"\"\"\n",
        "\n",
        "# Running psuedo query, and returns the amount of bytes it will take to run query\n",
        "dry_run_config = bigquery.QueryJobConfig(dry_run=True)\n",
        "dry_run_query = client.query(week2_2023_plays_query, job_config=dry_run_config)\n",
        "print(\"This query will process {} bytes.\".format(dry_run_query.total_bytes_processed))\n",
        "\n",
        "# Running query (Being mindful of the amount of data being grabbed)\n",
        "# Will grab a maximum of a Gigabyte\n",
        "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**9)\n",
        "safe_config_query = client.query(week2_2023_plays_query, job_config=safe_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "27xLLVO6PfSJ"
      },
      "outputs": [],
      "source": [
        "# Putting data attained from query into a dataframe\n",
        "week2_2023_plays = safe_config_query.to_dataframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pJP-0GxhPhI_",
        "outputId": "1eb3eb0f-c3b3-48db-87a2-01117ac7c4f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Season    Week  Day   Date AwayTeam   HomeTeam      Quarter  DriveNumber  \\\n",
              "0    2023  Week 2  SUN  09/17   Giants  Cardinals  1ST QUARTER            1   \n",
              "1    2023  Week 2  SUN  09/17   Giants  Cardinals  1ST QUARTER            1   \n",
              "2    2023  Week 2  SUN  09/17   Giants  Cardinals  4TH QUARTER            1   \n",
              "3    2023  Week 2  SUN  09/17   Giants  Cardinals  1ST QUARTER            1   \n",
              "4    2023  Week 2  SUN  09/17   Giants  Cardinals  4TH QUARTER            1   \n",
              "\n",
              "  TeamWithPossession  IsScoringDrive  PlayNumberInDrive  IsScoringPlay  \\\n",
              "0                ARI               0                  7              0   \n",
              "1                ARI               0                  1              0   \n",
              "2                ARI               0                  2              0   \n",
              "3                ARI               0                  6              0   \n",
              "4                ARI               0                  7              0   \n",
              "\n",
              "       PlayOutcome                                    PlayDescription  \\\n",
              "0  Pass Incomplete  (12:21) (Shotgun) J.Dobbs pass incomplete shor...   \n",
              "1          Kickoff  G.Gano kicks 65 yards from NYG 35 to end zone,...   \n",
              "2     17 Yard Pass  (3:27) (Shotgun) J.Dobbs pass short middle to ...   \n",
              "3  Pass Incomplete  (12:27) J.Dobbs pass incomplete deep left to Z...   \n",
              "4      -1 Yard Run  (:38) J.Conner right tackle pushed ob at NYG 4...   \n",
              "\n",
              "             PlayStart  \n",
              "0    3rd & 6 at NYG 37  \n",
              "1  Kickoff from NYG 35  \n",
              "2   1st & 10 at ARI 25  \n",
              "3    2nd & 6 at NYG 37  \n",
              "4   1st & 10 at NYG 43  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a01d7c18-d801-4456-a82b-7fedf432580b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Season</th>\n",
              "      <th>Week</th>\n",
              "      <th>Day</th>\n",
              "      <th>Date</th>\n",
              "      <th>AwayTeam</th>\n",
              "      <th>HomeTeam</th>\n",
              "      <th>Quarter</th>\n",
              "      <th>DriveNumber</th>\n",
              "      <th>TeamWithPossession</th>\n",
              "      <th>IsScoringDrive</th>\n",
              "      <th>PlayNumberInDrive</th>\n",
              "      <th>IsScoringPlay</th>\n",
              "      <th>PlayOutcome</th>\n",
              "      <th>PlayDescription</th>\n",
              "      <th>PlayStart</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023</td>\n",
              "      <td>Week 2</td>\n",
              "      <td>SUN</td>\n",
              "      <td>09/17</td>\n",
              "      <td>Giants</td>\n",
              "      <td>Cardinals</td>\n",
              "      <td>1ST QUARTER</td>\n",
              "      <td>1</td>\n",
              "      <td>ARI</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>Pass Incomplete</td>\n",
              "      <td>(12:21) (Shotgun) J.Dobbs pass incomplete shor...</td>\n",
              "      <td>3rd &amp; 6 at NYG 37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2023</td>\n",
              "      <td>Week 2</td>\n",
              "      <td>SUN</td>\n",
              "      <td>09/17</td>\n",
              "      <td>Giants</td>\n",
              "      <td>Cardinals</td>\n",
              "      <td>1ST QUARTER</td>\n",
              "      <td>1</td>\n",
              "      <td>ARI</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Kickoff</td>\n",
              "      <td>G.Gano kicks 65 yards from NYG 35 to end zone,...</td>\n",
              "      <td>Kickoff from NYG 35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2023</td>\n",
              "      <td>Week 2</td>\n",
              "      <td>SUN</td>\n",
              "      <td>09/17</td>\n",
              "      <td>Giants</td>\n",
              "      <td>Cardinals</td>\n",
              "      <td>4TH QUARTER</td>\n",
              "      <td>1</td>\n",
              "      <td>ARI</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>17 Yard Pass</td>\n",
              "      <td>(3:27) (Shotgun) J.Dobbs pass short middle to ...</td>\n",
              "      <td>1st &amp; 10 at ARI 25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2023</td>\n",
              "      <td>Week 2</td>\n",
              "      <td>SUN</td>\n",
              "      <td>09/17</td>\n",
              "      <td>Giants</td>\n",
              "      <td>Cardinals</td>\n",
              "      <td>1ST QUARTER</td>\n",
              "      <td>1</td>\n",
              "      <td>ARI</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>Pass Incomplete</td>\n",
              "      <td>(12:27) J.Dobbs pass incomplete deep left to Z...</td>\n",
              "      <td>2nd &amp; 6 at NYG 37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2023</td>\n",
              "      <td>Week 2</td>\n",
              "      <td>SUN</td>\n",
              "      <td>09/17</td>\n",
              "      <td>Giants</td>\n",
              "      <td>Cardinals</td>\n",
              "      <td>4TH QUARTER</td>\n",
              "      <td>1</td>\n",
              "      <td>ARI</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>-1 Yard Run</td>\n",
              "      <td>(:38) J.Conner right tackle pushed ob at NYG 4...</td>\n",
              "      <td>1st &amp; 10 at NYG 43</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a01d7c18-d801-4456-a82b-7fedf432580b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a01d7c18-d801-4456-a82b-7fedf432580b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a01d7c18-d801-4456-a82b-7fedf432580b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9654564c-36e3-4317-85f4-09724302de1d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9654564c-36e3-4317-85f4-09724302de1d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9654564c-36e3-4317-85f4-09724302de1d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "week2_2023_plays",
              "summary": "{\n  \"name\": \"week2_2023_plays\",\n  \"rows\": 2634,\n  \"fields\": [\n    {\n      \"column\": \"Season\",\n      \"properties\": {\n        \"dtype\": \"Int64\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2023\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Week\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Week 2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Day\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"SUN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"09/17\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AwayTeam\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"Giants\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HomeTeam\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"Cardinals\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Quarter\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"4TH QUARTER\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DriveNumber\",\n      \"properties\": {\n        \"dtype\": \"Int64\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TeamWithPossession\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 32,\n        \"samples\": [\n          \"TB\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IsScoringDrive\",\n      \"properties\": {\n        \"dtype\": \"Int64\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PlayNumberInDrive\",\n      \"properties\": {\n        \"dtype\": \"Int64\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IsScoringPlay\",\n      \"properties\": {\n        \"dtype\": \"Int64\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PlayOutcome\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 183,\n        \"samples\": [\n          \"7 Yard Run\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PlayDescription\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2481,\n        \"samples\": [\n          \"(12:06) (Shotgun) C.Stroud pass short middle to N.Dell to IND 49 for 4 yards (J.Blackmon).\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PlayStart\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2063,\n        \"samples\": [\n          \"2nd & 5 at SEA 28\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "week2_2023_plays.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oShT8MvlRQdR",
        "outputId": "b3ddd543-7ee2-4873-a8c1-8b27cb674fe9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2634, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "# Noting the original size of the raw uncleaned dataframe of data\n",
        "# - (rows, columns)\n",
        "week2_2023_plays.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JD1VzJWRWn0"
      },
      "source": [
        "# CATEGORIZE PLAYS\n",
        "- The goal here is to parse out the different values for 'PlayOutcome'\n",
        "  - This is where I will separate different types of plays\n",
        "    - ( pass / run / kickoff / etc. )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0WcGgv1RXl0",
        "outputId": "fdb9f9ac-2441-4225-fc01-5783f8e1820a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Pass Incomplete', 'Kickoff', '17 Yard Pass', '-1 Yard Run',\n",
              "       'Touchdown Cardinals', '16 Yard Pass', '17 Yard Run', '1 Yard Run',\n",
              "       '5 Yard Run', 'Punt', '-1 Yard Pass', '1 Yard Pass', '4 Yard Run',\n",
              "       'Field Goal No Good', 'Extra Point Good', '5 Yard Pass',\n",
              "       '14 Yard Pass', '12 Yard Pass', '23 Yard Pass', '7 Yard Run',\n",
              "       '5 Yard Penalty', 'Touchdown Falcons', '-5 Yard Penalty',\n",
              "       '4 Yard Pass', '45 Yard Pass', 'Run for No Gain', '20 Yard Pass',\n",
              "       '3 Yard Run', '8 Yard Run', '-3 Yard Pass', '20 Yard Run',\n",
              "       '2 Yard Run', 'Touchdown Ravens', '8 Yard Pass', '9 Yard Pass',\n",
              "       '7 Yard Pass', '-10 Yard Penalty', '6 Yard Run', '25 Yard Penalty',\n",
              "       '-7 Yard Sack', '3 Yard Pass', '10 Yard Pass', '14 Yard Run',\n",
              "       'Field Goal', '19 Yard Pass', 'Touchdown Bills', '16 Yard Run',\n",
              "       '11 Yard Run', '-2 Yard Pass', '11 Yard Pass', '-10 Yard Sack',\n",
              "       '32 Yard Pass', 'Interception', 'Touchdown Bengals', '2 Yard Pass',\n",
              "       'Touchdown Browns', '2PT Conversion Success', '-9 Yard Run',\n",
              "       '-15 Yard Penalty', '1 Yard Penalty', 'Fumble', '18 Yard Pass',\n",
              "       '25 Yard Pass', '-2 Yard Penalty', '6 Yard Pass',\n",
              "       'Touchdown Cowboys', '15 Yard Run', '-4 Yard Run', '21 Yard Pass',\n",
              "       '31 Yard Pass', '-9 Yard Sack', '-2 Yard Run', '-3 Yard Run',\n",
              "       'Turnover on Downs', '15 Yard Pass', 'Touchdown Packers',\n",
              "       '24 Yard Run', '44 Yard Penalty', '-6 Yard Sack', '-5 Yard Pass',\n",
              "       '2 Yard Penalty', '-4 Yard Sack', '13 Yard Pass',\n",
              "       'Touchdown Colts', '10 Yard Penalty', '11 Yard Penalty', 'Sack',\n",
              "       '31 Yard Run', '34 Yard Pass', 'Touchdown Chiefs',\n",
              "       '-9 Yard Penalty', 'Touchdown Chargers', '24 Yard Pass',\n",
              "       '29 Yard Pass', '34 Yard Run', 'Touchdown Raiders',\n",
              "       'Touchdown Dolphins', '10 Yard Run', '-5 Yard Sack',\n",
              "       '28 Yard Pass', 'Touchdown Vikings', 'Pass for No Gain',\n",
              "       'Touchdown Giants', '58 Yard Pass', '54 Yard Pass', '9 Yard Run',\n",
              "       '-2 Yard Sack', '-12 Yard Sack', 'Touchdown Steelers',\n",
              "       '-4 Yard Penalty', 'Touchdown Seahawks', '0 Yard Run',\n",
              "       '4 Yard Penalty', 'Touchdown 49ers', '51 Yard Run',\n",
              "       '15 Yard Penalty', '12 Yard Penalty', 'Touchdown Titans',\n",
              "       '27 Yard Run', 'Touchdown Commanders', '-3 Yard Sack',\n",
              "       '36 Yard Pass', '7 Yard Penalty', '21 Yard Run', '22 Yard Run',\n",
              "       '22 Yard Pass', '19 Yard Run', '-8 Yard Penalty', '52 Yard Pass',\n",
              "       '26 Yard Run', '17 Yard Penalty', '13 Yard Run', 'Touchdown Bears',\n",
              "       '-11 Yard Sack', '33 Yard Pass', '69 Yard Run', '23 Yard Run',\n",
              "       '-1 Yard Sack', '53 Yard Pass', 'Touchdown Broncos',\n",
              "       'Touchdown Lions', 'Touchdown Rams', 'Touchdown Patriots',\n",
              "       '-4 Yard Pass', 'Touchdown Eagles', '30 Yard Pass',\n",
              "       '-11 Yard Pass', 'Touchdown Buccaneers', '-13 Yard Sack',\n",
              "       '28 Yard Run', '26 Yard Pass', '40 Yard Pass', '27 Yard Pass',\n",
              "       '30 Yard Run', '-5 Yard Run', 'Touchdown Texans', '43 Yard Pass',\n",
              "       '18 Yard Run', '-7 Yard Run', '6 Yard Penalty', 'Touchdown Saints',\n",
              "       '4 Yard Sack', '43 Yard Run', '-9 Yard Pass', '70 Yard Pass',\n",
              "       '-8 Yard Sack', 'Extra Point No Good', 'Touchdown Panthers',\n",
              "       '12 Yard Run', '43 Yard Penalty', '42 Yard Pass', 'Touchdown Jets',\n",
              "       'Penalty', '-17 Yard Sack', '36 Yard Run', '19 Yard Penalty',\n",
              "       '29 Yard Run', '2PT Conversion Fails', '8 Yard Penalty',\n",
              "       '-6 Yard Penalty', '49 Yard Pass', '-13 Yard Run', '35 Yard Pass'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "# Maybe try to fuzzywuzzy this in the future?\n",
        "# - I need to narrow these down into basic categories.\n",
        "# - (Take away numbers & \"Yard\")\n",
        "# - Find the most common words between all outcomes (hoping to get all categories e.i. 'Pass', 'Run', 'Touchdown', etc...)\n",
        "\n",
        "# All play outcomes from the game\n",
        "# - From here we can categorize and clean plays accordingly\n",
        "week2_2023_plays['PlayOutcome'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "sYCiceyQRrxl"
      },
      "outputs": [],
      "source": [
        "# NOTES:\n",
        "# - Currently, I am eyeing at all unique play outcomes to categorizing them.\n",
        "#   - This type of approach is not flexable because a play outcome can\n",
        "#     arise that has not been seen yet.\n",
        "#     - There may be more play outcomes in the future when working on a full season,\n",
        "#       let alone all seasons and future games\n",
        "\n",
        "# Play Types with complete cleaning methods (As far as this sample size goes)\n",
        "\n",
        "# ~ OFFENSE ~\n",
        "df_2023_pass_week2 = week2_2023_plays[week2_2023_plays['PlayOutcome'].str.contains('Pass')]\n",
        "df_2023_run_week2 = week2_2023_plays[week2_2023_plays['PlayOutcome'].str.contains('Run')]\n",
        "# ~ DEFENSE ~\n",
        "df_2023_interception_week2 = week2_2023_plays[week2_2023_plays['PlayOutcome'].str.contains('Interception')]\n",
        "df_2023_sack_week2 = week2_2023_plays[week2_2023_plays['PlayOutcome'].str.contains('Sack')]\n",
        "# ~ SPECIAL TEAMS ~\n",
        "df_2023_punt_week2 = week2_2023_plays[week2_2023_plays['PlayOutcome'].str.contains('Punt')]\n",
        "df_2023_kickoff_week2 = week2_2023_plays[week2_2023_plays['PlayOutcome'].str.contains('Kickoff')]\n",
        "# ~ SCORING ~\n",
        "df_2023_touchdown_week2 = week2_2023_plays[week2_2023_plays['PlayOutcome'].str.contains('Touchdown')]\n",
        "df_2023_extrapoint_week2 = week2_2023_plays[week2_2023_plays['PlayOutcome'].str.contains('Extra Point')]\n",
        "df_2023_fieldgoal_week2 = week2_2023_plays[week2_2023_plays['PlayOutcome'].str.contains('Field Goal')]\n",
        "df_2023_2pt_conversion_week2 = week2_2023_plays[week2_2023_plays['PlayOutcome'].str.contains('2PT Conversion')]\n",
        "# ~ OTHER ~\n",
        "df_2023_fumble_week2 = week2_2023_plays[week2_2023_plays['PlayOutcome'].str.contains('Fumble')]\n",
        "df_2023_penalty_week2 = week2_2023_plays[week2_2023_plays['PlayOutcome'].str.contains('Penalty')]\n",
        "df_2023_turnover_on_downs_week2 = week2_2023_plays[week2_2023_plays['PlayOutcome'].str.contains('Turnover on Downs')]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELSW1R82_TqT"
      },
      "source": [
        "## SANITY CHECK (All Plays Accounted for)\n",
        "  - Once all plays have been categorized, will compare the sum of all plays within each category to the size of the original dataframe of plays.\n",
        "    - Goal is to make sure the number of plays is the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcD7xXS03qBu",
        "outputId": "890fafb9-7428-419e-e95c-0bd1a163fe6a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "# Categorized plays\n",
        "\n",
        "plays_list = [df_2023_pass_week2,         # Offense\n",
        "              df_2023_run_week2,\n",
        "              df_2023_interception_week2, # Defense\n",
        "              df_2023_sack_week2,\n",
        "              df_2023_punt_week2,         # Special Teams\n",
        "              df_2023_kickoff_week2,\n",
        "              df_2023_touchdown_week2,    # Scoring\n",
        "              df_2023_extrapoint_week2,\n",
        "              df_2023_fieldgoal_week2,\n",
        "              df_2023_2pt_conversion_week2,\n",
        "              df_2023_fumble_week2,       # Other\n",
        "              df_2023_penalty_week2,\n",
        "              df_2023_turnover_on_downs_week2]\n",
        "\n",
        "num_plays_categorized = 0\n",
        "\n",
        "for plays in plays_list:\n",
        "  num_plays_categorized = num_plays_categorized + len(plays)\n",
        "\n",
        "num_plays_categorized == len(week2_2023_plays)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uau4ner4_fug"
      },
      "source": [
        "# HELPER METHODS (personal use)\n",
        "- For personal use, does not actually take part in cleaning dataset at all."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "u8Sza2J8_hwG"
      },
      "outputs": [],
      "source": [
        "# PURPOSE:\n",
        "# - Quick look at a section of plays\n",
        "#   - Ideally the plays that the user wants to break down and clean.\n",
        "# INPUT PARAMETERS:\n",
        "# df_all_plays      - DataFrame - The original dataframe where the desired plays to view came from\n",
        "# df_section_plays  - DataFrame - A section of the original dataframe the user wants to view\n",
        "# RETURN:\n",
        "# - Printing to the console:\n",
        "#   1. index of play (Within original dataframe)\n",
        "#   2. 'PlayDescription' feature of play\n",
        "#   3. 'PlayOutcome' feature of play\n",
        "def print_plays(df_all_plays, df_section_plays):\n",
        "  for idx, value in df_section_plays['PlayOutcome'].items():\n",
        "    play = df_all_plays['PlayDescription'].iloc[idx]\n",
        "    print(\"index: \" + str(idx))\n",
        "    for i in play.split(\". \"):\n",
        "      print(i)\n",
        "    print(value)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aWsMN7EqofF",
        "outputId": "4c5c2abc-a9a5-4c50-fe68-594c172c6c18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "index: 6\n",
            "(15:00) J.Dobbs scrambles up the middle for 23 yards, TOUCHDOWN.\n",
            "Touchdown Cardinals\n",
            "\n",
            "index: 34\n",
            "(11:54) (Shotgun) D.Ridder left end for 6 yards, TOUCHDOWN.\n",
            "Touchdown Falcons\n",
            "\n",
            "index: 55\n",
            "(7:15) D.Faalele reported in as eligible\n",
            " G.Edwards left guard for 1 yard, TOUCHDOWN.\n",
            "Touchdown Ravens\n",
            "\n",
            "index: 71\n",
            "(11:42) (Shotgun) L.Jackson pass deep right to N.Agholor for 17 yards, TOUCHDOWN.\n",
            "Touchdown Ravens\n",
            "\n",
            "index: 101\n",
            "(6:06) (Shotgun) J.Allen pass short right to G.Davis for 2 yards, TOUCHDOWN.\n",
            "Touchdown Bills\n",
            "\n",
            "index: 107\n",
            "(12:16) D.Edwards reported in as eligible\n",
            " J.Allen pass short left to D.Knox for 2 yards, TOUCHDOWN.\n",
            "Touchdown Bills\n",
            "\n",
            "index: 142\n",
            "(13:31) J.Stout punts 54 yards to CIN 19, Center-T.Ott\n",
            "C.Jones for 81 yards, TOUCHDOWN.\n",
            "Touchdown Bengals\n",
            "\n",
            "index: 156\n",
            "(14:09) (Shotgun) D.Watson pass short right to J.Ford for 3 yards, TOUCHDOWN.\n",
            "Touchdown Browns\n",
            "\n",
            "index: 188\n",
            "(9:25) (Shotgun) D.Prescott pass short left to J.Ferguson for 4 yards, TOUCHDOWN.\n",
            "Touchdown Cowboys\n",
            "\n",
            "index: 240\n",
            "(13:40) (Shotgun) J.Love pass short middle to J.Reed for 9 yards, TOUCHDOWN.\n",
            "Touchdown Packers\n",
            "\n",
            "index: 287\n",
            "(10:49) (Shotgun) A.Richardson up the middle for 18 yards, TOUCHDOWN.\n",
            "Touchdown Colts\n",
            "\n",
            "index: 337\n",
            "(11:36) (Shotgun) P.Mahomes pass short right to T.Kelce for 9 yards, TOUCHDOWN.\n",
            "Touchdown Chiefs\n",
            "\n",
            "index: 365\n",
            "(14:41) (No Huddle, Shotgun) J.Herbert pass short left to K.Allen for 12 yards, TOUCHDOWN.\n",
            "Touchdown Chargers\n",
            "\n",
            "index: 379\n",
            "(12:22) J.Garoppolo pass short left to D.Adams for 16 yards, TOUCHDOWN.\n",
            "Touchdown Raiders\n",
            "\n",
            "index: 381\n",
            "(9:43) (Shotgun) R.Mostert left end for 8 yards, TOUCHDOWN.\n",
            "Touchdown Dolphins\n",
            "\n",
            "index: 403\n",
            "(10:45) K.Cousins pass short left to T.Hockenson for 5 yards, TOUCHDOWN.\n",
            "Touchdown Vikings\n",
            "\n",
            "index: 443\n",
            "(13:48) (No Huddle, Shotgun) D.Jones left end for 14 yards, TOUCHDOWN.\n",
            "Touchdown Giants\n",
            "\n",
            "index: 492\n",
            "(15:00) (Shotgun) D.Watson pass short left intended for H.Bryant INTERCEPTED by A.Highsmith (M.Fitzpatrick) at CLE 30\n",
            "A.Highsmith for 30 yards, TOUCHDOWN.\n",
            "Touchdown Steelers\n",
            "\n",
            "index: 519\n",
            "(10:45) G.Smith pass short left to T.Lockett for 3 yards, TOUCHDOWN.\n",
            "Touchdown Seahawks\n",
            "\n",
            "index: 523\n",
            "(7:07) (Shotgun) K.Walker up the middle for 1 yard, TOUCHDOWN.\n",
            "Touchdown Seahawks\n",
            "\n",
            "index: 524\n",
            "(5:48) (Shotgun) G.Smith pass short right to T.Lockett for 6 yards, TOUCHDOWN.\n",
            "Touchdown Seahawks\n",
            "\n",
            "index: 535\n",
            "(8:31) C.McCaffrey right guard for 14 yards, TOUCHDOWN.\n",
            "Touchdown 49ers\n",
            "\n",
            "index: 546\n",
            "(11:37) D.Samuel left end for 11 yards, TOUCHDOWN.\n",
            "Touchdown 49ers\n",
            "\n",
            "index: 601\n",
            "(10:14) (Shotgun) R.Tannehill right tackle for 12 yards, TOUCHDOWN.\n",
            "Touchdown Titans\n",
            "\n",
            "index: 611\n",
            "(13:29) (Shotgun) B.Robinson up the middle for 2 yards, TOUCHDOWN.\n",
            "Touchdown Commanders\n",
            "\n",
            "index: 638\n",
            "(9:39) (Shotgun) J.Dobbs pass short right to M.Brown for 3 yards, TOUCHDOWN.\n",
            "Touchdown Cardinals\n",
            "\n",
            "index: 672\n",
            "(8:44) (Shotgun) L.Jackson pass short right to M.Andrews for 3 yards, TOUCHDOWN.\n",
            "Touchdown Ravens\n",
            "\n",
            "index: 701\n",
            "(6:23) J.Fields scrambles right end for 1 yard, TOUCHDOWN.\n",
            "Touchdown Bears\n",
            "\n",
            "index: 738\n",
            "(10:05) M.Dunn reported in as eligible\n",
            " P.Strong left guard for 1 yard, TOUCHDOWN.\n",
            "Touchdown Browns\n",
            "\n",
            "index: 777\n",
            "(6:19) J.McLaughlin left end for 5 yards, TOUCHDOWN.\n",
            "Touchdown Broncos\n",
            "\n",
            "index: 778\n",
            "(9:07) (No Huddle, Shotgun) R.Wilson pass short middle to B.Johnson for 16 yards, TOUCHDOWN.\n",
            "Touchdown Broncos\n",
            "\n",
            "index: 782\n",
            "(3:55) (Shotgun) J.Goff pass deep right to J.Reynolds for 22 yards, TOUCHDOWN.\n",
            "Touchdown Lions\n",
            "\n",
            "index: 801\n",
            "(10:39) (Shotgun) J.Love pass short middle to D.Wicks for 32 yards, TOUCHDOWN.\n",
            "Touchdown Packers\n",
            "\n",
            "index: 866\n",
            "(9:55) (Shotgun) M.Stafford pass short right to K.Williams for 6 yards, TOUCHDOWN.\n",
            "Touchdown Rams\n",
            "\n",
            "index: 952\n",
            "(7:47) K.Cousins pass short left to K.Osborn for 10 yards, TOUCHDOWN [J.Sweat].\n",
            "Touchdown Vikings\n",
            "\n",
            "index: 968\n",
            "(11:27) (Shotgun) M.Jones pass short right to H.Henry for 6 yards, TOUCHDOWN.\n",
            "Touchdown Patriots\n",
            "\n",
            "index: 1021\n",
            "(8:57) (Shotgun) D.Jones pass short right to S.Barkley for 9 yards, TOUCHDOWN.\n",
            "Touchdown Giants\n",
            "\n",
            "index: 1049\n",
            "(2:46) J.Hurts up the middle for 1 yard, TOUCHDOWN.\n",
            "Touchdown Eagles\n",
            "\n",
            "index: 1055\n",
            "(13:55) (No Huddle) J.Hurts up the middle for 1 yard, TOUCHDOWN.\n",
            "Touchdown Eagles\n",
            "\n",
            "index: 1071\n",
            "(14:22) (No Huddle, Shotgun) K.Walker left tackle for 3 yards, TOUCHDOWN.\n",
            "Touchdown Seahawks\n",
            "\n",
            "index: 1076\n",
            "(8:14) (Shotgun) J.Goff pass short left intended for J.Gibbs INTERCEPTED by T.Brown [U.Nwosu] at DET 40\n",
            "T.Brown for 40 yards, TOUCHDOWN.\n",
            "Touchdown Seahawks\n",
            "\n",
            "index: 1097\n",
            "(4:14) (Shotgun) B.Mayfield pass deep left to M.Evans for 32 yards, TOUCHDOWN.\n",
            "Touchdown Buccaneers\n",
            "\n",
            "index: 1133\n",
            "(11:53) (Shotgun) S.Howell pass deep middle to T.McLaurin for 30 yards, TOUCHDOWN.\n",
            "Touchdown Commanders\n",
            "\n",
            "index: 1140\n",
            "(6:15) (Shotgun) J.Conner up the middle for 4 yards, TOUCHDOWN.\n",
            "Touchdown Cardinals\n",
            "\n",
            "index: 1203\n",
            "(5:11) (Shotgun) D.Harris up the middle for 1 yard, TOUCHDOWN.\n",
            "Touchdown Bills\n",
            "\n",
            "index: 1244\n",
            "(2:38) (Shotgun) J.Burrow pass short left to T.Higgins for 3 yards, TOUCHDOWN.\n",
            "Touchdown Bengals\n",
            "\n",
            "index: 1296\n",
            "(3:12) (Shotgun) J.Goff pass short middle to J.Reynolds for 4 yards, TOUCHDOWN.\n",
            "Touchdown Lions\n",
            "\n",
            "index: 1301\n",
            "(9:09) D.Montgomery up the middle for 4 yards, TOUCHDOWN.\n",
            "Touchdown Lions\n",
            "\n",
            "index: 1321\n",
            "(4:59) (Shotgun) J.Goff pass deep right to K.Raymond for 36 yards, TOUCHDOWN.\n",
            "Touchdown Lions\n",
            "\n",
            "index: 1338\n",
            "(9:54) (No Huddle, Shotgun) C.Stroud pass short right to N.Dell for 23 yards, TOUCHDOWN.\n",
            "Touchdown Texans\n",
            "\n",
            "index: 1347\n",
            "(9:47) (No Huddle, Shotgun) Z.Moss right tackle for 11 yards, TOUCHDOWN.\n",
            "Touchdown Colts\n",
            "\n",
            "index: 1348\n",
            "(9:18) (Shotgun) A.Richardson right end for 15 yards, TOUCHDOWN.\n",
            "Touchdown Colts\n",
            "\n",
            "index: 1402\n",
            "(8:24) (Shotgun) J.Herbert pass short left to K.Allen for 8 yards, TOUCHDOWN [A.Key]\n",
            "PENALTY on TEN-J.Simmons, Roughing the Passer, 1 yard, enforced between downs\n",
            "Penalty on TEN-T.Avery, Defensive Pass Interference, declined.\n",
            "Touchdown Chargers\n",
            "\n",
            "index: 1483\n",
            "(3:18) T.Jones up the middle for 2 yards, TOUCHDOWN.\n",
            "Touchdown Saints\n",
            "\n",
            "index: 1500\n",
            "(3:30) M.Peart reported in as eligible\n",
            " S.Barkley right tackle for 1 yard, TOUCHDOWN.\n",
            "Touchdown Giants\n",
            "\n",
            "index: 1517\n",
            "(4:18) (Shotgun) D.Swift left tackle for 2 yards, TOUCHDOWN.\n",
            "Touchdown Eagles\n",
            "\n",
            "index: 1523\n",
            "(7:06) D.Watson sacked at CLE 13 for -7 yards (A.Highsmith)\n",
            "FUMBLES (A.Highsmith) [A.Highsmith], RECOVERED by PIT-T.Watt at CLE 16\n",
            "T.Watt for 16 yards, TOUCHDOWN.\n",
            "Touchdown Steelers\n",
            "\n",
            "index: 1557\n",
            "(10:58) (Shotgun) R.White left guard for 4 yards, TOUCHDOWN.\n",
            "Touchdown Buccaneers\n",
            "\n",
            "index: 1583\n",
            "(7:18) (Shotgun) B.Robinson left guard for 15 yards, TOUCHDOWN.\n",
            "Touchdown Commanders\n",
            "\n",
            "index: 1631\n",
            "(:16) (Shotgun) D.Ridder pass short left to D.London for 3 yards, TOUCHDOWN [Q.Walker].\n",
            "Touchdown Falcons\n",
            "\n",
            "index: 1653\n",
            "(4:23) L.Murray up the middle for 4 yards, TOUCHDOWN.\n",
            "Touchdown Bills\n",
            "\n",
            "index: 1658\n",
            "(1:21) (Shotgun) B.Young pass short right to A.Thielen for 3 yards, TOUCHDOWN.\n",
            "Touchdown Panthers\n",
            "\n",
            "index: 1680\n",
            "(6:23) (Shotgun) J.Fields pass deep middle to C.Claypool for 20 yards, TOUCHDOWN.\n",
            "Touchdown Bears\n",
            "\n",
            "index: 1690\n",
            "(3:32) (Shotgun) J.Burrow pass short right to T.Higgins for 4 yards, TOUCHDOWN.\n",
            "Touchdown Bengals\n",
            "\n",
            "index: 1729\n",
            "(:20) R.Wilson pass deep left to M.Mims for 60 yards, TOUCHDOWN.\n",
            "Touchdown Broncos\n",
            "\n",
            "index: 1758\n",
            "(1:01) R.Walker reported in as eligible\n",
            " J.Love pass short right to J.Reed for 10 yards, TOUCHDOWN.\n",
            "Touchdown Packers\n",
            "\n",
            "index: 1773\n",
            "(3:19) (Shotgun) C.Stroud pass short middle to N.Collins for 8 yards, TOUCHDOWN.\n",
            "Touchdown Texans\n",
            "\n",
            "index: 1839\n",
            "(1:50) (Shotgun) K.Williams up the middle for 4 yards, TOUCHDOWN.\n",
            "Touchdown Rams\n",
            "\n",
            "index: 1864\n",
            "(1:14) (No Huddle, Shotgun) K.Cousins pass short right to T.Hockenson for 5 yards, TOUCHDOWN.\n",
            "Touchdown Vikings\n",
            "\n",
            "index: 1901\n",
            "(3:03) T.Jones right guard for 2 yards, TOUCHDOWN.\n",
            "Touchdown Saints\n",
            "\n",
            "index: 1922\n",
            "(4:29) (Shotgun) D.Jones pass short middle to I.Hodgins for 11 yards, TOUCHDOWN.\n",
            "Touchdown Giants\n",
            "\n",
            "index: 1951\n",
            "(7:21) Z.Wilson pass short middle to G.Wilson for 68 yards, TOUCHDOWN.\n",
            "Touchdown Jets\n",
            "\n",
            "index: 1963\n",
            "(11:02) (Shotgun) J.Hurts pass deep left to D.Smith for 63 yards, TOUCHDOWN.\n",
            "Touchdown Eagles\n",
            "\n",
            "index: 2015\n",
            "(7:12) (No Huddle) D.Henry up the middle for 1 yard, TOUCHDOWN.\n",
            "Touchdown Titans\n",
            "\n",
            "index: 2076\n",
            "(:24) (Shotgun) J.Allen pass short middle to K.Shakir for 11 yards, TOUCHDOWN.\n",
            "Touchdown Bills\n",
            "\n",
            "index: 2104\n",
            "(1:56) D.Prescott pass short left to L.Schoonmaker for 1 yard, TOUCHDOWN\n",
            "Penalty on NYJ-S.Eguavoen, Defensive Holding, declined\n",
            "PENALTY on NYJ-M.Clemons, Roughing the Passer, 1 yard, enforced between downs.\n",
            "Touchdown Cowboys\n",
            "\n",
            "index: 2160\n",
            "(:15) (No Huddle, Shotgun) G.Minshew pass short left to K.Granson pushed ob at HOU 1 for 3 yards (D.Houston-Carson)\n",
            "The Replay Official reviewed the short of the goal line ruling, and the play was REVERSED\n",
            "(No Huddle, Shotgun) G.Minshew pass short left to K.Granson for 4 yards, TOUCHDOWN.\n",
            "Touchdown Colts\n",
            "\n",
            "index: 2212\n",
            "(:15) (Shotgun) T.Tagovailoa pass short right to T.Hill for 2 yards, TOUCHDOWN.\n",
            "Touchdown Dolphins\n",
            "\n",
            "index: 2217\n",
            "(8:51) (Shotgun) R.Mostert left guard for 43 yards, TOUCHDOWN.\n",
            "Touchdown Dolphins\n",
            "\n",
            "index: 2223\n",
            "(9:18) (Shotgun) K.Cousins pass deep middle to J.Addison for 62 yards, TOUCHDOWN.\n",
            "Touchdown Vikings\n",
            "\n",
            "index: 2263\n",
            "(:01) B.Purdy up the middle for 1 yard, TOUCHDOWN.\n",
            "Touchdown 49ers\n",
            "\n",
            "index: 2290\n",
            "(1:52) (Shotgun) S.Howell pass short middle to L.Thomas for 4 yards, TOUCHDOWN\n",
            "WAS-L.Thomas was injured during the play\n",
            " PENALTY on DEN-K.Jackson, Disqualification, 1 yard, enforced between downs.\n",
            "Touchdown Commanders\n",
            "\n",
            "index: 2342\n",
            "(:03) (Shotgun) R.Wilson pass deep middle to B.Johnson for 50 yards, TOUCHDOWN [C.Barton].\n",
            "Touchdown Broncos\n",
            "\n",
            "index: 2386\n",
            "(5:29) (No Huddle, Shotgun) R.Stevenson right guard for 2 yards, TOUCHDOWN.\n",
            "Touchdown Patriots\n",
            "\n",
            "index: 2445\n",
            "(6:16) (Shotgun) K.Pickett pass deep middle to G.Pickens for 71 yards, TOUCHDOWN [D.Tomlinson].\n",
            "Touchdown Steelers\n",
            "\n",
            "index: 2457\n",
            "(2:12) (Shotgun) J.Fields pass short middle intended for K.Herbert INTERCEPTED by S.Barrett at CHI 4\n",
            "S.Barrett for 4 yards, TOUCHDOWN.\n",
            "Touchdown Buccaneers\n",
            "\n",
            "index: 2464\n",
            "(2:25) (Shotgun) R.Tannehill pass short middle to N.Westbrook-Ikhine for 4 yards, TOUCHDOWN.\n",
            "Touchdown Titans\n",
            "\n",
            "index: 2519\n",
            "(:30) (No Huddle, Shotgun) P.Mahomes pass short right to S.Moore for 9 yards, TOUCHDOWN\n",
            "Penalty on JAX-Ty.Campbell, Illegal Use of Hands, declined.\n",
            "Touchdown Chiefs\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# EXAMPLE: Displaying all touchdown plays within dataset\n",
        "\n",
        "print_plays(week2_2023_plays, df_2023_touchdown_week2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkZ2lDw3yF4z"
      },
      "source": [
        "# PIPELINE\n",
        "  - ORDER\n",
        "    1. Team Dictionary\n",
        "      - Used to map team names with thier acronyms\n",
        "    2. Regular expressions\n",
        "      - Used to find common patterns within raw data\n",
        "    3. Transforming Data\n",
        "      - So far, only label encoding\n",
        "    4. Cleaning methods\n",
        "      - Unique cleaning methods for each play type\n",
        "    5. Main pipeline method\n",
        "      - Control flow of cleaning methods\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtbzjEyWlB8B"
      },
      "source": [
        "## 1. TEAM DICTIONARY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "f1J4J0JllNCP"
      },
      "outputs": [],
      "source": [
        "# KEY: Team name\n",
        "# VALUE: Acronym of team\n",
        "\n",
        "dict_teams = {\n",
        "    'Cardinals': 'ARI', 'Falcons': 'ATL', 'Ravens': 'BAL', 'Bills': 'BUF', 'Panthers': 'CAR', 'Bears': 'CHI',\n",
        "    'Bengals': 'CIN', 'Browns': 'CLE', 'Cowboys': 'DAL', 'Broncos': 'DEN', 'Lions': 'DET', 'Packers': 'GB',\n",
        "    'Texans': 'HOU', 'Colts': 'IND', 'Jaguars': 'JAX', 'Chiefs': 'KC', 'Raiders': 'LV', 'Chargers': 'LAC',\n",
        "    'Rams': 'LAR', 'Dolphins': 'MIA', 'Vikings': 'MIN', 'Patriots': 'NE', 'Saints': 'NO', 'Giants': 'NYG',\n",
        "    'Jets': 'NYJ', 'Eagles': 'PHI', 'Steelers': 'PIT', '49ers': 'SF', 'Seahawks': 'SEA', 'Buccaneers': 'TB',\n",
        "    'Titans': 'TEN', 'Commanders': 'WAS'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "51RyMwQllJ0f"
      },
      "outputs": [],
      "source": [
        "# KEY: Acronym of team\n",
        "# VALUE: Team name\n",
        "\n",
        "dict_teams_2 = {\n",
        "    'ARI': 'Cardinals', 'ATL': 'Falcons', 'BAL': 'Ravens', 'BUF': 'Bills', 'CAR': 'Panthers', 'CHI': 'Bears',\n",
        "    'CIN': 'Bengals', 'CLE': 'Browns', 'DAL': 'Cowboys', 'DEN': 'Broncos', 'DET': 'Lions', 'GB': 'Packers',\n",
        "    'HOU': 'Texans', 'IND': 'Colts', 'JAX': 'Jaguars', 'KC': 'Chiefs', 'LV': 'Raiders', 'LAC': 'Chargers',\n",
        "    'LAR': 'Rams', 'MIA': 'Dolphins', 'MIN': 'Vikings', 'NE': 'Patriots', 'NO': 'Saints', 'NYG': 'Giants',\n",
        "    'NYJ': 'Jets', 'PHI': 'Eagles', 'PIT': 'Steelers', 'SF': '49ers', 'SEA': 'Seahawks', 'TB': 'Buccaneers',\n",
        "    'TEN': 'Titans', 'WAS': 'Commanders'\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XksC21RH41fY"
      },
      "source": [
        "## 2. REGULAR EXPRESSIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "7GjwQpriPJcS"
      },
      "outputs": [],
      "source": [
        "####################################################\n",
        "# REGULAR EXPRESSIONS USED TO LOCATE SPECIFIC DATA #\n",
        "####################################################\n",
        "\n",
        "# Will eventually have to combine some regular expressions into one\n",
        "# - For example, punt returns <-> kick returns <-> interceptions <-> fumble recoveries (?)\n",
        "#   - standard_play_end_pattern <-> defensive_takeaway_run_pattern\n",
        "#     - Need to combine into 1.\n",
        "\n",
        "###########\n",
        "# GENERAL #\n",
        "###########\n",
        "\n",
        "# Players name (Grabs every variation come across so far)\n",
        "# - I need this to be able to grab 'A.St. Brown' & 'C.Edwards-Helaire' & 'L.Van Ness'\n",
        "# - I can imagine that I will have to change this again in the future.\n",
        "#   - Specifically the 'compound surnames' part\n",
        "\n",
        "#                                   V  V <-> meant to grab initial of first name and compound surnames such as \"St.\" in \"A.St. Brown\"\n",
        "#               V  team abr   V V 1 name abr  V    V last name V     VV <-> name separator ( - | . )                          V     V <-> last name 2\n",
        "#               V 1 name w/-  V V nam w/. nam V                          V          common words that follow name           V             V      V <-> does not end with..?\n",
        "#               V no team abr V\n",
        "name_pattern = \"(?:[A-Za-z]+-)*(?:[A-Za-z]{1,4}\\.)+(?:[A-Za-z]+)?(?:[- ](?!to|pushed|INTERCEPTED|scrambles|for|pass|ran|is|at)[A-Za-z]+)*[^\\W\\d_\\.]\" # <-- this seems extra.\n",
        "\n",
        "################\n",
        "# PLAY DETAILS #\n",
        "################\n",
        "\n",
        "# Play start time\n",
        "time_on_clock_pattern = r'\\((\\d*:\\d+)\\)'\n",
        "\n",
        "# Offense play formation\n",
        "formation = r'\\(([A-Za-z]+ ?[A-Za-z]*,? ?[A-Za-z]*)\\)'\n",
        "\n",
        "# Yards gained on play\n",
        "# - Will probably have to adjust this in the future to include 'no gain'\n",
        "yardage_gained = r'for (-?[0-9]+) yards?'\n",
        "# yardage_gained = r'for (no gain|-?[0-9]+)(?: yards?)?'\n",
        "# for (no gain|-?[0-9]+)(?: yards?)?\n",
        "\n",
        "# Officially, a pass for -3 yards.\n",
        "# Yards gained on play (When discrepancy)\n",
        "official_pass_yards_pattern = r'Officially, a pass for (-?[0-9]+) yards?'\n",
        "\n",
        "# 4th & 8 at 50\n",
        "# Positioning of the start of the play\n",
        "# I do not think that this actually grabs all play starting positions.\n",
        "play_start_pattern = \"(?:1st|2nd|3rd|4th) & [0-9]+ at (?:([A-Z]+) )?([0-9]+)\"\n",
        "\n",
        "# Positioning at the end of the play\n",
        "# - Probably needs to be able to grab 'no gain' at the end as well.\n",
        "# standard_play_end_pattern = \"(?:to|at) (?:([A-Z]+) )?([0-9]+) for (-?[0-9]+) yards?\"\n",
        "standard_play_end_pattern = \"(?:to|at) (?:([A-Z]+) )?([0-9]+) for (no gain|-?[0-9]+)(?: yards?)?\"\n",
        "\n",
        "# fumble recovery field spotting\n",
        "# - ball out of bounds            at BUF 25\n",
        "# - recovered by BAL-K.Zeitler    at HOU 23\n",
        "# - and recovers                  at TEN 9\n",
        "# - RECOVERED by JAX-D.Lloyd      at JAX 46\n",
        "fumble_recovery_spotting_pattern = f\"(?:ball out of bounds|recovered by {name_pattern}|RECOVERED by {name_pattern}|and recovers) at ([A-Z]+)? ([0-9]+)\"\n",
        "\n",
        "interception_play_end_pattern = f\"INTERCEPTED by {name_pattern}(?: \\[(?:{name_pattern})\\]| \\((?:{name_pattern})\\))? at (?:([A-Z]+) )?([0-9]+)\"\n",
        "\n",
        "# Yardage from penalty\n",
        "penalty_yardage_pattern = \", ([0-9]+) yards?, enforced at (?:([A-Z]+) )?([0-9]+)\"\n",
        "\n",
        "between_downs_penalty_yardage_pattern = \", ([0-9]+) yards?, enforced between downs\"\n",
        "\n",
        "###########\n",
        "# OFFENSE #\n",
        "###########\n",
        "\n",
        "# Passer (Player passing, Player spiking, Player who got sacked)\n",
        "passer_name_pattern = f\"({name_pattern}) (?:pass|spiked|sacked)\"\n",
        "\n",
        "# Rushing play (Player running ball)\n",
        "rusher_pattern = f\"({name_pattern})(?: scrambles)? (?:left|right|up|kneels).?\"\n",
        "\n",
        "# Pass play (Returns intended receiver and the direction of the pass)\n",
        "receiver_pattern = f\"(short|deep) (left|right|middle) (?:to|intended for) ({name_pattern})\"\n",
        "\n",
        "# 2 Point Conversion (Pass attempt)\n",
        "tp_conversion_pass_pattern = f\"({name_pattern}) pass to ({name_pattern})\"\n",
        "\n",
        "# 2 Point Conversion (Rush attempt)\n",
        "tp_conversion_rush_pattern = f\"({name_pattern}) rushes (?:left|right|up)\"\n",
        "\n",
        "# Handoff\n",
        "handoff_pattern = f\"Handoff to ({name_pattern}) to(?: ([A-Z]+))? ([0-9]+) for (-?[0-9]+) yards?\"\n",
        "\n",
        "# Lateral\n",
        "lateral_reception_pattern = f\"Lateral to ({name_pattern}) (?:pushed ob at|ran ob at|to)(?: ([A-Z]+))? (-?[0-9]+) for (no gain|-?[0-9]+)(?: yards?)?\"\n",
        "\n",
        "###########\n",
        "# DEFENSE #\n",
        "###########\n",
        "\n",
        "# Tackles\n",
        "\n",
        "# solo / sack\n",
        "solo_tackle_pattern = f\"\\(({name_pattern})\\)\"\n",
        "\n",
        "# assisted\n",
        "shared_tackle_pattern = f\"\\(({name_pattern}), ({name_pattern})\\)\"\n",
        "\n",
        "# shared\n",
        "assisted_tackle_pattern = f\"\\(({name_pattern}); ({name_pattern})\\)\"\n",
        "\n",
        "# Pressure (Who applied pressure to passer)\n",
        "# - I think it might be possible for multiple defenders to apply pressure to the passer.\n",
        "defense_pressure_name_pattern = f\"\\[({name_pattern})\\]\"\n",
        "\n",
        "# Interception (Player who intercepted pass)\n",
        "interception_name_pattern = f\"INTERCEPTED by ({name_pattern})\"\n",
        "\n",
        "\n",
        "# Quarterback Fumbles (Quarterback fumble solo, Quarterback fumble solo -> who recovers, Quarterback <-> Center discrepancy)\n",
        "\n",
        "# How far passer went before fumbling on his own\n",
        "qb_fumble_pattern = f\" ({name_pattern}) to(?: [A-Z]+) [0-9]+ for -?[0-9]+ yards$\" # Passer fumbles are always the initial action of the play\n",
        "\n",
        "# Action directly after a quarterback only fumble\n",
        "qb_fumble_description_pattern = f\"^FUMBLES, \"\n",
        "\n",
        "# Fumble missnap (Will either be the quarterback or center.)\n",
        "qb_aborted_fumble_pattern = f\"({name_pattern}) FUMBLES \\(Aborted\\)\"\n",
        "qb_center_aborted_fumble_pattern = f\"({name_pattern}) Aborted\"\n",
        "center_aborted_fumble_pattern = f\"({name_pattern}) FUMBLES at\"\n",
        "\n",
        "# Forced fumbles (Player who forced the fumble)\n",
        "forced_fumble_pattern = f\"FUMBLES \\(({name_pattern})\\)\"\n",
        "\n",
        "# Who recovered the fumble\n",
        "fumble_recovery_pattern = f\"by ({name_pattern}) at (?:([A-Z]+) )?([0-9]+)\"\n",
        "\n",
        "# fumble touched (causing down..?)\n",
        "fumble_touch_pattern = f\"touched at (?:([A-Z]+) )?([0-9]+)\"\n",
        "\n",
        "# Sack (Who is credited with a sack, who split sack, how many yards was the sack)\n",
        "\n",
        "# Fumble from sack (Player who forced the fumble on a sack)\n",
        "sacked_forced_fumble_sentence = f\"FUMBLES \\({name_pattern}\\) \\[({name_pattern})\\]\"\n",
        "\n",
        "# Split sack (Players who equally received credit for sack)\n",
        "split_sack_pattern = f\"sack split by ({name_pattern}) and ({name_pattern})\"\n",
        "\n",
        "# Yardage of sack (starting from line of scrimmage)\n",
        "yardage_from_sack = r'sacked(?: ob)? at(?: [A-Z]+)? [0-9]+ for (-?[0-9]+) yards'\n",
        "\n",
        "# Defense takeaway (takeaway for yardage)\n",
        "# D.Hill pushed ob at 50 for 20 yards (J.Wills)\n",
        "# J.Bates to ATL 49 for no gain (T.Marshall)\n",
        "defensive_takeaway_run_pattern = f\"({name_pattern}) (?:pushed ob at|ran ob at|to)(?: ([A-Z]+))? (-?[0-9]+) for (no gain|-?[0-9]+)(?: yards?)?\" # yardage after fumble recovery & yardage after interception\n",
        "\n",
        "# Defense takeaway (takeaway for touchdown)\n",
        "touchdown_after_takeaway_pattern = f\"({name_pattern}) for [0-9]+ yards, TOUCHDOWN\" # touchdown after a fumble recovery or interception\n",
        "\n",
        "#################\n",
        "# SPECIAL TEAMS #\n",
        "#################\n",
        "\n",
        "# Punting play (Who was the punter, How many yards the ball went, Who was the Longsnapper)\n",
        "punting_pattern = f\"({name_pattern}) punts (-?[0-9]+) yards? to(?: ([A-Z]+) (-?[0-9]+)| -?[0-9]+| end zone), Center-({name_pattern})\"\n",
        "\n",
        "# Punt return (Who was returning the punt, How many yards did they go, The player(s) that tackled the returner)\n",
        "punt_return_pattern = f\"({name_pattern}) (?:pushed ob at|ran ob at|to)(?: ([A-Z]+))? ([0-9]+) for\"\n",
        "\n",
        "# J.Reed (didn't try to advance) to CHI 44 for no gain.\n",
        "kick_return_pattern = f\"({name_pattern})(?: \\(didn't try to advance\\))? (?:pushed ob at|ran ob at|to)(?: ([A-Z]+))? (-?[0-9]+) for (?:no gain|(-?[0-9]+) yards? \\(({name_pattern})(?:(?:,|;) ({name_pattern}))?\\))\" # yardage after kickoff\n",
        "\n",
        "# Punt return resulting in fair catch\n",
        "punt_fair_catch_pattern = f\", fair catch by ({name_pattern})\"\n",
        "\n",
        "# Punt or kickoff downed by\n",
        "kick_downed_by_pattern = f\", downed by ({name_pattern})\"\n",
        "\n",
        "# Kickoff play (Who was the kicker, How many yards the ball was kicked )\n",
        "kickoff_pattern = f\"({name_pattern}) kicks(?: onside)? (-?[0-9]+) yards from (?:([A-Z]+) )?([0-9]+) to(?: ([A-Z]+) (-?[0-9]+)| -?[0-9]+| end zone)\"\n",
        "\n",
        "# Field goal (Good)\n",
        "field_goal_good_pattern = f\"({name_pattern}) (-?[0-9]+) yard field goal is GOOD, Center-({name_pattern}), Holder-({name_pattern}).\"\n",
        "\n",
        "# Field goal (no good)\n",
        "field_goal_no_good_pattern = f\"({name_pattern}) (-?[0-9]+) yard field goal is No Good, ([A-Za-z]+(?: [A-Za-z]+)*), Center-({name_pattern}), Holder-({name_pattern}).\"\n",
        "\n",
        "# Field goal (blocked)\n",
        "field_goal_blocked_pattern = f\"({name_pattern}) (-?[0-9]+) yard field goal is BLOCKED \\(({name_pattern})\\), Center-({name_pattern}), Holder-({name_pattern}), RECOVERED by ({name_pattern})\"\n",
        "\n",
        "# Extra point (good)\n",
        "extra_point_good_pattern = f\"({name_pattern}) extra point is GOOD, Center-({name_pattern}), Holder-({name_pattern}).\"\n",
        "\n",
        "# Extra point (no good)\n",
        "extra_point_no_good_pattern = f\"({name_pattern}) extra point is No Good, ([A-Za-z]+(?: [A-Za-z]+)*), Center-({name_pattern}), Holder-({name_pattern}).\"\n",
        "\n",
        "##############\n",
        "#  INJURIES  #\n",
        "##############\n",
        "\n",
        "# Injuries (Returns the player(s) who go injuried during play)\n",
        "injury_pattern = f\"[A-Z]+-({name_pattern}) was injured during the play\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFaoNUpK6sjg"
      },
      "source": [
        "## TRANSFORMING DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emY80yEPMQHs",
        "outputId": "a203b4c5-3ade-4446-fad3-d24a1e71c8e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['1ST QUARTER', '4TH QUARTER', '2ND QUARTER', '3RD QUARTER',\n",
              "       'OVERTIME'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "# Value mapping the \"Quarter\" feature\n",
        "week2_2023_plays['Quarter'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "uQbvMHKhNags"
      },
      "outputs": [],
      "source": [
        "week2_2023_plays_modified = week2_2023_plays.copy()\n",
        "\n",
        "dict_replace_quarter = {'1ST QUARTER': 1, '2ND QUARTER': 2, '3RD QUARTER': 3, '4TH QUARTER': 4, 'OVERTIME': 5}\n",
        "\n",
        "week2_2023_plays_modified['Quarter'] = week2_2023_plays_modified['Quarter'].map(dict_replace_quarter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LYvErx95uaA"
      },
      "source": [
        "## 3. CLEANING METHODS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-Tm3s7Nskgl"
      },
      "source": [
        "###HELPER CLEANING METHODS"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### helper method to find yardage between 2 spottings on field"
      ],
      "metadata": {
        "id": "TJMX1xGDpQ3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PURPOSE:\n",
        "# - Method that will return the amount of yardage between 2 spottings on the field during a play\n",
        "#   - IMPORTANT: The spotting needs to have yardage gained on play.\n",
        "#   - This is needed for situations where there is something that occurs that affects the yardage\n",
        "#     gained during a play, such as a penalty or fumble.\n",
        "\n",
        "# INPUT PARAMETERS:\n",
        "# start_spotting            -   list   - Where the start of the play or action took place\n",
        "#                                        - EXAMPLE FORMAT: ('BUF', '20')\n",
        "# end_spotting              -   list   - Where the end of the play or action took place\n",
        "#                                        - EXAMPLE FORMAT: ('BUF', '30')\n",
        "# yardage                   -  String  - Yardage recorded between start and end spotting\n",
        "#                                        - EXAMPLE FORMAT: '10'\n",
        "\n",
        "# RETURN:\n",
        "# Yardage gained between start_spotting and end_spotting\n",
        "\n",
        "def yardage_between_spottings(start_spotting, end_spotting, yardage):\n",
        "  # Need to figure out which zone the player with the ball is in and which direction they are fighting for given:\n",
        "  # 1. position yardage (+/-)\n",
        "  #    - Take the starting position and ending position,\n",
        "  #      is the difference between them positive or negative?\n",
        "  #      - ( ending position - starting position = (+/-) )\n",
        "  #        - EXAMPLE: BUF 20 -> BUF 30 is (+)\n",
        "  # 2. play yardage (+/-)\n",
        "  #    - Did the intended play gain yardage or lose yardage?\n",
        "\n",
        "  # In what zone is the line of scrimmage located?\n",
        "  # - There are 2 different zones that the line of scrimmage could be located.\n",
        "  #   1. 0 yard - 49 yard (e.g 'BUF 25')\n",
        "  #   2. 51 yard - 100 yard (e.g. 'KC 25')\n",
        "  # ~ 3. 50 yard line (e.g. '50') (50 yard line does not have a team acronym attached to it)\n",
        "\n",
        "  # Standard cases (start position and end position are in the same zone):\n",
        "  # position yardage (+) & play yardage (+):\n",
        "  # - the starting position team zone is the beginning (0-50)\n",
        "  # position yardage (-) & play yardage (+):\n",
        "  # - the starting position team zone is the ending (50-100)\n",
        "  # position yardage (+) & play yardage (-):\n",
        "  # - the starting position team zone is the ending (50-100)\n",
        "  # position yardage (-) & play yardage (-):\n",
        "  # - the starting position team zone is the beginning (0-50)\n",
        "\n",
        "  # Unique cass (start position and ending position are in different zones):\n",
        "  # zones switch (e.g. KC 47 -> BUF 47)\n",
        "  # play yardage (+):\n",
        "  # - the starting position team zone is the beginning (0-50)\n",
        "  # play yardage (-):\n",
        "  # - the starting position team zone is the ending (50-100)\n",
        "\n",
        "  starting_territory = start_spotting[0]\n",
        "  starting_yardage = int(start_spotting[1])\n",
        "  ending_territory = end_spotting[0]\n",
        "  ending_yardage = int(end_spotting[1])\n",
        "  yardage = int(yardage)\n",
        "\n",
        "  # Standard cases\n",
        "  if (starting_territory == ending_territory):\n",
        "    # position yardage (+)\n",
        "    if starting_yardage < ending_yardage:\n",
        "      # play yardage (+)\n",
        "      # starting position 0-50 zone\n",
        "      if yardage > 0:\n",
        "        starting_position = starting_yardage\n",
        "        ending_position = ending_yardage\n",
        "      # play yardage (-)\n",
        "      # starting position 50-100\n",
        "      else:\n",
        "        starting_position = 100 - starting_yardage\n",
        "        ending_position = 100 - ending_yardage\n",
        "    # position yardage (-)\n",
        "    else:\n",
        "      # play yardage (+)\n",
        "      # starting position 50-100\n",
        "      if yardage > 0:\n",
        "        starting_position = 100 - starting_yardage\n",
        "        ending_position = 100 - ending_yardage\n",
        "      # play yardage (-)\n",
        "      # starting position 0-50\n",
        "      else:\n",
        "        starting_position = starting_yardage\n",
        "        ending_position = ending_yardage\n",
        "  else:\n",
        "    # play yardage (+)\n",
        "    # starting position 0-50\n",
        "    if yardage > 0:\n",
        "      starting_position = starting_yardage\n",
        "      ending_position = 100 - ending_yardage\n",
        "    # play yardage (-)\n",
        "    # starting position 50-100\n",
        "    else:\n",
        "      starting_position = 100 - starting_yardage\n",
        "      ending_position = ending_yardage\n",
        "\n",
        "  return int(ending_position - starting_position)"
      ],
      "metadata": {
        "id": "CThYmQUbpUuD"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn4gd8SjZpOM"
      },
      "source": [
        "#### helper method for fumbles"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ~ HELPER METHOD ~\n",
        "\n",
        "# PURPOSE:\n",
        "# - Calculate the yardage gained on a play when a fumble occured.\n",
        "#   - On certain fumbled plays, the yardage gained will not be from start -> fumble spotting\n",
        "#     it will be start -> fumble recovery.\n",
        "\n",
        "# INPUT PARAMETERS:\n",
        "# start_spotting            -   list   - Where the start of the play or action took place\n",
        "#                                        - EXAMPLE FORMAT: [('BUF', '21')]\n",
        "#                                        - Often the 'start' of the play is the line of scrimmage\n",
        "# fumble_spotting           -   list   - Where the fumble of the play or action took place\n",
        "#                                        - EXAMPLE FORMAT: [('BUF', '22', '-1')]\n",
        "# recovery_spotting         -   list   - Where the fumble recovery took place\n",
        "#                                        - EXAMPLE FORMAT: [('BUF', '25')]\n",
        "#                                        - The spotting of when a ball goes out of bounds\n",
        "#                                          after a fumble also falls under 'recovery_spotting'\n",
        "\n",
        "# RETURN:\n",
        "# Yardage gained on fumbled play\n",
        "\n",
        "# RULES:\n",
        "# - Yardage gained is the distance from start spotting -> fumble recovery WHEN:\n",
        "#   1. The same team that fumbled makes the fumble recovery\n",
        "#   2. The fumble recovery is behind the fumble spotting\n",
        "#      - The player that fumbled the ball does not gain yardage if the ball was\n",
        "#        fumbled forward and recovered.\n",
        "\n",
        "def fumble_recovery_yardage(start_spotting, fumble_spotting, recovery_spotting):\n",
        "\n",
        "  start_zone = start_spotting[0][0]\n",
        "  start_yardage = int(start_spotting[0][1])\n",
        "\n",
        "  fumble_zone = fumble_spotting[0][0]\n",
        "  fumble_yardage = int(fumble_spotting[0][1])\n",
        "  if fumble_spotting[0][2] == 'no gain':\n",
        "    fumble_play_yardage = 0\n",
        "  else:\n",
        "    fumble_play_yardage = int(fumble_spotting[0][2])\n",
        "\n",
        "  recovery_zone = recovery_spotting[0][0]\n",
        "  recovery_yardage = int(recovery_spotting[0][1])\n",
        "\n",
        "  # Standard cases (start zone and fumble zone are same)\n",
        "  if start_zone == fumble_zone:\n",
        "    # position yardage (+) <-- I do not like this name. Need to change for clarity\n",
        "    # - EXAMPLE: BUF 20 -> BUF 30\n",
        "    if start_yardage < fumble_yardage:\n",
        "      # play yardage (+)\n",
        "      # - (starting position 0-50)\n",
        "      # - (fumble position 0-50)\n",
        "      if fumble_play_yardage > 0:\n",
        "        starting_position = start_yardage\n",
        "        fumble_position = fumble_yardage\n",
        "        # fumble recovery spotting in same zone (0-50)\n",
        "        if start_zone == recovery_zone:\n",
        "          recovery_position = recovery_yardage\n",
        "        # fumble recovery spotting in opposite zone (50-100)\n",
        "        else:\n",
        "          recovery_position = 100 - recovery_yardage\n",
        "      # play yardage (-)\n",
        "      # - (starting position 50-100)\n",
        "      # - (fumble position 50-100)\n",
        "      else:\n",
        "        starting_position = 100 - start_yardage\n",
        "        fumble_position = 100 - fumble_yardage\n",
        "        # fumble recovery spotting in same zone (50-100)\n",
        "        if start_zone == recovery_zone:\n",
        "          recovery_position = 100 - recovery_yardage\n",
        "        # fumble recovery spotting in opposite zone (0-50)\n",
        "        else:\n",
        "          recovery_position = recovery_yardage\n",
        "    # position yardage (-)\n",
        "    # EXAMPLE: BUF 30 -> BUF 20\n",
        "    else:\n",
        "      # play yardage (+)\n",
        "      # - (starting position 50-100)\n",
        "      # - (fumble position 50-100)\n",
        "      if fumble_play_yardage > 0:\n",
        "        starting_position = 100 - start_yardage\n",
        "        fumble_position = 100 - fumble_yardage\n",
        "        # fumble recovery spotting in same zone (50-100)\n",
        "        if start_zone == recovery_zone:\n",
        "          recovery_position = 100 - recovery_yardage\n",
        "        # fumble recovery spotting in opposite zone (0-50)\n",
        "        else:\n",
        "          recovery_position = recovery_yardage\n",
        "      # play yardage (-)\n",
        "      # - (starting position 0-50)\n",
        "      # - (fumble position 0-50)\n",
        "      else:\n",
        "        starting_position = start_yardage\n",
        "        fumble_position = fumble_yardage\n",
        "        # fumble recovery spotting in same zone (0-50)\n",
        "        if start_zone == recovery_zone:\n",
        "          recovery_position = recovery_yardage\n",
        "        # fumble recovery spotting in opposite zone (50-100)\n",
        "        else:\n",
        "          recovery_position = 100 - recovery_yardage\n",
        "  # Unique cases (start position and ending position are in different zones)\n",
        "  else:\n",
        "    # play yardage (+)\n",
        "    # - (starting position 0-50)\n",
        "    # - (fumble position 50-100)\n",
        "    if fumble_play_yardage > 0:\n",
        "      starting_position = start_yardage\n",
        "      fumble_position = 100 - fumble_yardage\n",
        "      # fumble recovery zone same as start zone (0-50)\n",
        "      if start_zone == recovery_zone:\n",
        "        recovery_position = recovery_yardage\n",
        "      # fumble recovery zone same as start zone (50-100)\n",
        "      else:\n",
        "        recovery_position = 100 - recovery_yardage\n",
        "    # play yardage (-)\n",
        "    # - (starting position 50-100)\n",
        "    # - (fumble position 0-50)\n",
        "    else:\n",
        "      starting_position = 100 - start_yardage\n",
        "      fumble_position = fumble_yardage\n",
        "      # fumble recovery zone same as start zone (50-100)\n",
        "      if start_zone == recovery_zone:\n",
        "        recovery_position = 100 - recovery_yardage\n",
        "      # fumble recovery zone same as start zone (0-50)\n",
        "      else:\n",
        "        recovery_position = recovery_yardage\n",
        "\n",
        "  # Fumble recovery only affects play yardage recorded when the same team recovers the ball\n",
        "  # behind the spotting of the fumble.\n",
        "\n",
        "  # If fumble spotting and recovery spotting are both negative\n",
        "  # - Go with recovery spotting\n",
        "  # If fumble spotting is negative and recovery spotting is positive\n",
        "  # - Go with the negative one (smaller)\n",
        "  # If fumble spotting is positive and recovery spotting is negative\n",
        "  # - Go with the negative one (smaller)\n",
        "  # If fumble spotting is positive and recovery spotting is positive\n",
        "  # - Go with the smaller one\n",
        "\n",
        "  fumble_yardage = fumble_position - starting_position\n",
        "  recovery_yardage = recovery_position - starting_position\n",
        "\n",
        "  if fumble_yardage < 0 and recovery_yardage < 0:\n",
        "    yardage = recovery_yardage\n",
        "  else:\n",
        "    yardage = min(fumble_yardage, recovery_yardage)\n",
        "\n",
        "  return yardage\n",
        "\n",
        "\n",
        "# PURPOSE:\n",
        "# - Universal helper method that extracts fumbled data from every playtype.\n",
        "\n",
        "# BASIC PLAN:\n",
        "# 1. Accept a play (single row from df) that has been fumbled.\n",
        "# 2. Replace that single row with a dataframe containing all extracted data.\n",
        "#    - These replacement dataframes are not limited to a single row, but can be many depending on the play.\n",
        "#      - Fumbled plays can sometimes be seen as many plays\n",
        "#        - FOR EXAMPLE:\n",
        "#          play 1 - intended play\n",
        "#          play 2 - run after fumble recovery\n",
        "\n",
        "# BASIC DESIGN STEP BY STEP:\n",
        "# 1. Split play description into significant actions and put into a list\n",
        "#    EXAMPLES:\n",
        "#    - intended play\n",
        "#    - fumble recovery for yardage\n",
        "# 2. Clean significant actions as their own rows\n",
        "# 3. Create and return replacement dataframe containing all cleaned significant actions (or rows)\n",
        "\n",
        "# INPUT PARAMETERS:\n",
        "# df_plays                  - dataframe - dataframe of plays\n",
        "# play                      -  String   - 'PlayDescription' of the current play that is being cleaned\n",
        "# play_index                -  Integer  - index of play (Almost always from main dataframe of plays)\n",
        "# main_action_patterns      -    list   - A list of regular expressions that are meant to pinpoint primary\n",
        "#                                         actions within a play that will be used to extract these actions\n",
        "#                                         to create a row within the replacement dataframe\n",
        "# map_who_fumbled_patterns  -    map    - A map with the purpose of finding who was responsible for fumbling the ball\n",
        "#                                         on a play.\n",
        "#                                         KEY   - fumble regular expressions\n",
        "#                                         VALUE - group number containing the player name within the regular expression.\n",
        "# main_cleaning_method      - function  - A callback function (the function using this helper method) which\n",
        "#                                         is used to clean intended play actions\n",
        "\n",
        "# RETURN:\n",
        "# df_multi_row_play - dataframe - dataframe of organized and cleaned actions stemming from a single unclean fumbled play\n",
        "\n",
        "def extract_fumble_data(df_plays, play, play_index, main_action_patterns, map_who_fumbled_patterns, main_cleaning_method):\n",
        "\n",
        "  original_play_copy = df_plays.loc[play_index]\n",
        "\n",
        "  # Breaking play description into a list of sentences\n",
        "  play_elements = play.split(\". \")\n",
        "\n",
        "  #################\n",
        "  # KEY VARIABLES #\n",
        "  #################\n",
        "\n",
        "  # 'play_split' info:\n",
        "  # - Designed to be a 2D list (list of lists)\n",
        "  # - All elements within this list collectively will represent a single play.\n",
        "  # - Each element within the list will become a separate row that will replace/add to the original dataframe of plays.\n",
        "  #   - Each element represents a distict action within the single play and will have all data required for that new row.\n",
        "  #   ROW CONTENTS:\n",
        "  #   1. [ ( The intended play ) + ( Extra data ) , ( Who caused the fumble ) ]   <-  This row will have extra info such as (injuries / penalties / eligibility / etc...)\n",
        "  #                                                                                   - \"The intended play\" includes 'Aborted' plays\n",
        "  # ~ 2. [            ( The fumble recovery )     , ( Who caused the fumble ) ]   <-  This can happen repeatedly or not at all\n",
        "  # ~ 3. [ (The fumble recovery for a touchdown) ]                                <-  This can only happen once for a single play or not at all\n",
        "  play_split = []\n",
        "\n",
        "  # 'extra_data' info:\n",
        "  # - Will be a single string containing all additional data from the play such as (injuries / penalties / eligibility / etc...)\n",
        "  # - Will be put into a single row dataframe and cleaned\n",
        "  #   - Once extra data has been cleaned, the single row (now clean) dataframe will serve as a shell for\n",
        "  #     the first new row that will replace the old play within the main dataframe.\n",
        "  #     - This first new row will have the initial action of the play as well as all additional information from the play\n",
        "  extra_data = \"\"\n",
        "\n",
        "  # Handoff after fumble recovery\n",
        "  # - Quarterback fumbles the ball -> recovers the ball -> performs a handoff to another player\n",
        "  #   - Question: Does this cover if a handoff happens -> fumble?\n",
        "  #   - Question: Can I use this approach for a qb fumble -> passes?\n",
        "  handoff_attempt = False\n",
        "\n",
        "  # Because punt/kickoff returns are formatted similarly to many other playtypes, these are needed\n",
        "  # in order to decifer between those playtypes and punt/kickoff returns.\n",
        "  is_punt = False\n",
        "  is_kickoff = False\n",
        "\n",
        "  # - Iterate through each element within play_elements\n",
        "  # - NOTE: We are iterating through actions of the play cronologically\n",
        "  for string in play_elements:\n",
        "\n",
        "    ######################################\n",
        "    # ORGANIZING KEY ACTIONS WITHIN PLAY #\n",
        "    ######################################\n",
        "\n",
        "    # ACTIONS WITHIN PLAY THAT DESERVE THEIR OWN ROW:\n",
        "    # These situations will have their own list element within \"play_split\" (meaning their own row within the new cleaned replacement dataframe)\n",
        "    # 1. intended play (initial action might be a better name for plays such as ones that have been aborted)\n",
        "    # 2. runs after fumble recoveries (emphasis on the plural)\n",
        "    # 3. touchdown after fumble recovery (can only happen once) (looks unique for each playtype) <- this might not be true.\n",
        "    # 4. handoffs\n",
        "    for play_pattern in main_action_patterns:\n",
        "      if re.search(play_pattern, string) != None:\n",
        "        play_split.append([string])\n",
        "        break\n",
        "    if re.search(play_pattern, string) != None:\n",
        "      continue\n",
        "\n",
        "    # ADD ON SECTION (Actions that will add to elements that will obtain their own row)\n",
        "    # - Appends data to elements within 'play_split'\n",
        "    #   - Every element within play_split is a list, this section will add to those individual lists\n",
        "    #     - Specifically it will append to the last element within 'play_split' and the reason for that\n",
        "    #       is because as we are iterating through sentences cronologically, the appending element\n",
        "    #       will always follow directly after the element that needs it\n",
        "    # These situations will add to the last element within 'play_split' (For all playtypes)\n",
        "    # 1. forced fumble description (happens after regular plays & sometimes after fumble recoveries)\n",
        "    # 2. fumble description describing a qb only fumble (happens after a qb only fumble)\n",
        "    # 3. qb_aborted_fumble_pattern -\n",
        "    for play_pattern in [forced_fumble_pattern, qb_fumble_description_pattern, center_aborted_fumble_pattern]:\n",
        "      if re.search(play_pattern, string):\n",
        "        index_last_element = len(play_split) - 1\n",
        "        play_split[index_last_element].append(string)\n",
        "        break\n",
        "    if re.search(play_pattern, string) != None:\n",
        "      continue\n",
        "\n",
        "    # When a sentence does not fit within the top 2 sections ( 1. adding an element to the list || 2. appending to an element in the list )\n",
        "    # - Glue the sentence into 'extra_data' to be cleaned separately.\n",
        "    extra_data = extra_data + string + \". \"\n",
        "\n",
        "  ##################################\n",
        "  ## CLEANING ACTIONS WITHIN PLAY ##\n",
        "  ##################################\n",
        "\n",
        "  ###################################\n",
        "  # CLEANING INITIAL ACTION OF PLAY #\n",
        "  ###################################\n",
        "\n",
        "  # GRABBING: Initial action of play (e.g. Intended play / aborted fumble / qb only fumble / etc...)\n",
        "  intended_play_description = play_split.pop(0)\n",
        "\n",
        "  # Creating a single row dataframe of the intended play\n",
        "  # No matter what the initial action is, the description will always be the first element of the first element within 'play_split'\n",
        "  unclean_intended_play = pd.DataFrame([original_play_copy.copy()], columns=df_plays.columns)\n",
        "  unclean_intended_play['PlayDescription'] = intended_play_description[0]\n",
        "\n",
        "  ### TEAM WITH POSSESSION AFTER RECOVERY ###\n",
        "  # fumble_recovery_team info:\n",
        "  # - The goal with this variable is to grab the team that recovered the fumble.\n",
        "  #   - The reason why this is needed is so that the feature 'TeamWithPossession'\n",
        "  #     mirrors what is happening and who has control of the ball during the play.\n",
        "  #   - This is also used to correct yardage gained when a team recovers their own\n",
        "  #     fumble.\n",
        "  #     - This is the reason why it is up top, this is a need to know before calculating\n",
        "  #       yardage gained during certain fumble recoveries.\n",
        "  fumble_recovery_team = None\n",
        "\n",
        "  # Figuring out who recovered the fumble and assigning 'fumble_recovery_team' with\n",
        "  # the team that this player is on.\n",
        "  for action in intended_play_description:\n",
        "\n",
        "    if action.find('and recovers') != -1:\n",
        "      unclean_intended_play['FumbleRecoveredBy'] = unclean_intended_play['WhoFumbled'].iloc[0]\n",
        "      break\n",
        "\n",
        "    # Who recovered the fumble\n",
        "    if 'recovered' in action.lower():\n",
        "      fumble_recovery = re.findall(fumble_recovery_pattern, action)\n",
        "      if len(fumble_recovery) > 0:\n",
        "        fumble_recovery_team = fumble_recovery[0][0].split(\"-\")[0]\n",
        "        unclean_intended_play['FumbleRecoveredBy'] = \"-\".join(fumble_recovery[0][0].split(\"-\")[1:])\n",
        "        break\n",
        "\n",
        "  ### STANDARD INTENDED PLAYTYPE FUMBLES ###\n",
        "  # - Typical play types such as runs or passes\n",
        "  # - Will have 2 elements:\n",
        "  #   1. Intended play\n",
        "  #   2. Who or how they fumbled\n",
        "  if len(intended_play_description) > 1:\n",
        "    unclean_intended_play['FumbleDetails'] = intended_play_description[1]\n",
        "\n",
        "    ### FORCED FUMBLE BY ###\n",
        "    forced_fumble = re.findall(forced_fumble_pattern, intended_play_description[1])\n",
        "    if len(forced_fumble) > 0:\n",
        "      unclean_intended_play['ForcedFumbleBy'] = forced_fumble[0]\n",
        "\n",
        "    ### WHO FUMBLED ###\n",
        "    for fumble_outcome in map_who_fumbled_patterns.keys():\n",
        "      fumbled_by = re.findall(fumble_outcome, intended_play_description[0])\n",
        "      if len(fumbled_by) > 0:\n",
        "        if isinstance(fumbled_by[0], tuple):\n",
        "          unclean_intended_play['WhoFumbled'] = fumbled_by[0][map_who_fumbled_patterns[fumble_outcome]]\n",
        "        else:\n",
        "          unclean_intended_play['WhoFumbled'] = fumbled_by[map_who_fumbled_patterns[fumble_outcome]]\n",
        "        break\n",
        "\n",
        "    cleaned_intended_play = main_cleaning_method(unclean_intended_play)\n",
        "\n",
        "    ### YARDAGE AFTER RECOVERY ###\n",
        "    if fumble_recovery_team == None or fumble_recovery_team == unclean_intended_play['TeamWithPossession'].iloc[0]:\n",
        "      # For some reason, 'aborted' plays do not count here.\n",
        "      if intended_play_description[0].find('Aborted') == -1:\n",
        "\n",
        "        print(play_index)\n",
        "        print(play_split)\n",
        "        print(intended_play_description)\n",
        "\n",
        "\n",
        "        # Play start ( FORMAT EX. - [('BUF', '21')] )\n",
        "        line_of_scrimmage = re.findall(play_start_pattern, original_play_copy['PlayStart'])\n",
        "        # fumble spotting ( FORMAT EX. - [('BUF', '22', '-1')] )\n",
        "        fumble_spotting = re.findall(standard_play_end_pattern, intended_play_description[0])\n",
        "        # recovery spotting ( FORMAT EX. - [('BUF', '25')] )\n",
        "        fumble_touch = re.findall(fumble_touch_pattern, intended_play_description[1])\n",
        "        if len(fumble_touch) > 0:\n",
        "          recovery_spotting = fumble_touch # I guess if a fumble is \"touched\" then that is what stops the yards after fumble from adding onto yardage gained?\n",
        "        else:\n",
        "          recovery_spotting = re.findall(fumble_recovery_spotting_pattern, intended_play_description[1])\n",
        "        print(line_of_scrimmage)\n",
        "        print(fumble_spotting)\n",
        "        print(recovery_spotting)\n",
        "        yardage = fumble_recovery_yardage(line_of_scrimmage, fumble_spotting, recovery_spotting)\n",
        "        cleaned_intended_play['Yardage'] = yardage\n",
        "\n",
        "  ### ABORTED FUMBLE ###\n",
        "  # - Will grab rusher, an aborted fumble still counts as a rush attempt\n",
        "  # - Will grab who was at fault for aborted play\n",
        "  if intended_play_description[0].find('Aborted') != -1:\n",
        "    rusher_patterns = [qb_fumble_pattern, qb_aborted_fumble_pattern, qb_center_aborted_fumble_pattern]\n",
        "    for pattern in rusher_patterns:\n",
        "      rusher = re.findall(pattern, play)\n",
        "      if len(rusher) > 0:\n",
        "        rusher_name = rusher[0]\n",
        "        unclean_intended_play['Rusher'] = rusher_name\n",
        "        break\n",
        "    # Rusher at fault for aborted play\n",
        "    if intended_play_description[0].find('(Aborted)') != -1:\n",
        "      unclean_intended_play['WhoFumbled'] = rusher_name\n",
        "      unclean_intended_play['FumbleDetails'] = intended_play_description[0]\n",
        "    # Center at fault for aborted play\n",
        "    else:\n",
        "      center_at_fault = re.findall(center_aborted_fumble_pattern, intended_play_description[1])\n",
        "      unclean_intended_play['WhoFumbled'] = center_at_fault\n",
        "      unclean_intended_play['FumbleDetails'] = intended_play_description[1]\n",
        "    unclean_intended_play['Yardage'] = 0\n",
        "    cleaned_intended_play = unclean_intended_play # Technically unnecessary, but doing this to show that the play is now clean.\n",
        "\n",
        "  ### KICKOFF FUMBLE ###\n",
        "  #   - Because there is the kickoff, then the kickoff return, then the fumble on the kickoff return,\n",
        "  #     the intended play will not have the fumble detail but still needs to be cleaned.\n",
        "  #   - Currently does not grab penalties during fumbles on kickoff plays.\n",
        "  kickoff = re.findall(kickoff_pattern, intended_play_description[0])\n",
        "  if len(kickoff) > 0:\n",
        "    is_kickoff = True\n",
        "    cleaned_intended_play = main_cleaning_method(unclean_intended_play)\n",
        "\n",
        "  ### PUNTING FUMBLE ###\n",
        "  #   - Because the fumble occurs on the punt return,\n",
        "  #     the intended play will not have the fumble detail but still needs to be cleaned.\n",
        "  #   - Currently does not grab penalties during punts on kickoff plays.\n",
        "  punt = re.findall(punting_pattern, intended_play_description[0])\n",
        "  if len(punt) > 0:\n",
        "    is_punt = True\n",
        "    cleaned_intended_play = main_cleaning_method(unclean_intended_play)\n",
        "\n",
        "  ### SACKED FUMBLE ###\n",
        "  if intended_play_description[0].find('sacked') != -1:\n",
        "    passer_name_sack_fumble = re.findall(passer_name_pattern, intended_play_description[0])\n",
        "    unclean_intended_play['WhoFumbled'] = passer_name_sack_fumble[0]\n",
        "    cleaned_intended_play = unclean_intended_play\n",
        "\n",
        "  ### CLEANING EXTRA DATA ###\n",
        "  # - Extra data includes (injuries / penalties / eligibility / official yardage ruling / etc...)\n",
        "  #   - 'Official yardage ruling' is why this is done last.\n",
        "  # - Extra data will be located within the first row of the replacement dataframe.\n",
        "  # - Question: Not sure how an accepted penalty will react during a fumbled play.\n",
        "  if extra_data:\n",
        "    playdescription = cleaned_intended_play['PlayDescription'].iloc[0]\n",
        "    cleaned_intended_play['PlayDescription'] = extra_data\n",
        "    cleaned_intended_play = main_cleaning_method(cleaned_intended_play)\n",
        "    cleaned_intended_play['PlayDescription'] = playdescription\n",
        "\n",
        "  ##########################################\n",
        "  # CLEANING SECONDARY ACTIONS WITHIN PLAY #\n",
        "  ##########################################\n",
        "\n",
        "  ####################################################################\n",
        "  # FUMBLE RECOVERIES FOR YARDAGE & FUMBLE RECOVERIES FOR TOUCHDOWNS #\n",
        "  ####################################################################\n",
        "\n",
        "  # Created list for the possibility of multiple fumbles and recoveries in a single play\n",
        "  list_recovery_runs = []\n",
        "\n",
        "  for play in play_split:\n",
        "\n",
        "    recovery_row = pd.DataFrame([original_play_copy.copy()], columns=df_plays.columns)\n",
        "\n",
        "    recovery_row['PlayDescription'] = play[0]\n",
        "\n",
        "    # Pass after fumble recovery\n",
        "    pass_play = re.findall(passer_name_pattern, play[0])\n",
        "    if len(pass_play) > 0:\n",
        "      recovery_row['PlayOutcome'] = 'Pass'\n",
        "      cleaned_recovery_row = clean_pass_plays(recovery_row)\n",
        "\n",
        "    # Handoff after fumble recovery\n",
        "    elif play[0].find('Handoff') != -1:\n",
        "      handoff_attempt = True\n",
        "      recovery_row['PlayOutcome'] = 'Run'\n",
        "      cleaned_recovery_row = clean_run_plays(recovery_row)\n",
        "\n",
        "    # Fumble on punt return\n",
        "    elif is_punt == True:\n",
        "      is_punt = False\n",
        "      cleaned_recovery_row = clean_punt_plays(recovery_row)\n",
        "\n",
        "    # Fumble on kickoff return\n",
        "    elif is_kickoff == True:\n",
        "      is_kickoff = False\n",
        "      cleaned_recovery_row = clean_kickoff_plays(recovery_row)\n",
        "\n",
        "    # Everything else can be labeled as a run play\n",
        "    else:\n",
        "      recovery_row['PlayOutcome'] = 'Run'\n",
        "      cleaned_recovery_row = clean_run_plays(recovery_row)\n",
        "      cleaned_recovery_row['PlayType'] = 'Fumble Return'\n",
        "\n",
        "    # Assigning 'TeamWithPossession' as the team who recovered the fumble.\n",
        "    if fumble_recovery_team != None:\n",
        "      cleaned_recovery_row['TeamWithPossession'] = fumble_recovery_team\n",
        "\n",
        "    # Was the recovered fumble fumbled?\n",
        "    # OR\n",
        "    # Did the fumble occur on a punt/kickoff return?\n",
        "    if len(play) > 1:\n",
        "\n",
        "      cleaned_recovery_row['FumbleDetails'] = play[1]\n",
        "\n",
        "      # Who forced fumble\n",
        "      forced_fumble = re.findall(forced_fumble_pattern, play[1])\n",
        "      if len(forced_fumble) > 0:\n",
        "        cleaned_recovery_row['ForcedFumbleBy'] = forced_fumble[0]\n",
        "\n",
        "      # Who fumbled the ball\n",
        "      cleaned_recovery_row['WhoFumbled'] = cleaned_recovery_row['Rusher'].iloc[0]\n",
        "\n",
        "      # Fumble occured during punt/kickoff return\n",
        "      if cleaned_recovery_row['Returner'].iloc[0] != 'nan':\n",
        "        cleaned_recovery_row['WhoFumbled'] = cleaned_recovery_row['Returner'].iloc[0]\n",
        "\n",
        "      # Who recovered the fumble\n",
        "      if 'recovered' in play[1].lower():\n",
        "        fumble_recovery = re.findall(fumble_recovery_pattern, play[1])\n",
        "        if len(fumble_recovery) > 0:\n",
        "          fumble_recovery_team = fumble_recovery[0][0].split(\"-\")[0]\n",
        "          # Always taking note of who recovers the fumble, so that the team with possession during that time is recorded.\n",
        "          # - If the player who recovered the fumble gains yards, this variable will loop back around to assign the 'TeamWithPossession'\n",
        "          #   feature to go along with the following row representing the recovery for yardage.\n",
        "          cleaned_recovery_row['FumbleRecoveredBy'] = \"-\".join(fumble_recovery[0][0].split(\"-\")[1:])\n",
        "\n",
        "    cleaned_recovery_row['PlayOutcome'] = original_play_copy['PlayOutcome'] # <- Maybe this isn't correct? when a play is split by multiple rows, this becomes tricky.\n",
        "    list_recovery_runs.append(cleaned_recovery_row)\n",
        "\n",
        "  # - I need to review teams with possession when there is a fumble recovery for a touchdown.\n",
        "\n",
        "  ###################\n",
        "  # 3.NEW DATAFRAME #\n",
        "  ###################\n",
        "  # - Create the cleaned replacement row(s) for the original row.\n",
        "\n",
        "  if len(list_recovery_runs) > 0:\n",
        "    df_multi_row_play = pd.DataFrame(columns=df_plays.columns)\n",
        "    df_multi_row_play = pd.concat([cleaned_intended_play, *list_recovery_runs], ignore_index=True)\n",
        "  else:\n",
        "    df_multi_row_play = cleaned_intended_play\n",
        "\n",
        "  #########################\n",
        "  # DATAFRAME ADJUSTMENTS #\n",
        "  #########################\n",
        "\n",
        "  # - I need to double check this and possibly incorporate this above\n",
        "  # Handoff after fumble recovery\n",
        "  # - Quarterback fumbles the ball -> recovers the ball -> performs a handoff to another player\n",
        "  #   - All actions recorded before the handoff need a change in 'PlayType'\n",
        "  #     - Currently each recorded as a rushing attempt.\n",
        "  # - I think this is wrong.\n",
        "  #   - I think the only reason why the QB received 0 yards after fumbling the ball\n",
        "  #     behind the LOS is because the handoff went passed the LOS. If it did not,\n",
        "  #     I have no idea what the yardage would look like.\n",
        "  #   - This may have to be taken out and adjusted in the future when I look at a larger\n",
        "  #     sample.\n",
        "  if handoff_attempt:\n",
        "    handoff_index = 0\n",
        "    list_indexes_to_handoff = []\n",
        "    for idx, action in df_multi_row_play['PlayDescription'].items():\n",
        "      if action.find('Handoff') != -1:\n",
        "        for i in list_indexes_to_handoff:\n",
        "          df_multi_row_play.loc[i, 'PlayType'] = 'Handoff Attempt'\n",
        "        break\n",
        "      else:\n",
        "        list_indexes_to_handoff.append(idx)\n",
        "\n",
        "  return df_multi_row_play"
      ],
      "metadata": {
        "id": "b8VnKaK1aniA"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCAisXBXGNyb"
      },
      "source": [
        "#### helper methods for penalties"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTES:\n",
        "# - I think that it is crucial to note that only plays where the team with the ball\n",
        "#   (offense or defense) are affected and ultimately worked on in this method.\n",
        "#   Penalties that aid the team with the ball will not be looked at because those\n",
        "#   do not effect the stats for either the ball carrier or qb or whoever. Only\n",
        "#   penalties against the team with the ball have effects on player stats.\n",
        "\n",
        "# Potential new features to add\n",
        "# - How far do I want to take this? I do not want unneccessary features\n",
        "#   that will just take up space.\n",
        "# - For now I will do the bare minimum.\n",
        "# 1. AcceptedPenalty\n",
        "# 2. DeclinedPenalty\n",
        "\n",
        "# FEATURE IDEAS IF I WANTED TO EXTEND\n",
        "# X 1. Yardage from penalty (?)(Will not add this right now)\n",
        "# X 2. Offensive penalty (?) (I do not think I want to go through with this yet)\n",
        "# X 3. Defensive penalty (?) (I do not think I want to go through with this yet)\n",
        "#    - I think these are features that would be beneficial but I could save space\n",
        "#      by grouping accepted penalties and declined penalties. (FOR NOW)\n",
        "# X 4. 'total yards gained' (?)\n",
        "#    - This way, I can easily grab\n",
        "#      1. Yards from play\n",
        "#      2. Yards from penalty\n",
        "#      3. Yards gained all together\n",
        "# X 5. 'Player awarded yardage' (?)\n",
        "#     - A feature strictly for yardage gained for the intented offensive player\n",
        "\n",
        "# PURPOSE:\n",
        "# - Categorize whether the penalty was offensive or defensive.\n",
        "#   - Helper method for 'accepted_penalty_play_on_offense'\n",
        "\n",
        "# INPUT PARAMETERS:\n",
        "# df_plays       - dataframe - dataframe of plays\n",
        "# play           -  String   - 'PlayDescription' of the current play that is being cleaned\n",
        "# play_index     -  Integer  - index of play (Almost always from main dataframe of plays)\n",
        "# start_string   -  String   - The string that contains the spotting of the beginning of the play for\n",
        "#                              that specific play type\n",
        "# dict_start     -   Dict    - A map that has a key of regular expressions and values of where to grab\n",
        "#                              the start of the play for that particular play type\n",
        "# end_string     -  String   - The string that contains the spotting of the end of the play for that\n",
        "#                              specific play type\n",
        "# dict_end       -   Dict    - A map that has a key of regular expressions and values of where to grab\n",
        "#                              the end of the play for that particular play type\n",
        "# yardage_string -  String   - A string that contains the yardage gained for that particular play type\n",
        "# dict_yardage   -   Dict    - A map that has a key of regular expressions and values of where to grab\n",
        "#                              the yardage of the play for that particular play type\n",
        "\n",
        "# RETURN/OUTCOME:\n",
        "# - Categorize offensive/defensive penalty to play's feature 'AcceptedPenalty' or 'DeclinedPenalty'\n",
        "\n",
        "def extract_penalty_data(df_plays, play, play_index, start_string, dict_start, end_string, dict_end, yardage_string, dict_yardage):\n",
        "\n",
        "  # Accepted Penalty\n",
        "  if play.find('PENALTY') != -1:\n",
        "    accepted_penalties = []\n",
        "    play_elements = play.split(\". \")\n",
        "    for i in play_elements:\n",
        "      if i.find('PENALTY') != -1:\n",
        "        accepted_penalties.append(i)\n",
        "        # Strictly looking for penalties against team with ball\n",
        "        # 1. Could be offense on a traditional play (pass/rush/etc...)\n",
        "        # 2. Could be defensive team on a defensive takeaway run (interception/fumble/etc..)\n",
        "        penalty_player_team = re.findall(name_pattern, i)\n",
        "        if len(penalty_player_team) > 0:\n",
        "          if penalty_player_team[0].split(\"-\")[0] == df_plays['TeamWithPossession'].loc[play_index]:\n",
        "            # Important to note that the feature 'Yardage' is player awarded yardage for intended play.\n",
        "            # - This does not factor in the yards penalized from the penalty.\n",
        "            df_plays.loc[play_index, 'Yardage'] = accepted_penalty_play_on_offense(df_plays, play, play_index, start_string, dict_start, end_string, dict_end, yardage_string, dict_yardage)\n",
        "    df_plays.at[play_index, 'AcceptedPenalty'] = accepted_penalties\n",
        "\n",
        "  # Declined Penalty\n",
        "  if play.find('Penalty') != -1:\n",
        "    declined_penalties = []\n",
        "    play_elements = play.split(\". \")\n",
        "    for i in play_elements:\n",
        "      if i.find('Penalty') != -1:\n",
        "        declined_penalties.append(i)\n",
        "    df_plays.at[play_index, 'DeclinedPenalty'] = declined_penalties\n",
        "\n",
        "# NOTES:\n",
        "\n",
        "# PENALTY YARDAGE RULES (yardage awarded to offensive players when offensive penalty occurs):\n",
        "# 1. If the penalty was beyond the line of scrimmage and brought back, the rusher is\n",
        "#    awarded with any positive gained yards up to the spotting of the ball.\n",
        "# 2. If the penalty was behind or at the line of scrimmage, the play does does not count.\n",
        "#    - This should not count as a rushing attempt 'Play Type' should be 'No play'\n",
        "#    - 'Yardage' will be 0.0\n",
        "\n",
        "# WHAT TO FIND\n",
        "# 1. Where the play started\n",
        "# 2. Positive direction for the offense (field awareness?)\n",
        "#    - I need to know which end zone the offense is trying to reach\n",
        "#      - Brake the positioning of the play (start, end, penalty) down to a scale of 0-100\n",
        "#        EXAMPLE:\n",
        "#        - original:\n",
        "#          (start: BUF 30, end: BUF 20, yardage: 10, penalty: offense 5 yards at BUF 30)\n",
        "#        - scaled:\n",
        "#          (start: 70,     end: 80,     yardage: 10, penalty: -5 yards at 80)\n",
        "\n",
        "# PURPOSE:\n",
        "# - Find yardage awarded to offensive players on penalized plays\n",
        "\n",
        "# INPUT PARAMETERS:\n",
        "# df_plays       - dataframe - dataframe of plays\n",
        "# play           -  String   - 'PlayDescription' of the current play that is being cleaned\n",
        "# play_index     -  Integer  - index of play (Almost always from main dataframe of plays)\n",
        "# start_string   -  String   - The string that contains the spotting of the beginning of the play for\n",
        "#                              that specific play type\n",
        "# dict_start     -   Dict    - A map that has a key of regular expressions and values of where to grab\n",
        "#                              the start of the play for that particular play type\n",
        "# end_string     -  String   - The string that contains the spotting of the end of the play for that\n",
        "#                              specific play type\n",
        "# dict_end       -   Dict    - A map that has a key of regular expressions and values of where to grab\n",
        "#                              the end of the play for that particular play type\n",
        "# yardage_string -  String   - A string that contains the yardage gained for that particular play type\n",
        "# dict_yardage   -   Dict    - A map that has a key of regular expressions and values of where to grab\n",
        "#                              the yardage of the play for that particular play type\n",
        "\n",
        "# RETURN/OUTCOME:\n",
        "# - Fill feature 'Yardage' for play containing offensive penalty.\n",
        "\n",
        "def accepted_penalty_play_on_offense(df_plays, play, play_index, start_string, dict_start, end_string, dict_end, yardage_string, dict_yardage):\n",
        "\n",
        "  # Situations where a penalty does not affect an offensive players yardage during\n",
        "  # a penalized play.\n",
        "  # 1. An incomplete pass will always result in a 0 gained yards.\n",
        "  # 2. If a 'PlayStart' is null, it is likely a 2PT conversion attempt(?)\n",
        "  #    - Players are not awarded yardage on a 2PT conversion attempt.\n",
        "  if df_plays['PlayOutcome'].loc[play_index] == 'Pass Incomplete':\n",
        "    return 0.0\n",
        "  if df_plays['PlayStart'].loc[play_index] is None:\n",
        "    return 0.0\n",
        "\n",
        "  # VARIABLES:\n",
        "  # 1. Starting point (on 100 yard format)\n",
        "  # 2. ending point (on 100 yard format)\n",
        "  # 3. penalty enforcement (on 100 yard format)\n",
        "  # BASIC ALGORITHM:\n",
        "  # 1. penalty enforcement - starting point\n",
        "  #    - If result < 0:\n",
        "  #      - yardage = 0.0\n",
        "  #    - else:\n",
        "  #      - yardage = result\n",
        "\n",
        "  # Starting variables (e.g. BUF 20)\n",
        "  # - Normally will be the line of scrimmage.\n",
        "  # - Can also be the start of when a punt was caught on a punt return.\n",
        "  start_territory = None\n",
        "  start_yardage = 0\n",
        "  # End variables (e.g. BUF 40)\n",
        "  end_territory = None\n",
        "  end_yardage = 0\n",
        "  # Penalty variables (e.g. BUF 30)\n",
        "  penalty_territory = None\n",
        "  penalty_yardage = 0\n",
        "\n",
        "  # ALL CLEANING METHODS THAT CURRENTLY HAVE THIS HELPER METHOD:\n",
        "\n",
        "  # PLAN:\n",
        "  # I need to grab specific bits of data from a play, each bit\n",
        "  # requiring a string from some feature of the play row and a regular\n",
        "  # expression to grab the data from within the string.\n",
        "  # - Instead of having an \"if\" statement for each playtype,\n",
        "  #   I am going to send in the string required and a dictionary of regular\n",
        "  #   expressions that could give me the information that I need.\n",
        "  #   - each regular expression within the dictionary will have a:\n",
        "  #     KEY - the regular expression\n",
        "  #     VALUE - indexes of the data within the regular expression that I need.\n",
        "\n",
        "  # 1. clean_pass_plays\n",
        "  #    START:             string - 'PlayStart' feature # <---- What happens if there isn't a playstart?\n",
        "  #           regular expression - play_start_pattern\n",
        "  #                    territory - 0\n",
        "  #                      yardage - 1\n",
        "  #    END:               string - PlayDescription\n",
        "  #           regular expression - standard_play_end_pattern\n",
        "  #                    territory - 0\n",
        "  #                      yardage - 1\n",
        "  #    PLAY YARDAGE:      string - PlayDescription\n",
        "  #           regular expression - standard_play_end_pattern\n",
        "  #                      yardage - 2\n",
        "  # NOTE:\n",
        "  # - I don't think that I have passing penalties correct.\n",
        "  #   - (4:00) (Shotgun) M.Jones pass short left to E.Elliott to PHI 29 for 6 yards (R.Blankenship; J.Bradberry)\n",
        "  #     PENALTY on NE-A.Mafi, Offensive Holding, 10 yards, enforced at PHI 29.\n",
        "  #     - With the current model that I have, I have the penalty spotting to be at PH 29\n",
        "  #       not 10 yards from PHI 29.\n",
        "\n",
        "  # 2. clean_intercepted_plays\n",
        "  #    START:             string - original PlayDescription\n",
        "  #           regular expression - interception_play_end_pattern\n",
        "  #                    territory - 1\n",
        "  #                      yardage - 2\n",
        "  #    END:               string - original PlayDescription\n",
        "  #           regular expression - defensive_takeaway_run_pattern\n",
        "  #                    territory - 1\n",
        "  #                      yardage - 2\n",
        "  #    PLAY YARDAGE:      string - original PlayDescription\n",
        "  #           regular expression - defensive_takeaway_run_pattern\n",
        "  #                      yardage - 3\n",
        "\n",
        "  # 3. clean_run_plays\n",
        "  #    START:             string - 'PlayStart' feature\n",
        "  #           regular expression - play_start_pattern\n",
        "  #                    territory - 0\n",
        "  #                      yardage - 1\n",
        "  #    END:               string - PlayDescription\n",
        "  #           regular expression - standard_play_end_pattern\n",
        "  #                    territory - 0\n",
        "  #                      yardage - 1\n",
        "  #    PLAY YARDAGE:      string - PlayDescription\n",
        "  #           regular expression - standard_play_end_pattern\n",
        "  #                      yardage - 2\n",
        "\n",
        "  # 4. cleaning_2pt_conversion_plays\n",
        "  #    START:             string - 'PlayStart' feature\n",
        "  #           regular expression - play_start_pattern\n",
        "  #                    territory - 0\n",
        "  #                      yardage - 1\n",
        "  #    END:               string - PlayDescription\n",
        "  #           regular expression - standard_play_end_pattern\n",
        "  #                    territory - 0\n",
        "  #                      yardage - 1\n",
        "  #    PLAY YARDAGE:      string - PlayDescription\n",
        "  #           regular expression - standard_play_end_pattern\n",
        "  #                      yardage - 2\n",
        "\n",
        "  # 5. clean_sacked_plays\n",
        "  #    START:             string - 'PlayStart' feature\n",
        "  #           regular expression - play_start_pattern\n",
        "  #                    territory - 0\n",
        "  #                      yardage - 1\n",
        "  #    END:               string - PlayDescription\n",
        "  #           regular expression - standard_play_end_pattern\n",
        "  #                    territory - 0\n",
        "  #                      yardage - 1\n",
        "  #    PLAY YARDAGE:      string - PlayDescription\n",
        "  #           regular expression - standard_play_end_pattern\n",
        "  #                      yardage - 2\n",
        "\n",
        "  # 6. clean_punt_plays\n",
        "  #    START:             string - original PlayDescription\n",
        "  #           regular expression - punting_pattern\n",
        "  #                    territory - 2\n",
        "  #                      yardage - 3\n",
        "  #    END:               string - PlayDescription\n",
        "  #           regular expression - standard_play_end_pattern\n",
        "  #                    territory - 0\n",
        "  #                      yardage - 1\n",
        "  #    PLAY YARDAGE:      string - PlayDescription\n",
        "  #           regular expression - standard_play_end_pattern\n",
        "  #                      yardage - 2\n",
        "\n",
        "  # 7. clean_kickoff_plays\n",
        "  #    START:             string - original PlayDescription\n",
        "  #           regular expression - punting_pattern\n",
        "  #                    territory - 2\n",
        "  #                      yardage - 3\n",
        "  #    END:               string - PlayDescription\n",
        "  #           regular expression - standard_play_end_pattern\n",
        "  #                    territory - 0\n",
        "  #                      yardage - 1\n",
        "  #    PLAY YARDAGE:      string - PlayDescription\n",
        "  #           regular expression - standard_play_end_pattern\n",
        "  #                      yardage - 2\n",
        "\n",
        "  # Penalty data\n",
        "  list_different_penalty_enforcements = [penalty_yardage_pattern, between_downs_penalty_yardage_pattern]\n",
        "  for penalty_enforcement_type in list_different_penalty_enforcements:\n",
        "    penalty_elements = re.findall(penalty_enforcement_type, play)\n",
        "    if len(penalty_elements) > 0:\n",
        "      # If penalty was enforced between downs, yardage from intended play is not affected\n",
        "      if penalty_enforcement_type == between_downs_penalty_yardage_pattern:\n",
        "        return df_plays['Yardage'].loc[play_index]\n",
        "      break\n",
        "  penalty_territory = penalty_elements[0][1]\n",
        "  penalty_yardage = int(penalty_elements[0][2])\n",
        "\n",
        "  # Start\n",
        "  for start_pattern in dict_start:\n",
        "    start_elements = re.findall(start_pattern, start_string)\n",
        "    if len(start_elements) > 0:\n",
        "      start_territory = start_elements[0][int(dict_start.get(start_pattern)[0])]\n",
        "      start_yardage = int(start_elements[0][int(dict_start.get(start_pattern)[1])])\n",
        "      break\n",
        "\n",
        "  # End\n",
        "  for end_pattern in dict_end:\n",
        "    end_elements = re.findall(end_pattern, end_string)\n",
        "    if len(end_elements) > 0:\n",
        "      end_territory = end_elements[0][int(dict_end.get(end_pattern)[0])]\n",
        "      end_yardage = int(end_elements[0][int(dict_end.get(end_pattern)[1])])\n",
        "      break\n",
        "  if end_territory is None:\n",
        "    return 0.0\n",
        "\n",
        "  # Play Yardage\n",
        "  for yard_pattern in dict_yardage:\n",
        "    yard_elements = re.findall(yard_pattern, yardage_string)\n",
        "    if len(yard_elements) > 0:\n",
        "      if yard_elements[0][int(dict_yardage.get(yard_pattern)[0])] == 'no gain':\n",
        "        play_yardage = 0\n",
        "      else:\n",
        "        play_yardage = int(yard_elements[0][int(dict_yardage.get(yard_pattern)[0])])\n",
        "      break\n",
        "\n",
        "  # Need to figure out which zone the offense is in and which direction they are fighting for given:\n",
        "  # 1. position yardage (+/-)\n",
        "  #    - Take the starting position and ending position, is the difference between\n",
        "  #      them positive or negaive? (e.g. BUF 30 -> BUF 40 is +)\n",
        "  # 2. play yardage (+/-)\n",
        "  #    - Did the intended play gain yardage or lose yardage?\n",
        "\n",
        "  # - I need to figure out which direction the penalty is going towards.\n",
        "  #   - Initially I am thinking that it would be the opposite of positive yardage.\n",
        "\n",
        "  # Standard cases:\n",
        "  # position yardage (+) & play yardage (+):\n",
        "  # - the starting position team zone is the beginning (0-50)\n",
        "  # position yardage (-) & play yardage (+):\n",
        "  # - the starting position team zone is the ending (50-100)\n",
        "  # position yardage (+) & play yardage (-):\n",
        "  # - the starting position team zone is the ending (50-100)\n",
        "  # position yardage (-) & play yardage (-):\n",
        "  # - the starting position team zone is the beginning (0-50)\n",
        "\n",
        "  # Unique cases:\n",
        "  # zones switch (e.g. KC 47 -> BUF 47)\n",
        "  # play yardage (+):\n",
        "  # - the starting position team zone is the beginning (0-50)\n",
        "  # play yardage (-):\n",
        "  # - the starting position team zone is the ending (50-100)\n",
        "  # penalty occured on the line of scrimmage\n",
        "  # - doesn't matter. yardage gained is 0\n",
        "\n",
        "  # 0-100 yard format\n",
        "  # EXAMPLE: GB 30\n",
        "  # GB is the 0-50 yard territory: 30 yards\n",
        "  # GB is the 50-100 yard territory: 100 - 30 = 70 yards\n",
        "\n",
        "  starting_fifty_to_end_zone = False\n",
        "  penalty_enforcement_fifty_to_end_zone = False\n",
        "\n",
        "  # Start territory and end territory are the same\n",
        "  if start_territory == end_territory:\n",
        "    # position yardage (+) (e.g. BUF 10 -> BUF 20)\n",
        "    if start_yardage < end_yardage:\n",
        "      # play yardage (-) (e.i. gained negative yards on play)\n",
        "      if play_yardage < 0:\n",
        "        starting_fifty_to_end_zone = True\n",
        "        penalty_enforcement_fifty_to_end_zone = True\n",
        "    else:\n",
        "      # play yardage (+) (e.i. gained positive yards on play)\n",
        "      if play_yardage > 0:\n",
        "        starting_fifty_to_end_zone = True\n",
        "        penalty_enforcement_fifty_to_end_zone = True\n",
        "  # Start territory and end territory are different\n",
        "  else:\n",
        "    # play yardage (+)\n",
        "    if play_yardage > 0:\n",
        "      zero_to_fifty_zone = start_territory\n",
        "      # penalty territory and start territory are different\n",
        "      if penalty_territory != zero_to_fifty_zone:\n",
        "        penalty_enforcement_fifty_to_end_zone = True\n",
        "    # play yardage (-)\n",
        "    else:\n",
        "      fifty_to_hundred_zone = start_territory\n",
        "      starting_fifty_to_end_zone = True\n",
        "      if penalty_territory == fifty_to_hundred_zone:\n",
        "        penalty_enforcement_fifty_to_end_zone = True\n",
        "\n",
        "  if starting_fifty_to_end_zone:\n",
        "    start_yardage = 100 - start_yardage\n",
        "  if penalty_enforcement_fifty_to_end_zone:\n",
        "    penalty_yardage = 100 - penalty_yardage\n",
        "\n",
        "  resulting_player_awarded_yardage = penalty_yardage - start_yardage\n",
        "\n",
        "  if resulting_player_awarded_yardage < 0:\n",
        "    return 0.0\n",
        "  else:\n",
        "    return resulting_player_awarded_yardage"
      ],
      "metadata": {
        "id": "82ge_k7ecifS"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### helper method for laterals"
      ],
      "metadata": {
        "id": "_Qs4C1j5asbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STILL A WORK IN PROGRESS. WILL 1000000% NEED TO ITERATE OVER TIME.\n",
        "\n",
        "# PURPOSE:\n",
        "# - To effectively clean plays that have laterals within them\n",
        "\n",
        "# FUNCTION:\n",
        "# - INPUT:\n",
        "#   1. dataframe of plays\n",
        "#   2. index of lateral play\n",
        "#   3. cleaning method using this helper method\n",
        "# - OUTPUT:\n",
        "#   1. dataframe (probably multiple rows) representing play cleaned\n",
        "\n",
        "# THOUGHTS:\n",
        "# - I think that a lateral will have to be separated into multiple rows.\n",
        "#   ROWS:\n",
        "#   1. initial play..\n",
        "#      - (Run / Pass / Punt Return / interception / etc..)\n",
        "#      - Although I have not seen this yet, I believe that a lateral could set\n",
        "#        up the main action of the play.\n",
        "#        - For example, there could be a lateral behind the line of scrimmage\n",
        "#          and then a pass following after.\n",
        "#   2. A new row for every lateral.\n",
        "# - I think this is a method that will have to evolve with time as more samples\n",
        "#   of laterals come in. I can't create a good method that will stand without\n",
        "#   more plays to clean.\n",
        "\n",
        "# WHAT I NEED:\n",
        "# - Ideally I would want parameters to be as minimal as possible.\n",
        "#   - This is a method that takes a single play description and will provide\n",
        "#     a potentially multi row replacement of that single play but cleaned.\n",
        "# - Would all I need is the play description..?\n",
        "#   - lets try\n",
        "\n",
        "# DESIGN IDEA:\n",
        "\n",
        "#########################\n",
        "# DATA COLLECTION PHASE #\n",
        "#########################\n",
        "\n",
        "# 1. Parameters:\n",
        "#    1. dataframe of plays\n",
        "#    2. index of play with lateral\n",
        "#    3. cleaning method using this helper method\n",
        "\n",
        "# 2. Locate lateral play\n",
        "#    - Save copy of entry to refer back to\n",
        "#    - Save copy of 'PlayDescription' feature\n",
        "\n",
        "# 3. Separate each sentence within 'PlayDescription' feature\n",
        "\n",
        "##########################\n",
        "# DATA ORGANIZAION PHASE #\n",
        "##########################\n",
        "\n",
        "# 4. Organize each sentence within play into list\n",
        "#    - All main actions will have their own rows\n",
        "#      - secondary actions (such as fumbles) will be add ons for those particular rows..\n",
        "#        - I will not worry about this now because I do not have a sample to test this.\n",
        "#    - I imagine the data structure for this will look something like this\n",
        "#      - DATA STRUCTURE: (list of lists)\n",
        "#        - [[action 1], [action 2, action 2 subaction], [action 3]]\n",
        "\n",
        "##################\n",
        "# CLEANING PHASE #\n",
        "##################\n",
        "# 5. Create list to put cleaned single row dataframes\n",
        "#    - Each action that is cleaned will be it's own single row dataframe\n",
        "#      - Once the action is cleaned, I will append it to the list and at the end\n",
        "#        will concatenate the list of cleaned single row dataframes to create a\n",
        "#        single dataframe and return it.\n",
        "# 6. Clean main play\n",
        "#    - I need to decipher what the initial play was and clean it\n",
        "#      - The initial play will be the first play within the list so I can 'pop'\n",
        "#        that play out and focus on that element of the play.\n",
        "#      - I could leverage where this play came from and use that\n",
        "#        - What I mean is that if this lateral play was initially being cleaned by\n",
        "#          'clean_pass_plays' then I will clean the initial play using that method.\n",
        "\n",
        "# INITIAL PLAY TYPES AND HOW TO CLEAN THEM\n",
        "# - Because the sample size that I am working with is so small, I will have to come back to this\n",
        "#   and iterate this method as I get exposed to more lateral plays.\n",
        "\n",
        "# PASSING PLAY\n",
        "# - If the initial play before the lateral is a passing play,\n",
        "#   there will be 2 rows representing the initial pass. ( 1. Passer, 2. Receiver )\n",
        "#   - Use return dataframe to make an extra copy:\n",
        "#     1. df_passer_row (will use original return dataframe copy)\n",
        "#     2. df_receiver_row (will be created and added to return dataframe)\n",
        "#        - Dataframe at this point should have a length of 2\n",
        "#   ROWS:\n",
        "#   1. PASSER\n",
        "#      - FEATURES:\n",
        "#        1. 'PlayDescription' - Sentence that contains play description of pass (Same as receiver row)\n",
        "#        2. 'Passer' - Record name of passer\n",
        "#        3. 'Receiver' - Record name of receiver as 'nan'\n",
        "#            - Receiver will have own row\n",
        "#        4. 'Yardage' - (Will be recorded during the cleaning of secondary actions)\n",
        "#            - Passing yards equivalent to how far the ball goes beyond the line of scrimmage\n",
        "#              - This is the main reason why the 'Passer' and 'Receiver' have separate rows.\n",
        "#   2. RECEIVER\n",
        "#      - FEATURES:\n",
        "#        1. 'PlayDescription' - Sentence that contains play description of pass (Same as passer row)\n",
        "#        2. 'Passer' - Record name of passer as 'nan'\n",
        "#            - Passer has own row\n",
        "#        3. 'Receiver' - Record name of receiver\n",
        "#        4. 'Yardage' - (Depends on outcome of lateral)\n",
        "#           - IF this receiver catches and laterals behind LOS ( (-) yards ):\n",
        "#             - IF lateral player goes beyond LOS:\n",
        "#               - This receiver gains 0 yardage\n",
        "#             - ELSE (lateral player stays behind LOS)\n",
        "#               - This receiver gains (-) yards where ball was lateraled\n",
        "#           - ELSE (this receiver catches and laterals beyond LOS ( (+) yards )):\n",
        "#             - this receiver gains yards until ball is lateraled (LOS -> this receiver laterals)\n",
        "\n",
        "\n",
        "#  - How will secondary laterals be able to access these rows within new dataframe to\n",
        "#    adjust yardage for both ( 1. Passer, 2. Receiver ) rows?\n",
        "#    - I am thinking that because the 'Passer' row will be the first row, then I could\n",
        "#      have the values of yardage I receive from these go straight to the first row of the dataframe.\n",
        "\n",
        "\n",
        "\n",
        "# 7. Clean remaining actions within list\n",
        "#    - Cycle through remaining actions within list (Loop)\n",
        "#      - decipher which action is taking place using regular expressions\n",
        "#        - If the action looks like a running play, clean it as a running play\n",
        "#          - This is where I think things can get sticky and I will have to iterate\n",
        "#            as time goes on and I get bigger samples.\n",
        "#          - For now, I will only add actions that I have come across so far.\n",
        "#        - Fow now, I will have the assumption that all actions after a lateral can be\n",
        "#          cleaned using the 'clean_run_plays' method. (I also might just clean it entirely within this method)\n",
        "#          - The type of yardage should refect the initial playtype\n",
        "#            - So this may mean that the 'PlayType' feature should be something like\n",
        "#              'lateral passing play' if the initial play was a passing play\n",
        "\n",
        "# REMAINING PLAY TYPES AND HOW TO CLEAN THEM\n",
        "\n",
        "# PASSING (INITIAL PLAY IS A PASSING PLAY)\n",
        "# - FEATURES:\n",
        "#   1. 'PlayDescription' - Sentence that contains the lateral play\n",
        "#   2. 'Receiver' - Player who received the lateral\n",
        "#   3. 'Yardage' - 2 different yardages will be captured:\n",
        "#       1. Yardage for player who received this lateral\n",
        "#          - FROM ( reception of the ball | LOS ) -> TO ( The end of their carry )\n",
        "#            - FROM\n",
        "#              - IF the start distance is behind the line of scrimmage:\n",
        "#                - the start distance will be from the LOS ( 'Yardage' (Player) = end of carry - LOS )\n",
        "#                  - IF player receives (+) yards:\n",
        "#                    - All players who held the ball before will have a yardage value of 0\n",
        "#              - ELSE the start distance is beyond the LOS:\n",
        "#                - the start distance will be from where the ball was lateralled ('Yardage' (Player) = end of carry - reception of ball)\n",
        "#            - TO\n",
        "#              - End of carry (Will be within PlayDescription)\n",
        "#       2. Distance from the line of scrimmage -> The end of their carry\n",
        "#          - FROM ( LOS ) -> TO end of carry\n",
        "#            - FROM\n",
        "#              - Line of scrimmage (taken from 'PlayStart' feature)\n",
        "#            - TO\n",
        "#              - End of carry (Will be within PlayDescription)\n",
        "#          - This will happen through every action found within loop (Every lateral)\n",
        "#            - Passer receives passing yards based off how far the ball traveled during play\n",
        "# - Add action row to return dataframe and go to the next\n",
        "\n",
        "####################\n",
        "# RETURN DATAFRAME #\n",
        "####################\n",
        "\n",
        "# 8. Return new cleaned lateral play replacement dataframe\n",
        "#    1. concat all cleaned single row dataframes within list of cleaned single row dataframes.\n",
        "#    2. return dataframe containing all cleaned actions\n",
        "\n",
        "def extract_lateral_data(df_plays, play_index, main_cleaning_method):\n",
        "\n",
        "  # 2. Locate lateral play\n",
        "  original_play_copy = df_plays.loc[[play_index]].copy().reset_index(drop=True)\n",
        "  play = original_play_copy['PlayDescription'].iloc[0]\n",
        "\n",
        "  # 3. Separate each sentence within 'PlayDescription' feature\n",
        "  play_elements = play.split(\". \")\n",
        "  # print(f\"ALL ELEMENTS IN PLAY\\n{play_elements}\")\n",
        "  # print()\n",
        "\n",
        "  # 4. Organize each sentence within play into list\n",
        "  play_split = []\n",
        "  for action in play_elements:\n",
        "\n",
        "    # Main Actions\n",
        "    if re.search(standard_play_end_pattern, action) != None:\n",
        "      play_split.append([action])\n",
        "      continue\n",
        "\n",
        "    # secondary actions (such as fumbles)\n",
        "    # - Expecting this to be present for next iteration\n",
        "\n",
        "  # print(f\"ALL ELEMENTS GRABBED\\n{play_split}\")\n",
        "  # print()\n",
        "\n",
        "  # 5. Create list to put cleaned single row dataframes\n",
        "  cleaned_actions_list = []\n",
        "  # Variable to keep track of where lateral spotting is\n",
        "  lateral_spotting = None\n",
        "\n",
        "  # 6. Clean main play\n",
        "  initial_play_description = play_split.pop(0)\n",
        "  # print(f\"INITIAL PLAY\\n{initial_play_description}\")\n",
        "  # print()\n",
        "\n",
        "  unclean_intended_play = original_play_copy.copy()\n",
        "  unclean_intended_play['PlayDescription'] = initial_play_description\n",
        "\n",
        "  # PASSING PLAY\n",
        "  if main_cleaning_method == clean_pass_plays:\n",
        "    # PASSER\n",
        "    df_passer_row = unclean_intended_play.copy()\n",
        "    df_passer_row.loc[0, 'Passer'] = re.findall(passer_name_pattern, df_passer_row['PlayDescription'].iloc[0])[0]\n",
        "    cleaned_actions_list.append(df_passer_row)\n",
        "    # RECEIVER\n",
        "    df_receiver_row = unclean_intended_play.copy()\n",
        "    df_receiver_row.loc[0, 'Receiver'] = re.findall(receiver_pattern, df_receiver_row['PlayDescription'].iloc[0])[0][2]\n",
        "    end_spotting = re.findall(standard_play_end_pattern, df_receiver_row['PlayDescription'].iloc[0])[0]\n",
        "    df_receiver_row.loc[0, 'Yardage'] = int(end_spotting[2])\n",
        "    lateral_spotting = end_spotting\n",
        "    cleaned_actions_list.append(df_receiver_row)\n",
        "\n",
        "  # RUSHING PLAY\n",
        "  if main_cleaning_method == clean_run_plays:\n",
        "    df_rusher_row = unclean_intended_play.copy()\n",
        "    df_rusher_row.loc[0, 'Rusher'] = re.findall(rusher_pattern, df_rusher_row['PlayDescription'].iloc[0])[0]\n",
        "    df_rusher_row.loc[0, 'Yardage'] = int(re.findall(standard_play_end_pattern, df_rusher_row['PlayDescription'].iloc[0])[0][2])\n",
        "    cleaned_actions_list.append(df_rusher_row)\n",
        "\n",
        "  # 7. Clean remaining actions within list\n",
        "  while(len(play_split) > 0):\n",
        "    play = play_split.pop(0)\n",
        "    lateral_row = original_play_copy.copy()\n",
        "    lateral_row['PlayDescription'] = play\n",
        "    lateral_data = re.findall(lateral_reception_pattern, play[0])\n",
        "    lateral_receiver = lateral_data[0][0]\n",
        "    lateral_end_spotting = [lateral_data[0][1], lateral_data[0][2]]\n",
        "    lateral_yardage = int(lateral_data[0][3])\n",
        "\n",
        "    # Yardage for player\n",
        "    # - Is lateral reception before or after line of scrimmage\n",
        "    #   - See if yardage from lateral reception and line of scrimmage is (+) or (-)\n",
        "    # - 'lateral_spotting' is not sustainable like this. Need to update if there are multiple laterals.\n",
        "    #   right now it grabs the lateral from the main action cleaning.\n",
        "    check_lateral_before_after_los = yardage_between_spottings(lateral_spotting,\n",
        "                                                               re.findall(play_start_pattern, lateral_row['PlayStart'].iloc[0])[0],\n",
        "                                                               cleaned_actions_list[len(cleaned_actions_list)-1]['Yardage'].iloc[0])\n",
        "\n",
        "    # lateral after LOS\n",
        "    if check_lateral_before_after_los > 0:\n",
        "      lateral_row.loc[0, 'Yardage'] = yardage_between_spottings(lateral_spotting,\n",
        "                                                                lateral_end_spotting,\n",
        "                                                                lateral_yardage)\n",
        "\n",
        "    # lateral before LOS\n",
        "    else:\n",
        "      lateral_row.loc[0, 'Yardage'] = yardage_between_spottings(re.findall(play_start_pattern, lateral_row['PlayStart'].iloc[0])[0],\n",
        "                                                                lateral_end_spotting,\n",
        "                                                                lateral_yardage)\n",
        "\n",
        "      # If lateral took place before line of scrimmage &\n",
        "      # ended passed line of scrimmage, then everyone apart of the lateral\n",
        "      # before the line of scrimmage gets 0 yardage instead of their (-).\n",
        "      if lateral_row['Yardage'].iloc[0] > 0:\n",
        "        for action_row in cleaned_actions_list:\n",
        "          action_row.loc[0, 'Yardage'] = 0\n",
        "\n",
        "    if main_cleaning_method == clean_run_plays:\n",
        "      # Name of rusher\n",
        "      lateral_row.loc[0, 'Rusher'] = lateral_receiver\n",
        "      # changin 'playtype' for lateral row\n",
        "      lateral_row.loc[0, 'PlayType'] = 'lateral after run'\n",
        "\n",
        "    if main_cleaning_method == clean_pass_plays:\n",
        "      # Name of lateral receiver\n",
        "      lateral_row.loc[0, 'Receiver'] = lateral_receiver\n",
        "      # changin 'playtype' for lateral row\n",
        "      lateral_row.loc[0, 'PlayType'] = 'lateral after pass'\n",
        "      # Yardage for passer\n",
        "      line_of_scrimmage = re.findall(play_start_pattern, lateral_row['PlayStart'].iloc[0])[0]\n",
        "      cleaned_actions_list[0].loc[0, 'Yardage'] = yardage_between_spottings(line_of_scrimmage, lateral_end_spotting, lateral_yardage)\n",
        "\n",
        "    # Need to see if there was another lateral, update 'lateral_spotting'\n",
        "    # - Will update when time comes.\n",
        "    cleaned_actions_list.append(lateral_row)\n",
        "\n",
        "  #############\n",
        "  #  DEFENSE  #\n",
        "  #############\n",
        "\n",
        "  solo_tackle = re.findall(solo_tackle_pattern, original_play_copy['PlayDescription'].iloc[0])\n",
        "  if len(solo_tackle) > 0:\n",
        "    cleaned_actions_list[len(cleaned_actions_list) - 1].loc[0, 'SoloTackle'] = solo_tackle[0]\n",
        "\n",
        "  shared_tackle = re.findall(shared_tackle_pattern, original_play_copy['PlayDescription'].iloc[0])\n",
        "  if len(shared_tackle) > 0:\n",
        "    cleaned_actions_list[len(cleaned_actions_list) - 1].at[0, 'SharedTackle'] = shared_tackle[0]\n",
        "\n",
        "  assisted_tackle = re.findall(assisted_tackle_pattern, original_play_copy['PlayDescription'].iloc[0])\n",
        "  if len(assisted_tackle) > 0:\n",
        "    cleaned_actions_list[len(cleaned_actions_list) - 1].at[0, 'AssistedTackle'] = [assisted_tackle[0][0], assisted_tackle[0][1]]\n",
        "\n",
        "  return pd.concat(cleaned_actions_list, ignore_index=True)"
      ],
      "metadata": {
        "id": "p9s_a3Gua2Q1"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_HCeydwrbwx"
      },
      "source": [
        "### OFFENSE CLEANING METHODS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L_L6vxtmnLQ"
      },
      "source": [
        "#### PASS PLAYS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "cUrrWP2jI3yC"
      },
      "outputs": [],
      "source": [
        "# PURPOSE:\n",
        "# - Clean all passing type plays within a given dataframe.\n",
        "# INPUT PARAMETERS:\n",
        "# df_plays    - dataframe - NFL plays (can include play types other than passing)\n",
        "# index_start -  integer  - index where within the dataframe the method will start\n",
        "#                           cleaning in ascending order.\n",
        "# RETURN:\n",
        "# df_plays - dataframe - the same input df_plays but with all passing play types cleaned\n",
        "\n",
        "# NOTE:\n",
        "# - I want this to work with slices of the main dataframe as well.\n",
        "#   - Within slices, I think it is crucial to keep the original indexing from the main\n",
        "#     dataframe for ease to put back into the original dataframe.\n",
        "\n",
        "def clean_pass_plays(df_plays, index_start = None):\n",
        "\n",
        "  # Adjusting df_plays to start cleaning at a specified index (index_start)\n",
        "  if index_start != None:\n",
        "    df_plays_adjusted = df_plays.loc[index_start:]\n",
        "    # Locating all passing type plays within dataframe\n",
        "    df_pass_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('Pass')]\n",
        "  else:\n",
        "    # Locating all passing type plays within dataframe\n",
        "    df_pass_plays = df_plays[df_plays['PlayOutcome'].str.contains('Pass')]\n",
        "\n",
        "  for idx, play in df_pass_plays['PlayDescription'].items():\n",
        "\n",
        "    ################\n",
        "    # Play details #\n",
        "    ################\n",
        "\n",
        "    # Play Type\n",
        "    df_plays.loc[idx, 'PlayType'] = 'Pass'\n",
        "\n",
        "    # TimeOnTheClock\n",
        "    TimeOnTheClock = re.findall(time_on_clock_pattern, play)\n",
        "    if len(TimeOnTheClock) > 0:\n",
        "      df_plays.loc[idx, 'TimeOnTheClock'] = TimeOnTheClock[0]\n",
        "\n",
        "    ############\n",
        "    # REVERSES #\n",
        "    ############\n",
        "\n",
        "    # In 'PlayDescription' all information before the \"reversed\" sentence is not needed.\n",
        "    # - All information before is stored within 'ReverseDetails' and the remaining is cleaned.\n",
        "    if play.find('REVERSED') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      for i in play_elements:\n",
        "        if i.find(\"REVERSED\") != -1:\n",
        "          df_plays.at[idx, 'ReverseDetails'] = play_elements[:play_elements.index(i) + 1]\n",
        "          play = \". \".join(play_elements[play_elements.index(i) + 1:])\n",
        "          break\n",
        "\n",
        "    ############################\n",
        "    # REPORTING IN AS ELIGIBLE #\n",
        "    ############################\n",
        "\n",
        "    # I do not think this contains any useful data so I am going to exclude it.\n",
        "    if play.find('reported in as eligible') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      for i in play_elements:\n",
        "        if i.find('reported in as eligible') != -1:\n",
        "          play = \". \".join(play_elements[play_elements.index(i) + 1:])\n",
        "          break\n",
        "\n",
        "    ############\n",
        "    # LATERALS #\n",
        "    ############\n",
        "    # - It makes sense to check for laterals here because I need to use the start\n",
        "    #   of the entry with no features filled out as a template.\n",
        "    #   - I do not know how this will affect laterals that are fumbled\n",
        "    #   - I do not know how this will affect laterals that have penalties\n",
        "    if play.lower().find('lateral') != -1:\n",
        "      df_replacement_rows = extract_lateral_data(df_plays, idx, clean_pass_plays)\n",
        "      df_before = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before, df_replacement_rows, df_after], ignore_index=True)\n",
        "      index_of_last_added_row = idx + len(df_replacement_rows) - 1\n",
        "      if df_pass_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_pass_plays(df_plays, index_of_last_added_row + 1)\n",
        "\n",
        "    ###########\n",
        "    # FUMBLES #\n",
        "    ###########\n",
        "\n",
        "    # Additional rows may be added after certain types of fumbled passing plays.\n",
        "    # - The idea here is that, in those situations, the helping method 'extract_fumble_data'\n",
        "    #   will return a small dataframe of the rows that the single play split into.\n",
        "    #   - When this small dataframe is returned, it will replace the original play\n",
        "    #     within the main dataframe of plays and then continue on cleaning the rest of the passing plays.\n",
        "\n",
        "    if play.find('FUMBLES') != -1:\n",
        "      main_action_patterns = [passer_name_pattern, qb_fumble_pattern, defensive_takeaway_run_pattern]\n",
        "      map_who_fumbled_patterns = {\n",
        "          qb_fumble_pattern : 0,\n",
        "          receiver_pattern: 2\n",
        "      }\n",
        "      main_cleaning_method = clean_pass_plays\n",
        "      df_replacement_rows = extract_fumble_data(df_plays, play, idx,\n",
        "                                                main_action_patterns,\n",
        "                                                map_who_fumbled_patterns,\n",
        "                                                main_cleaning_method)\n",
        "\n",
        "      # \"df_plays.index.tolist().index(idx)\" needed for method usage with slices of original dataframe.\n",
        "      df_before = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before, df_replacement_rows, df_after], ignore_index=True)\n",
        "      index_of_last_added_row = idx + len(df_replacement_rows) - 1\n",
        "      if df_pass_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_pass_plays(df_plays, index_of_last_added_row + 1)\n",
        "\n",
        "    ###########\n",
        "    # OFFENSE #\n",
        "    ###########\n",
        "\n",
        "    # NOTE:\n",
        "    # - Incomplete passes will have 'PlayOutcome' as 'Pass Incomplete' as well\n",
        "    #   as yardage value being 0.0\n",
        "\n",
        "    # Yardage gained\n",
        "    yardage = re.findall(yardage_gained, play)\n",
        "    if len(yardage) > 0:\n",
        "      df_plays.loc[idx, 'Yardage'] = int(yardage[0])\n",
        "    else:\n",
        "      if df_plays.loc[idx, 'PlayOutcome'] == 'Pass Incomplete':\n",
        "        df_plays.loc[idx, 'Yardage'] = 0\n",
        "\n",
        "    # Overruled yardage gained\n",
        "    official_yardage = re.findall(official_pass_yards_pattern, play)\n",
        "    if len(official_yardage) > 0:\n",
        "      df_plays.loc[idx, 'Yardage'] = int(official_yardage[0])\n",
        "\n",
        "    # Formation\n",
        "    Formation = re.findall(formation, play)\n",
        "    if len(Formation) > 0:\n",
        "      if Formation[0] == 'Aborted':\n",
        "        pass\n",
        "      else:\n",
        "        df_plays.loc[idx, 'Formation'] = Formation[0]\n",
        "\n",
        "    # Passer (What about spikes?)\n",
        "    passer_name = re.findall(passer_name_pattern, play)\n",
        "    if len(passer_name) > 0:\n",
        "      df_plays.loc[idx, 'Passer'] = passer_name[0]\n",
        "\n",
        "    receiver_name_and_passing_details = re.findall(receiver_pattern, play)\n",
        "    if len(receiver_name_and_passing_details) > 0:\n",
        "      df_plays.loc[idx, 'Direction'] = f\"{receiver_name_and_passing_details[0][0]} {receiver_name_and_passing_details[0][1]}\"\n",
        "      df_plays.loc[idx, 'Receiver'] = receiver_name_and_passing_details[0][2]\n",
        "\n",
        "    # Unique situation (offense spikes the ball)\n",
        "    if play.find('spike') != -1:\n",
        "      df_plays.loc[idx, 'Direction'] = 'spiked' # Direction?\n",
        "\n",
        "    #############\n",
        "    #  DEFENSE  #\n",
        "    #############\n",
        "\n",
        "    solo_tackle = re.findall(solo_tackle_pattern, play)\n",
        "    if len(solo_tackle) > 0:\n",
        "      if df_plays.loc[idx, 'PlayDescription'].find('pass incomplete') != -1:\n",
        "        df_plays.loc[idx, 'PassDefendedBy'] = solo_tackle[0]\n",
        "      else:\n",
        "        df_plays.loc[idx, 'SoloTackle'] = solo_tackle[0]\n",
        "\n",
        "    shared_tackle = re.findall(shared_tackle_pattern, play)\n",
        "    if len(shared_tackle) > 0:\n",
        "      if df_plays.loc[idx, 'PlayDescription'].find('pass incomplete') != -1:\n",
        "        df_plays.at[idx, 'PassDefendedBy'] = shared_tackle[0]\n",
        "      else:\n",
        "        df_plays.at[idx, 'SharedTackle'] = shared_tackle[0]\n",
        "\n",
        "    assisted_tackle = re.findall(assisted_tackle_pattern, play)\n",
        "    if len(assisted_tackle) > 0:\n",
        "      df_plays.at[idx, 'AssistedTackle'] = [assisted_tackle[0][0], assisted_tackle[0][1]]\n",
        "\n",
        "    pressure_by = re.findall(defense_pressure_name_pattern, play)\n",
        "    if len(pressure_by) > 0:\n",
        "      df_plays.loc[idx, 'PressureBy'] = pressure_by[0]\n",
        "\n",
        "    ##############\n",
        "    #  INJURIES  #\n",
        "    ##############\n",
        "\n",
        "    injuries = re.findall(injury_pattern, play)\n",
        "    if len(injuries) > 0:\n",
        "      df_plays.at[idx, 'InjuredPlayers'] = injuries\n",
        "\n",
        "    #############\n",
        "    #  PENALTY  #\n",
        "    #############\n",
        "\n",
        "    if play.lower().find('penalty') != -1:\n",
        "      # start of play\n",
        "      start_string = df_plays['PlayStart'].loc[idx]\n",
        "      dict_start = {\n",
        "          play_start_pattern: [0, 1]\n",
        "      }\n",
        "      # end of play\n",
        "      end_string = play\n",
        "      dict_end = {\n",
        "          standard_play_end_pattern: [0, 1]\n",
        "      }\n",
        "      # play yardage\n",
        "      play_yardage_string = play\n",
        "      dict_play_yardage = {\n",
        "          standard_play_end_pattern: [2]\n",
        "      }\n",
        "      extract_penalty_data(df_plays, play, idx, start_string, dict_start, end_string, dict_end, play_yardage_string, dict_play_yardage)\n",
        "\n",
        "  if df_pass_plays.tail(1).index.tolist()[0] == idx:\n",
        "    return df_plays"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRGsJa-J8CPe"
      },
      "source": [
        "#### RUN PLAYS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "cT8LK3jaWneq"
      },
      "outputs": [],
      "source": [
        "# PURPOSE:\n",
        "# - Clean run play types\n",
        "# INPUT PARAMETERS:\n",
        "# df_plays    - dataframe - dataframe of plays\n",
        "# index_start -  integer  - the starting index of the associated input dataframe\n",
        "#                           to begin cleaning.\n",
        "# RETURN:\n",
        "# df_plays - dataframe - dataframe of plays that now has all useful run play\n",
        "#                        data accessable and clean.\n",
        "\n",
        "# NOTE:\n",
        "# - Need to comment on how this is also a method being used for\n",
        "#   1. fumble recoveries for yardage\n",
        "#   2. fumble recoveries for touchdown\n",
        "# - I also have not come across a case where a rushing play has been fumbled and someone\n",
        "#   recovered the ball and scored a touchdown yet.\n",
        "\n",
        "def clean_run_plays(df_plays, index_start = None):\n",
        "\n",
        "  if index_start != None:\n",
        "    df_plays_adjusted = df_plays.loc[index_start:]\n",
        "    df_run_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('Run')]\n",
        "  else:\n",
        "    df_run_plays = df_plays[df_plays['PlayOutcome'].str.contains('Run')]\n",
        "\n",
        "  # Iterating through every run play within 'df_run_plays'\n",
        "  for idx, play in df_run_plays['PlayDescription'].items():\n",
        "\n",
        "    ################\n",
        "    # Play details #\n",
        "    ################\n",
        "\n",
        "    # Play Type\n",
        "    df_plays.loc[idx, 'PlayType'] = 'Run'\n",
        "\n",
        "    # TimeOnTheClock\n",
        "    TimeOnTheClock = re.findall(time_on_clock_pattern, play)\n",
        "    if len(TimeOnTheClock) > 0:\n",
        "      df_plays.loc[idx, 'TimeOnTheClock'] = TimeOnTheClock[0]\n",
        "\n",
        "    # Formation\n",
        "    Formation = re.findall(formation, play)\n",
        "    if len(Formation) > 0:\n",
        "      if Formation[0] == 'Aborted':\n",
        "        pass\n",
        "      else:\n",
        "        df_plays.loc[idx, 'Formation'] = Formation[0]\n",
        "\n",
        "    ############\n",
        "    # REVERSES #\n",
        "    ############\n",
        "\n",
        "    # In 'PlayDescription' all information before the \"reversed\" sentence is not needed.\n",
        "    # - All information before is stored within 'ReverseDetails' and the remaining is cleaned.\n",
        "    if play.find('REVERSED') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      for i in play_elements:\n",
        "        if i.find(\"REVERSED\") != -1:\n",
        "          df_plays.at[idx, 'ReverseDetails'] = play_elements[:play_elements.index(i) + 1]\n",
        "          play = \". \".join(play_elements[play_elements.index(i) + 1:])\n",
        "          break\n",
        "\n",
        "    ############################\n",
        "    # REPORTING IN AS ELIGIBLE #\n",
        "    ############################\n",
        "\n",
        "    # I do not think this contains any useful data so I am going to exclude it.\n",
        "    if play.find('reported in as eligible') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      for i in play_elements:\n",
        "        if i.find('reported in as eligible') != -1:\n",
        "          play = \". \".join(play_elements[play_elements.index(i) + 1:])\n",
        "          break\n",
        "\n",
        "    ############\n",
        "    # LATERALS #\n",
        "    ############\n",
        "    # - I think it makes sense to check for laterals here because I need to use the start\n",
        "    #   of the entry with it having not features filled out as a template.\n",
        "    #   - I do not know how this will affect laterals that are fumbled\n",
        "    #   - I do not know how this will affect laterals that have penalties\n",
        "    if play.lower().find('lateral') != -1:\n",
        "      df_replacement_rows = extract_lateral_data(df_plays, idx, clean_run_plays)\n",
        "      df_before = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before, df_replacement_rows, df_after], ignore_index=True)\n",
        "      index_of_last_added_row = idx + len(df_replacement_rows) - 1\n",
        "\n",
        "      # returning row after the last index\n",
        "      if df_run_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_run_plays(df_plays, index_of_last_added_row + 1)\n",
        "\n",
        "    ###########\n",
        "    # FUMBLES #\n",
        "    ###########\n",
        "\n",
        "    if play.find('FUMBLES') != -1:\n",
        "\n",
        "      # - I think it would help to comment on each action added\n",
        "      # - Does this catch fumble recovery touchdowns? <--\n",
        "      main_action_patterns = [rusher_pattern,\n",
        "                              qb_aborted_fumble_pattern,\n",
        "                              qb_center_aborted_fumble_pattern,\n",
        "                              qb_fumble_pattern, defensive_takeaway_run_pattern,\n",
        "                              handoff_pattern]\n",
        "\n",
        "      map_who_fumbled_patterns = {\n",
        "          rusher_pattern : 0,\n",
        "          qb_aborted_fumble_pattern: 0,\n",
        "          qb_fumble_pattern: 0,\n",
        "          defensive_takeaway_run_pattern: 0,\n",
        "          handoff_pattern: 0\n",
        "      }\n",
        "\n",
        "      main_cleaning_method = clean_run_plays\n",
        "      df_replacement_rows = extract_fumble_data(df_plays, play, idx,\n",
        "                                                main_action_patterns,\n",
        "                                                map_who_fumbled_patterns,\n",
        "                                                main_cleaning_method)\n",
        "\n",
        "      # \"df_plays.index.tolist().index(idx)\" needed for method usage with slices of original dataframe.\n",
        "      df_before = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before, df_replacement_rows, df_after], ignore_index=True)\n",
        "      index_of_last_added_row = idx + len(df_replacement_rows) - 1\n",
        "\n",
        "      # returning row after the last index\n",
        "      if df_run_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_run_plays(df_plays, index_of_last_added_row + 1)\n",
        "\n",
        "    #############\n",
        "    #  OFFENSE  #\n",
        "    #############\n",
        "\n",
        "    # Rusher\n",
        "    rusher_patterns = [rusher_pattern, defensive_takeaway_run_pattern, qb_fumble_pattern, touchdown_after_takeaway_pattern, handoff_pattern]\n",
        "    # Loop through patterns and find the first match\n",
        "    for pattern in rusher_patterns:\n",
        "      rusher = re.findall(pattern, play)\n",
        "      if len(rusher) > 0:\n",
        "        if isinstance(rusher[0], tuple):\n",
        "          rusher_name = rusher[0][0]\n",
        "        else:\n",
        "          rusher_name = rusher[0]\n",
        "        df_plays.loc[idx, 'Rusher'] = rusher_name\n",
        "        break\n",
        "\n",
        "    # Direction\n",
        "    rushing_directions = ['guard', 'middle', 'tackle', 'end', 'kneels']\n",
        "    for i in rushing_directions:\n",
        "      if play.find(i) != -1:\n",
        "        start = play.find(rusher_name) + len(rusher_name) + 1\n",
        "        end = play.find(i) + len(i)\n",
        "        df_plays.loc[idx, 'Direction'] = play[start:end]\n",
        "        break\n",
        "\n",
        "    # Yardage gained\n",
        "    yardage = re.findall(yardage_gained, play)\n",
        "    if len(yardage) > 0:\n",
        "      df_plays.loc[idx, 'Yardage'] = int(yardage[0])\n",
        "    elif math.isnan(df_plays['Yardage'].loc[idx]):\n",
        "      df_plays.loc[idx, 'Yardage'] = 0\n",
        "\n",
        "    # Find yardage gained during handoff.\n",
        "    # - Yardage gained (as obvious as it sounds) is\n",
        "    #   yardage gained from the line of scrimmage.\n",
        "    if play.find('Handoff') != -1:\n",
        "      start = re.findall(play_start_pattern, df_run_plays['PlayStart'].loc[idx])[0]\n",
        "      end = re.findall(handoff_pattern, play)[0]\n",
        "      start_territory = start[0]\n",
        "      start_yardage = int(start[1])\n",
        "      end_territory = end[1]\n",
        "      end_yardage = int(end[2])\n",
        "      handoff_yardage_gained = int(end[3])\n",
        "\n",
        "      if start_territory == end_territory:\n",
        "        if start_yardage > end_yardage:\n",
        "          if handoff_yardage_gained > 0:\n",
        "            df_plays.loc[idx, 'Yardage'] = start_yardage - end_yardage\n",
        "          else:\n",
        "            df_plays.loc[idx, 'Yardage'] = end_yardage - start_yardage\n",
        "        else:\n",
        "          if handoff_yardage_gained > 0:\n",
        "            df_plays.loc[idx, 'Yardage'] = end_yardage - start_yardage\n",
        "          else:\n",
        "            df_plays.loc[idx, 'Yardage'] = start_yardage - end_yardage\n",
        "      else:\n",
        "        if handoff_yardage_gained > 0:\n",
        "          df_plays.loc[idx, 'Yardage'] = 100 - end_yardage - start_yardage\n",
        "        else:\n",
        "          df_plays.loc[idx, 'Yardage'] = end_yardage - (100 - start_yardage)\n",
        "\n",
        "    #############\n",
        "    #  DEFENSE  #\n",
        "    #############\n",
        "\n",
        "    solo_tackle = re.findall(solo_tackle_pattern, play)\n",
        "    if len(solo_tackle) > 0:\n",
        "      df_plays.loc[idx, 'SoloTackle'] = solo_tackle[0]\n",
        "\n",
        "    shared_tackle = re.findall(shared_tackle_pattern, play)\n",
        "    if len(shared_tackle) > 0:\n",
        "      df_plays.at[idx, 'SharedTackle'] = shared_tackle[0]\n",
        "\n",
        "    assisted_tackle = re.findall(assisted_tackle_pattern, play)\n",
        "    if len(assisted_tackle) > 0:\n",
        "      df_plays.at[idx, 'AssistedTackle'] = [assisted_tackle[0][0], assisted_tackle[0][1]]\n",
        "\n",
        "    ##############\n",
        "    #  INJURIES  #\n",
        "    ##############\n",
        "\n",
        "    injuries = re.findall(injury_pattern, play)\n",
        "    if len(injuries) > 0:\n",
        "      df_plays.at[idx, 'InjuredPlayers'] = injuries\n",
        "\n",
        "    #############\n",
        "    #  PENALTY  #\n",
        "    #############\n",
        "\n",
        "    if play.lower().find('penalty') != -1:\n",
        "      # start of play\n",
        "      start_string = df_plays['PlayStart'].loc[idx]\n",
        "      dict_start = {\n",
        "          play_start_pattern: [0, 1]\n",
        "      }\n",
        "      # end of play\n",
        "      end_string = play\n",
        "      dict_end = {\n",
        "          standard_play_end_pattern: [0, 1]\n",
        "      }\n",
        "      # play yardage\n",
        "      play_yardage_string = play\n",
        "      dict_play_yardage = {\n",
        "          standard_play_end_pattern: [2]\n",
        "      }\n",
        "      extract_penalty_data(df_plays, play, idx, start_string, dict_start, end_string, dict_end, play_yardage_string, dict_play_yardage)\n",
        "\n",
        "    # Return if the last play has been cleaned in 'df_run_plays'\n",
        "    if df_run_plays.tail(1).index.tolist()[0] == idx:\n",
        "      return df_plays"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHh3e-2kHDIM"
      },
      "source": [
        "####2PT CONVERSIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "PIjLfa5XHIq8"
      },
      "outputs": [],
      "source": [
        "# I NEED A LARGER SAMPLE SIZE FOR MORE PLAYS\n",
        "# - I need a sample size that has fumbled plays (if that's possible?)\n",
        "# - I need a sample size that has interception (if that's possible?)\n",
        "# - I need a sample size with injuries (as dark as that may sound)\n",
        "\n",
        "def cleaning_2pt_conversion_plays(df_plays, index_start = None):\n",
        "\n",
        "  # Cut 'df_plays' to begin from 'index_start' to the last penalty play available in dataframe\n",
        "  if index_start != None:\n",
        "    df_plays_adjusted = df_plays.loc[index_start]\n",
        "    df_2pt_conversion_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('2PT Conversion', case=False)]\n",
        "  else:\n",
        "    df_2pt_conversion_plays = df_plays[df_plays['PlayOutcome'].str.contains('2PT Conversion', case=False)]\n",
        "\n",
        "  # Iterating through every penalty play within 'df_2pt_conversion_plays'\n",
        "  for idx, play in df_2pt_conversion_plays['PlayDescription'].items():\n",
        "\n",
        "    ###################\n",
        "    # PASSING ATTEMPT #\n",
        "    ###################\n",
        "\n",
        "    pass_2ptc = re.findall(tp_conversion_pass_pattern, play)\n",
        "    if len(pass_2ptc) > 0:\n",
        "      df_plays.loc[idx, 'Passer'] = pass_2ptc[0][0]\n",
        "      df_plays.loc[idx, 'Receiver'] = pass_2ptc[0][1]\n",
        "      df_plays.loc[idx, 'PlayType'] = '2PT Conversion Pass'\n",
        "\n",
        "    ###################\n",
        "    # RUSHING ATTEMPT #\n",
        "    ###################\n",
        "\n",
        "    rush_2ptc = re.findall(tp_conversion_rush_pattern, play)\n",
        "    if len(rush_2ptc) > 0:\n",
        "      df_plays.loc[idx, 'Rusher'] = rush_2ptc[0]\n",
        "      df_plays.loc[idx, 'PlayType'] = '2PT Conversion Run'\n",
        "      # Direction\n",
        "      rushing_directions = ['guard', 'middle', 'tackle', 'end', 'kneels']\n",
        "      for i in rushing_directions:\n",
        "        if play.find(i) != -1:\n",
        "          start = play.find('rushes') + len('rushes') + 1\n",
        "          end = play.find(i) + len(i)\n",
        "          df_plays.loc[idx, 'Direction'] = play[start:end]\n",
        "          break\n",
        "\n",
        "    #############\n",
        "    #  PENALTY  #\n",
        "    #############\n",
        "\n",
        "    if play.lower().find('penalty') != -1:\n",
        "      # start of play\n",
        "      start_string = df_plays['PlayStart'].loc[idx]\n",
        "      dict_start = {\n",
        "          play_start_pattern: [0, 1]\n",
        "      }\n",
        "      # end of play\n",
        "      end_string = play\n",
        "      dict_end = {\n",
        "          standard_play_end_pattern: [0, 1]\n",
        "      }\n",
        "      # play yardage\n",
        "      play_yardage_string = play\n",
        "      dict_play_yardage = {\n",
        "          standard_play_end_pattern: [2]\n",
        "      }\n",
        "      extract_penalty_data(df_plays, play, idx, start_string, dict_start, end_string, dict_end, play_yardage_string, dict_play_yardage)\n",
        "\n",
        "  return df_plays"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TieP_Cy5rmj-"
      },
      "source": [
        "###DEFENSE CLEANING METHODS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZpJpikZCx--"
      },
      "source": [
        "#### INTERCEPTIONS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# interception that was fumbled\n",
        "\n",
        "df_play_under_review = week2_2023_plays_modified.loc[(week2_2023_plays_modified['PlayDescription'].str.contains('INTERCEPTED')) &\n",
        "                                                     (week2_2023_plays_modified['PlayDescription'].str.contains('R.Wilson'))]\n",
        "\n",
        "for idx, play in df_play_under_review['PlayDescription'].items():\n",
        "  print(idx)\n",
        "  play_split = play.split(\". \")\n",
        "  for i in play_split:\n",
        "    print(i)\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK7QM4bWW3ON",
        "outputId": "d7070c23-1d63-44ac-9afa-dd1a7a140e55"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1292\n",
            "(10:33) (No Huddle, Shotgun) R.Wilson pass short left intended for C.Sutton INTERCEPTED by E.Forbes at DEN 47\n",
            "E.Forbes to DEN 44 for 3 yards\n",
            "FUMBLES, ball out of bounds at DEN 44\n",
            "The Replay Official reviewed the interception ruling, and the play was Upheld\n",
            "The ruling on the field stands.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# All interceptions\n",
        "\n",
        "df_play_under_review = week2_2023_plays_modified.loc[(week2_2023_plays_modified['PlayDescription'].str.contains('INTERCEPTED'))]\n",
        "\n",
        "for idx, play in df_play_under_review['PlayDescription'].items():\n",
        "  print(idx)\n",
        "  play_split = play.split(\". \")\n",
        "  for i in play_split:\n",
        "    print(i)\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHu9H77bjAfh",
        "outputId": "9f1622e9-cc93-4124-de2a-c91990648ba1"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "141\n",
            "(10:48) (Shotgun) J.Burrow pass short middle intended for T.Higgins INTERCEPTED by G.Stone at BAL 2\n",
            "G.Stone ran ob at BAL 38 for 36 yards (J.Burrow).\n",
            "\n",
            "492\n",
            "(15:00) (Shotgun) D.Watson pass short left intended for H.Bryant INTERCEPTED by A.Highsmith (M.Fitzpatrick) at CLE 30\n",
            "A.Highsmith for 30 yards, TOUCHDOWN.\n",
            "\n",
            "639\n",
            "(10:51) (Shotgun) J.Dobbs pass short middle intended for Z.Ertz INTERCEPTED by J.Pinnock at NYG 21\n",
            "J.Pinnock pushed ob at NYG 47 for 26 yards (R.Moore)\n",
            "PENALTY on NYG-B.Okereke, Defensive Pass Interference, 10 yards, enforced at NYG 35 - No Play.\n",
            "\n",
            "655\n",
            "(12:39) (Shotgun) D.Ridder pass deep middle intended for J.Smith INTERCEPTED by R.Douglas [K.Clark] at GB 42\n",
            "R.Douglas to GB 40 for -2 yards (K.Pitts).\n",
            "\n",
            "922\n",
            "(3:58) T.Munford reported in as eligible\n",
            " J.Garoppolo pass short right intended for J.Jacobs INTERCEPTED by M.Milano at BUF 49\n",
            "M.Milano to LV 48 for 3 yards (J.Jacobs).\n",
            "\n",
            "1030\n",
            "(11:51) (Shotgun) Z.Wilson pass short right intended for G.Wilson INTERCEPTED by J.Kearse at NYJ 49\n",
            "J.Kearse to NYJ 17 for 32 yards (D.Brown)\n",
            "Penalty on NYJ-M.Becton, Offensive Holding, declined.\n",
            "\n",
            "1076\n",
            "(8:14) (Shotgun) J.Goff pass short left intended for J.Gibbs INTERCEPTED by T.Brown [U.Nwosu] at DET 40\n",
            "T.Brown for 40 yards, TOUCHDOWN.\n",
            "\n",
            "1209\n",
            "(9:27) (Shotgun) J.Allen pass short right intended for S.Diggs INTERCEPTED by R.Teamer (M.Crosby) [M.Koonce] at BUF 36\n",
            "R.Teamer pushed ob at BUF 20 for 16 yards (D.Kincaid)\n",
            "PENALTY on LV-N.Hobbs, Illegal Use of Hands, 5 yards, enforced at BUF 27 - No Play.\n",
            "\n",
            "1292\n",
            "(10:33) (No Huddle, Shotgun) R.Wilson pass short left intended for C.Sutton INTERCEPTED by E.Forbes at DEN 47\n",
            "E.Forbes to DEN 44 for 3 yards\n",
            "FUMBLES, ball out of bounds at DEN 44\n",
            "The Replay Official reviewed the interception ruling, and the play was Upheld\n",
            "The ruling on the field stands.\n",
            "\n",
            "1387\n",
            "(4:17) (No Huddle, Shotgun) M.Stafford pass short left intended for K.Williams INTERCEPTED by I.Oliver at SF 25\n",
            "I.Oliver to SF 28 for 3 yards (K.Williams).\n",
            "\n",
            "1420\n",
            "(8:22) J.Garoppolo pass short middle intended for A.Abdullah INTERCEPTED by T.Bernard (G.Rousseau) [D.Jones] at LV 28\n",
            "T.Bernard to LV 28 for no gain (A.Abdullah).\n",
            "\n",
            "1441\n",
            "(10:04) (Shotgun) T.Tagovailoa pass deep left intended for T.Hill INTERCEPTED by C.Gonzalez [M.Judon] at NE 14\n",
            "C.Gonzalez to NE 14 for no gain (T.Hill).\n",
            "\n",
            "1528\n",
            "(8:12) (Shotgun) K.Pickett pass short left intended for G.Pickens INTERCEPTED by G.Delpit at PIT 19\n",
            "G.Delpit to PIT 19 for no gain (C.Austin).\n",
            "\n",
            "1828\n",
            "(4:58) (Shotgun) M.Stafford pass short middle intended for V.Jefferson INTERCEPTED by D.Lenoir at LA 36\n",
            "D.Lenoir ran ob at LA 15 for 21 yards (C.Shelton).\n",
            "\n",
            "1883\n",
            "(:57) (No Huddle, Shotgun) M.Jones pass deep right intended for D.Parker INTERCEPTED by X.Howard at MIA 3\n",
            "X.Howard pushed ob at MIA 3 for no gain (D.Parker).\n",
            "\n",
            "1927\n",
            "(4:30) (No Huddle, Shotgun) D.Jones pass short right intended for S.Barkley INTERCEPTED by J.Thompson at ARI 31\n",
            "J.Thompson ran ob at NYG 34 for 35 yards (D.Jones).\n",
            "\n",
            "1950\n",
            "(6:10) (Shotgun) Z.Wilson pass deep left intended for G.Wilson INTERCEPTED by M.Hooker at DAL 8\n",
            "M.Hooker to DAL 8 for no gain (G.Wilson).\n",
            "\n",
            "1961\n",
            "(3:04) (Shotgun) J.Hurts pass deep middle intended for D.Smith INTERCEPTED by Th.Jackson at MIN 35\n",
            "Th.Jackson to MIN 35 for no gain (D.Smith).\n",
            "\n",
            "2176\n",
            "(9:51) (Shotgun) P.Mahomes pass deep middle intended for Ju.Watson INTERCEPTED by A.Cisco [J.Allen] at JAX 12\n",
            "A.Cisco to JAX 12 for no gain (Ju.Watson).\n",
            "\n",
            "2399\n",
            "(3:16) (Shotgun) D.Carr pass deep right intended for C.Olave INTERCEPTED by V.Bell at NO 48\n",
            "V.Bell to NO 37 for 11 yards (T.Jones).\n",
            "\n",
            "2421\n",
            "(3:07) (Shotgun) Z.Wilson pass short left intended for Mi.Carter INTERCEPTED by T.Diggs at DAL 45\n",
            "T.Diggs to NYJ 47 for 8 yards (Mi.Carter).\n",
            "\n",
            "2457\n",
            "(2:12) (Shotgun) J.Fields pass short middle intended for K.Herbert INTERCEPTED by S.Barrett at CHI 4\n",
            "S.Barrett for 4 yards, TOUCHDOWN.\n",
            "\n",
            "2490\n",
            "(1:17) (No Huddle, Shotgun) J.Fields pass short middle intended for C.Claypool INTERCEPTED by C.Izien (A.Winfield) at CHI 29\n",
            "C.Izien to CHI 25 for 4 yards (R.Johnson).\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "2GEMXbRHjt1W"
      },
      "outputs": [],
      "source": [
        "# # PURPOSE:\n",
        "# # - Clean intercepted plays\n",
        "# # INPUT PARAMETERS:\n",
        "# # df_plays    - dataframe - dataframe of plays\n",
        "# # index_start -  integer  - the starting index of the associated input dataframe\n",
        "# #                           to begin cleaning.\n",
        "# # RETURN:\n",
        "# # df_plays - dataframe - dataframe of plays that now has all useful intercepted play\n",
        "# #                        data accessible and clean.\n",
        "\n",
        "# # ROUGH DESGIN\n",
        "# # 1. Narrow dataframe using 'index_start'\n",
        "# #    - This is a recursive method, the narrowing will get smaller and\n",
        "# #      smaller until all 'intercepted' type plays have been cleaned.\n",
        "# # 2. Grab first 'intercepted' play from narrowed dataframe\n",
        "# # 3. Create 2 single row dataframes.\n",
        "# #    a. intended play\n",
        "# #    b. yardage after interception\n",
        "# # 4. Break down play into sentences and clean\n",
        "# #    - Depending on the sentence within the play, will determine which\n",
        "# #      single row dataframe it will go to.\n",
        "# # 5. Combine both dataframes of cleaned data into one dataframe\n",
        "# # 6. Replace old play row with new cleaned multi row\n",
        "# # 7. return clean_interceped_plays( x , y)\n",
        "# #    - x = updated df_plays\n",
        "# #    - y = index directly after the last clean added row\n",
        "\n",
        "# # Concerns:\n",
        "# # ~ 1 ~\n",
        "# # PLAY SNIP - \"(9:53) (Shotgun) D.Watson pass short left intended for E.Moore INTERCEPTED by D.Hill (Z.Carter) at CIN 30.\"\n",
        "# # - The concern here is (Z.Carter)\n",
        "# #   - I do not know what to categorize this player as? I believe that he had an impact on the play and could possibly be a reason\n",
        "# #     that D.Hill was able to intercept the ball.\n",
        "# #     - Should I create a feature called \"ImpactPlayer\" or something?\n",
        "# # ~ 2 ~\n",
        "# # PLAY SNIP - \"(4:16) (Shotgun) J.Allen pass deep middle intended for S.Diggs INTERCEPTED by J.Whitehead [Q.Williams] at NYJ -1. Touchback.\"\n",
        "# # - The concern here is 'touchback'\n",
        "# #   - I have no idea what to do with that\n",
        "# # ~ 3 ~\n",
        "# #`- I do not have anything set in play to handle fumbles? What happens if a QB fumbles, recovers, then throws an interception? -> Then player that intercepted fumbles?\n",
        "# # ~ 4 ~\n",
        "# # - There are 2 rows within this sinlge play. (Intended throwing play, yardage after interception)\n",
        "# #   - For both of these rows that represent a single play, they both state that the throwing team has possession\n",
        "# #     - I do not know how this is going to effect the future with analysis on data\n",
        "# # - -----> GRAB DATA FOR TOUCHBACKS <-----\n",
        "# # - -----> GRAB DATA FOR PLAYTYPE INTERCEPTION FOR YARDAGE <-----\n",
        "\n",
        "\n",
        "\n",
        "# # I need to fix this method to account for fumbles after interceptions.\n",
        "# # I need to fix this method to account for fumbles before interceptions.\n",
        "# # - Would it work if I split the playdescriptions into individual actions and use\n",
        "# #   the main cleaning method to clean them..?\n",
        "\n",
        "\n",
        "\n",
        "# def clean_intercepted_plays(df_plays, index_start = None):\n",
        "\n",
        "#   # Will cut df_plays starting from index_start (narrowing our search space)\n",
        "#   if index_start != None:\n",
        "#     df_plays_adjusted = df_plays.loc[index_start:]\n",
        "#     df_intercepted_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('Interception')]\n",
        "#   else:\n",
        "#     df_intercepted_plays = df_plays[df_plays['PlayOutcome'].str.contains('Interception')]\n",
        "\n",
        "#   # Exit case (If no more 'Interception' type plays are found)\n",
        "#   if df_intercepted_plays.empty:\n",
        "#     return df_plays\n",
        "\n",
        "#   # Retrieve the index and 'PlayDescription' of the first intercepted play in 'df_intercepted_plays'\n",
        "#   # - Process one play per iteration in the recursive method\n",
        "#   idx = df_intercepted_plays.index[0]\n",
        "#   play = df_plays['PlayDescription'].loc[idx]\n",
        "\n",
        "#   ############\n",
        "#   # REVERSES #\n",
        "#   ############\n",
        "\n",
        "#   # In 'PlayDescription' all information before the \"reversed\" sentence is not needed.\n",
        "#   # - All information before is stored within 'ReverseDetails' and the remaining is cleaned.\n",
        "#   if play.find('REVERSED') != -1:\n",
        "#     play_elements = play.split(\". \")\n",
        "#     for i in play_elements:\n",
        "#       if i.find(\"REVERSED\") != -1:\n",
        "#         df_plays.at[idx, 'ReverseDetails'] = play_elements[:play_elements.index(i) + 1]\n",
        "#         play = \". \".join(play_elements[play_elements.index(i) + 1:])\n",
        "#         break\n",
        "\n",
        "#   # Create 2 single row dataframes.\n",
        "#   # 1. intended play\n",
        "#   df_intended_play = df_plays.loc[idx].copy()\n",
        "#   df_intended_play = pd.DataFrame([df_intended_play], columns=df_plays.columns)\n",
        "#   df_intended_play.reset_index(drop=True, inplace=True)\n",
        "#   df_intended_play['PlayDescription'] = 'nan'\n",
        "#   # 2. yardage after interception\n",
        "#   df_yardage_after_interception = df_plays.loc[idx].copy()\n",
        "#   df_yardage_after_interception = pd.DataFrame([df_yardage_after_interception], columns=df_plays.columns)\n",
        "#   df_yardage_after_interception.reset_index(drop=True, inplace=True)\n",
        "#   df_yardage_after_interception['PlayDescription'] = 'nan'\n",
        "\n",
        "#   # break down play by sentences.\n",
        "#   play_elements = play.split(\". \")\n",
        "\n",
        "#   # Every sentence within 'PlayDescription' except yardage/touchdown after interception/penalties\n",
        "#   intended_play_data = []\n",
        "#   penalties = []\n",
        "\n",
        "#   # iterate through play_elements\n",
        "#   for i in play_elements:\n",
        "\n",
        "#     ##############################\n",
        "#     # YARDAGE AFTER INTERCEPTION #\n",
        "#     ##############################\n",
        "\n",
        "#     yardage_after_interception = re.findall(defensive_takeaway_run_pattern, i)\n",
        "#     if len(yardage_after_interception) > 0:\n",
        "#       # print(yardage_after_interception)\n",
        "#       df_yardage_after_interception['PlayDescription'] = i\n",
        "\n",
        "#       # Player running after interception\n",
        "#       df_yardage_after_interception['Rusher'] = yardage_after_interception[0][0]\n",
        "\n",
        "#       # Playtype?\n",
        "#       # - Should this be a new playtype? Something like \"RunAfterInterception\"?\n",
        "#       df_yardage_after_interception['PlayType'] = 'Run After Interception'\n",
        "\n",
        "#       # Yardage gained\n",
        "#       yardage = re.findall(yardage_gained, i)\n",
        "#       if len(yardage) > 0:\n",
        "#         df_yardage_after_interception['Yardage'] = int(yardage[0])\n",
        "#       else:\n",
        "#         df_yardage_after_interception['Yardage'] = 0\n",
        "\n",
        "#       # Who made tackle\n",
        "#       tackler = re.findall(solo_tackle_pattern, i)\n",
        "#       if len(tackler) > 0:\n",
        "#         df_yardage_after_interception['SoloTackle'] = tackler[0]\n",
        "\n",
        "#       continue\n",
        "\n",
        "#     ################################\n",
        "#     # TOUCHDOWN AFTER INTERCEPTION #\n",
        "#     ################################\n",
        "\n",
        "#     touchdown_after_interception_check = re.findall(touchdown_after_takeaway_pattern, i)\n",
        "#     if len(touchdown_after_interception_check) > 0:\n",
        "#       df_yardage_after_interception['PlayDescription'] = i\n",
        "\n",
        "#       # Player running after interception\n",
        "#       df_yardage_after_interception['Rusher'] = touchdown_after_interception_check[0]\n",
        "\n",
        "#       # Yardage gained\n",
        "#       yardage = re.findall(yardage_gained, i)\n",
        "#       if len(yardage) > 0:\n",
        "#         df_yardage_after_interception['Yardage'] = int(yardage[0])\n",
        "\n",
        "#       # # PlayOutcome\n",
        "#       df_yardage_after_interception['PlayType'] = 'Run After Interception'\n",
        "\n",
        "#       # IsScoringPlay\n",
        "#       df_yardage_after_interception['IsScoringPlay'] = 1\n",
        "\n",
        "#       continue\n",
        "\n",
        "#     if i.lower().find('penalty') != -1:\n",
        "#       penalties.append(i)\n",
        "#       continue\n",
        "\n",
        "#     intended_play_data.append(i)\n",
        "\n",
        "#   ################################\n",
        "#   # INTERCEPTION ROW ADJUSTMENTS #\n",
        "#   ################################\n",
        "\n",
        "#   # Flipping team with possession when the play transitions from one team with possession to the other.\n",
        "#   if dict_teams_2.get(df_yardage_after_interception['TeamWithPossession'].iloc[0]) == df_yardage_after_interception['HomeTeam'].iloc[0]:\n",
        "#     df_yardage_after_interception['TeamWithPossession'] = dict_teams.get(df_yardage_after_interception['AwayTeam'].iloc[0])\n",
        "#   else:\n",
        "#     df_yardage_after_interception['TeamWithPossession'] = dict_teams.get(df_yardage_after_interception['HomeTeam'].iloc[0])\n",
        "\n",
        "#   #################\n",
        "#   # INTENDED PLAY #\n",
        "#   #################\n",
        "\n",
        "#   intended_play_playdescription = \". \".join(intended_play_data)\n",
        "\n",
        "#   df_intended_play['PlayDescription'] = intended_play_playdescription\n",
        "\n",
        "#   df_intended_play['PlayOutcome'] = 'Pass'\n",
        "#   df_intended_play = clean_pass_plays(df_intended_play)\n",
        "#   df_intended_play['PlayOutcome'] =  df_plays['PlayOutcome'].loc[idx]\n",
        "\n",
        "#   # Intercepted by\n",
        "#   intercepted_by = re.findall(interception_name_pattern, intended_play_playdescription)\n",
        "#   if len(intercepted_by) > 0:\n",
        "#     df_intended_play['InterceptedBy'] = intercepted_by[0]\n",
        "#     # THIS IS NOT CLEAN.\n",
        "#     # - During intercepted plays, The intended play portion of the play description is cleaned\n",
        "#     #   by the regular pass cleaning method. A defensive player awarded with a pass defend\n",
        "#     #   during an intercepted play is formatted the exact same as a player awarded a solo\n",
        "#     #   tackle during a completed pass play. I will leverage that here and move the player\n",
        "#     #   to the correct feature ('SoloTackle' -> 'PassDefendedBy')\n",
        "#     if df_intended_play['SoloTackle'].iloc[0] != 'nan':\n",
        "#       df_intended_play.at[0, 'PassDefendedBy'] = (intercepted_by[0], df_intended_play['SoloTackle'].iloc[0])\n",
        "#       df_intended_play['SoloTackle'] = 'nan'\n",
        "#     else:\n",
        "#       df_intended_play['PassDefendedBy'] = intercepted_by[0]\n",
        "\n",
        "#   #############\n",
        "#   # PENALTIES #\n",
        "#   #############\n",
        "\n",
        "#   if len(penalties) > 0:\n",
        "#     # start of play\n",
        "#     start_string = play\n",
        "#     dict_start = {\n",
        "#         interception_play_end_pattern: [0, 1]\n",
        "#     }\n",
        "#     # end of play\n",
        "#     end_string = play\n",
        "#     dict_end = {\n",
        "#         defensive_takeaway_run_pattern: [1, 2]\n",
        "#     }\n",
        "#     # play yardage\n",
        "#     play_yardage_string = play\n",
        "#     dict_play_yardage = {\n",
        "#         defensive_takeaway_run_pattern: [3]\n",
        "#     }\n",
        "#     extract_penalty_data(df_yardage_after_interception, play, df_yardage_after_interception.index[0], start_string, dict_start, end_string, dict_end, play_yardage_string, dict_play_yardage)\n",
        "\n",
        "#   #############################\n",
        "#   # NEW REPLACEMENT DATAFRAME #\n",
        "#   #############################\n",
        "\n",
        "#   # combine both single row dataframes into one\n",
        "#   if df_yardage_after_interception['PlayDescription'].iloc[0] == 'nan':\n",
        "#     df_cleaned_replacement = df_intended_play\n",
        "#   else:\n",
        "#     df_cleaned_replacement = pd.concat([df_intended_play, df_yardage_after_interception], ignore_index=True)\n",
        "\n",
        "#   # Replace old row with new cleaned dataframe\n",
        "#   df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "#   df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "#   df_plays = pd.concat([df_before_row, df_cleaned_replacement, df_after_row], ignore_index=True)\n",
        "\n",
        "#   # If this is the last play in the dataset\n",
        "#   if df_intercepted_plays.tail(1).index.tolist()[0] == idx:\n",
        "#     return df_plays\n",
        "#   else:\n",
        "#     return clean_intercepted_plays(df_plays, idx+len(df_cleaned_replacement))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PURPOSE:\n",
        "# - Clean intercepted plays\n",
        "# INPUT PARAMETERS:\n",
        "# df_plays    - dataframe - dataframe of plays\n",
        "# index_start -  integer  - the starting index of the associated input dataframe\n",
        "#                           to begin cleaning.\n",
        "# RETURN:\n",
        "# df_plays - dataframe - dataframe of plays that now has all useful intercepted play\n",
        "#                        data accessible and clean.\n",
        "\n",
        "# ROUGH DESGIN\n",
        "# 1. Narrow dataframe using 'index_start'\n",
        "#    - This is a recursive method, the narrowing will get smaller and\n",
        "#      smaller until all 'intercepted' type plays have been cleaned.\n",
        "# 2. Grab first 'intercepted' play from narrowed dataframe\n",
        "# 3. Create 2 single row dataframes.\n",
        "#    a. intended play\n",
        "#    b. yardage after interception\n",
        "# 4. Break down play into sentences and clean\n",
        "#    - Depending on the sentence within the play, will determine which\n",
        "#      single row dataframe it will go to.\n",
        "# 5. Combine both dataframes of cleaned data into one dataframe\n",
        "# 6. Replace old play row with new cleaned multi row\n",
        "# 7. return clean_interceped_plays( x , y)\n",
        "#    - x = updated df_plays\n",
        "#    - y = index directly after the last clean added row\n",
        "\n",
        "# Concerns:\n",
        "# ~ 1 ~\n",
        "# PLAY SNIP - \"(9:53) (Shotgun) D.Watson pass short left intended for E.Moore INTERCEPTED by D.Hill (Z.Carter) at CIN 30.\"\n",
        "# - The concern here is (Z.Carter)\n",
        "#   - I do not know what to categorize this player as? I believe that he had an impact on the play and could possibly be a reason\n",
        "#     that D.Hill was able to intercept the ball.\n",
        "#     - Should I create a feature called \"ImpactPlayer\" or something?\n",
        "# ~ 2 ~\n",
        "# PLAY SNIP - \"(4:16) (Shotgun) J.Allen pass deep middle intended for S.Diggs INTERCEPTED by J.Whitehead [Q.Williams] at NYJ -1. Touchback.\"\n",
        "# - The concern here is 'touchback'\n",
        "#   - I have no idea what to do with that\n",
        "# ~ 3 ~\n",
        "#`- I do not have anything set in play to handle fumbles? What happens if a QB fumbles, recovers, then throws an interception? -> Then player that intercepted fumbles?\n",
        "# ~ 4 ~\n",
        "# - There are 2 rows within this sinlge play. (Intended throwing play, yardage after interception)\n",
        "#   - For both of these rows that represent a single play, they both state that the throwing team has possession\n",
        "#     - I do not know how this is going to effect the future with analysis on data\n",
        "# - -----> GRAB DATA FOR TOUCHBACKS <-----\n",
        "# - -----> GRAB DATA FOR PLAYTYPE INTERCEPTION FOR YARDAGE <-----\n",
        "\n",
        "\n",
        "\n",
        "# I need to fix this method to account for fumbles after interceptions.\n",
        "# I need to fix this method to account for fumbles before interceptions.\n",
        "# - Would it work if I split the playdescriptions into individual actions and use\n",
        "#   the main cleaning method to clean them..?\n",
        "#   - Because the first sentence of the play (I beleive) is always going to be the\n",
        "#     interception action sentece, I could just grab that sentence and clean it using\n",
        "#     the main cleaning method.\n",
        "#     - Then I could try and group the remaining sentences and clean them using the\n",
        "#       run cleaning method..?\n",
        "\n",
        "\n",
        "\n",
        "def clean_intercepted_plays(df_plays, index_start = None):\n",
        "\n",
        "  # Will cut df_plays starting from index_start (narrowing our search space)\n",
        "  if index_start != None:\n",
        "    df_plays_adjusted = df_plays.loc[index_start:]\n",
        "    df_intercepted_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('Interception')]\n",
        "  else:\n",
        "    df_intercepted_plays = df_plays[df_plays['PlayOutcome'].str.contains('Interception')]\n",
        "\n",
        "  # Exit case (If no more 'Interception' type plays are found)\n",
        "  if df_intercepted_plays.empty:\n",
        "    return df_plays\n",
        "\n",
        "  # Retrieve the index and 'PlayDescription' of the first intercepted play in 'df_intercepted_plays'\n",
        "  # - Process one play per iteration in the recursive method\n",
        "  idx = df_intercepted_plays.index[0]\n",
        "  play = df_plays['PlayDescription'].loc[idx]\n",
        "\n",
        "  ############\n",
        "  # REVERSES #\n",
        "  ############\n",
        "\n",
        "  # In 'PlayDescription' all information before the \"reversed\" sentence is not needed.\n",
        "  # - All information before is stored within 'ReverseDetails' and the remaining is cleaned.\n",
        "  if play.find('REVERSED') != -1:\n",
        "    play_elements = play.split(\". \")\n",
        "    for i in play_elements:\n",
        "      if i.find(\"REVERSED\") != -1:\n",
        "        df_plays.at[idx, 'ReverseDetails'] = play_elements[:play_elements.index(i) + 1]\n",
        "        play = \". \".join(play_elements[play_elements.index(i) + 1:])\n",
        "        break\n",
        "\n",
        "  # Create 2 single row dataframes.\n",
        "  # 1. intended play\n",
        "  df_intended_play = df_plays.loc[idx].copy()\n",
        "  df_intended_play = pd.DataFrame([df_intended_play], columns=df_plays.columns)\n",
        "  df_intended_play.reset_index(drop=True, inplace=True)\n",
        "  df_intended_play['PlayDescription'] = 'nan'\n",
        "  # 2. yardage after interception\n",
        "  df_yardage_after_interception = df_plays.loc[idx].copy()\n",
        "  df_yardage_after_interception = pd.DataFrame([df_yardage_after_interception], columns=df_plays.columns)\n",
        "  df_yardage_after_interception.reset_index(drop=True, inplace=True)\n",
        "  df_yardage_after_interception['PlayDescription'] = 'nan'\n",
        "\n",
        "  # break down play by sentences.\n",
        "  play_elements = play.split(\". \")\n",
        "\n",
        "  # Every sentence within 'PlayDescription' except yardage/touchdown after interception/penalties\n",
        "  # intended_play_data = []\n",
        "  penalties = []\n",
        "\n",
        "\n",
        "\n",
        "  # I think I wont have to loop through these anymore, I could use play_elements and split them from there.\n",
        "  # 1. intended play\n",
        "  #    - Grab the first element of the play (use regular expression to make sure the action is the interception)\n",
        "  # 2. actions after interception\n",
        "  #    - I could group the rest of the elements (or actions) within the play and run them through a cleaning method\n",
        "  #      like the run cleaning method\n",
        "  #      - I think this would take care of regular actions after interception as well as touchdowns?\n",
        "  #      - From there, I could take stock on what the features look like and adjust from there\n",
        "  #        1. Make sure the correct team is shown for 'TeamWithPossession'\n",
        "  #           - Could possibly change this before running it through the cleaning method\n",
        "  #        2. Change 'PlayType'\n",
        "\n",
        "  # Separating play into\n",
        "  # 1. intended passing play\n",
        "  # 2. remaining actions following interception\n",
        "  for i in play_elements:\n",
        "    if i.lower().find('intercepted') != -1:\n",
        "      intended_play_playdescription = \". \".join(play_elements[:play_elements.index(i)+1])\n",
        "      after_interception_playdescription = \". \".join(play_elements[play_elements.index(i)+1:])\n",
        "      print(intended_play_playdescription)\n",
        "      print(after_interception_playdescription)\n",
        "      break\n",
        "\n",
        "  #################\n",
        "  # INTENDED PLAY #\n",
        "  #################\n",
        "\n",
        "  df_intended_play['PlayDescription'] = intended_play_playdescription\n",
        "  df_intended_play['PlayOutcome'] = 'Pass'\n",
        "  df_intended_play = clean_pass_plays(df_intended_play)\n",
        "  df_intended_play['PlayOutcome'] =  df_plays['PlayOutcome'].loc[idx]\n",
        "\n",
        "  # Intercepted by\n",
        "  intercepted_by = re.findall(interception_name_pattern, intended_play_playdescription)\n",
        "  if len(intercepted_by) > 0:\n",
        "    df_intended_play['InterceptedBy'] = intercepted_by[0]\n",
        "    # THIS IS NOT CLEAN.\n",
        "    # - During intercepted plays, The intended play portion of the play description is cleaned\n",
        "    #   by the regular pass cleaning method. A defensive player awarded with a pass defend\n",
        "    #   during an intercepted play is formatted the exact same as a player awarded a solo\n",
        "    #   tackle during a completed pass play. I will leverage that here and move the player\n",
        "    #   to the correct feature ('SoloTackle' -> 'PassDefendedBy')\n",
        "    if df_intended_play['SoloTackle'].iloc[0] != 'nan':\n",
        "      df_intended_play.at[0, 'PassDefendedBy'] = (intercepted_by[0], df_intended_play['SoloTackle'].iloc[0])\n",
        "      df_intended_play['SoloTackle'] = 'nan'\n",
        "    else:\n",
        "      df_intended_play['PassDefendedBy'] = intercepted_by[0]\n",
        "\n",
        "  #############################################################\n",
        "  # YARDAGE AFTER INTERCEPTION / TOUCHDOWN AFTER INTERCEPTION #\n",
        "  #############################################################\n",
        "  # - I need this to be able to clean everything.\n",
        "  #   - I need it to be able to clean regular interceptions for yardage\n",
        "  #   - I need it to be able to clean regular interceptions for yardage and then fumbled\n",
        "  #   - I need it to be able to clean interceptions for touchdowns\n",
        "  #   - I need it to be able to clean a fumbled interception that is recoverd for a touchdown\n",
        "  for action in [touchdown_after_takeaway_pattern, defensive_takeaway_run_pattern]:\n",
        "    yardage_after_interception = re.findall(action, after_interception_playdescription)\n",
        "    if len(yardage_after_interception) > 0:\n",
        "      df_yardage_after_interception['PlayDescription'] = after_interception_playdescription\n",
        "      df_yardage_after_interception['PlayType'] = 'Run After Interception'\n",
        "\n",
        "      # Flipping team with possession when the play transitions from one team with possession to the other.\n",
        "      if dict_teams_2.get(df_yardage_after_interception['TeamWithPossession'].iloc[0]) == df_yardage_after_interception['HomeTeam'].iloc[0]:\n",
        "        df_yardage_after_interception['TeamWithPossession'] = dict_teams.get(df_yardage_after_interception['AwayTeam'].iloc[0])\n",
        "      else:\n",
        "        df_yardage_after_interception['TeamWithPossession'] = dict_teams.get(df_yardage_after_interception['HomeTeam'].iloc[0])\n",
        "\n",
        "      # Ideally I would like to send this off to another method.\n",
        "      if action == touchdown_after_takeaway_pattern:\n",
        "        df_yardage_after_interception['IsScoringPlay'] = 1\n",
        "      else:\n",
        "        df_yardage_after_interception['PlayOutcome'] = 'Run'\n",
        "        df_yardage_after_interception = clean_run_plays(df_yardage_after_interception)\n",
        "        df_yardage_after_interception['PlayOutcome'] =  df_plays['PlayOutcome'].loc[idx]\n",
        "      break\n",
        "\n",
        "  # # Flipping team with possession when the play transitions from one team with possession to the other.\n",
        "  # if dict_teams_2.get(df_yardage_after_interception['TeamWithPossession'].iloc[0]) == df_yardage_after_interception['HomeTeam'].iloc[0]:\n",
        "  #   df_yardage_after_interception['TeamWithPossession'] = dict_teams.get(df_yardage_after_interception['AwayTeam'].iloc[0])\n",
        "  # else:\n",
        "  #   df_yardage_after_interception['TeamWithPossession'] = dict_teams.get(df_yardage_after_interception['HomeTeam'].iloc[0])\n",
        "\n",
        "\n",
        "\n",
        "  # # iterate through play_elements\n",
        "  # # for i in play_elements:\n",
        "\n",
        "  #   ##############################\n",
        "  #   # YARDAGE AFTER INTERCEPTION #\n",
        "  #   ##############################\n",
        "\n",
        "  #   # yardage_after_interception = re.findall(defensive_takeaway_run_pattern, i)\n",
        "  #   # if len(yardage_after_interception) > 0:\n",
        "  #     # print(yardage_after_interception)\n",
        "  #     # df_yardage_after_interception['PlayDescription'] = i\n",
        "\n",
        "  #     # Player running after interception\n",
        "  #     df_yardage_after_interception['Rusher'] = yardage_after_interception[0][0]\n",
        "\n",
        "  #     # Playtype?\n",
        "  #     # - Should this be a new playtype? Something like \"RunAfterInterception\"?\n",
        "  #     # df_yardage_after_interception['PlayType'] = 'Run After Interception'\n",
        "\n",
        "  #     # Yardage gained\n",
        "  #     yardage = re.findall(yardage_gained, i)\n",
        "  #     if len(yardage) > 0:\n",
        "  #       df_yardage_after_interception['Yardage'] = int(yardage[0])\n",
        "  #     else:\n",
        "  #       df_yardage_after_interception['Yardage'] = 0\n",
        "\n",
        "  #     # Who made tackle\n",
        "  #     tackler = re.findall(solo_tackle_pattern, i)\n",
        "  #     if len(tackler) > 0:\n",
        "  #       df_yardage_after_interception['SoloTackle'] = tackler[0]\n",
        "\n",
        "  #     continue\n",
        "\n",
        "  #   ################################\n",
        "  #   # TOUCHDOWN AFTER INTERCEPTION #\n",
        "  #   ################################\n",
        "\n",
        "  #   touchdown_after_interception_check = re.findall(touchdown_after_takeaway_pattern, i)\n",
        "  #   if len(touchdown_after_interception_check) > 0:\n",
        "  #     # df_yardage_after_interception['PlayDescription'] = i\n",
        "\n",
        "  #     # Player running after interception\n",
        "  #     df_yardage_after_interception['Rusher'] = touchdown_after_interception_check[0]\n",
        "\n",
        "  #     # Yardage gained\n",
        "  #     yardage = re.findall(yardage_gained, i)\n",
        "  #     if len(yardage) > 0:\n",
        "  #       df_yardage_after_interception['Yardage'] = int(yardage[0])\n",
        "\n",
        "  #     # # PlayOutcome\n",
        "  #     # df_yardage_after_interception['PlayType'] = 'Run After Interception'\n",
        "\n",
        "  #     # IsScoringPlay\n",
        "  #     # df_yardage_after_interception['IsScoringPlay'] = 1\n",
        "\n",
        "  #     continue\n",
        "\n",
        "    # if i.lower().find('penalty') != -1:\n",
        "    #   penalties.append(i)\n",
        "    #   continue\n",
        "\n",
        "    # intended_play_data.append(i)\n",
        "\n",
        "  ################################\n",
        "  # INTERCEPTION ROW ADJUSTMENTS #\n",
        "  ################################\n",
        "\n",
        "  # # Flipping team with possession when the play transitions from one team with possession to the other.\n",
        "  # if dict_teams_2.get(df_yardage_after_interception['TeamWithPossession'].iloc[0]) == df_yardage_after_interception['HomeTeam'].iloc[0]:\n",
        "  #   df_yardage_after_interception['TeamWithPossession'] = dict_teams.get(df_yardage_after_interception['AwayTeam'].iloc[0])\n",
        "  # else:\n",
        "  #   df_yardage_after_interception['TeamWithPossession'] = dict_teams.get(df_yardage_after_interception['HomeTeam'].iloc[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # #################\n",
        "  # # INTENDED PLAY #\n",
        "  # #################\n",
        "\n",
        "  # intended_play_playdescription = \". \".join(intended_play_data)\n",
        "\n",
        "  # df_intended_play['PlayDescription'] = intended_play_playdescription\n",
        "\n",
        "  # df_intended_play['PlayOutcome'] = 'Pass'\n",
        "  # df_intended_play = clean_pass_plays(df_intended_play)\n",
        "  # df_intended_play['PlayOutcome'] =  df_plays['PlayOutcome'].loc[idx]\n",
        "\n",
        "  # # Intercepted by\n",
        "  # intercepted_by = re.findall(interception_name_pattern, intended_play_playdescription)\n",
        "  # if len(intercepted_by) > 0:\n",
        "  #   df_intended_play['InterceptedBy'] = intercepted_by[0]\n",
        "  #   # THIS IS NOT CLEAN.\n",
        "  #   # - During intercepted plays, The intended play portion of the play description is cleaned\n",
        "  #   #   by the regular pass cleaning method. A defensive player awarded with a pass defend\n",
        "  #   #   during an intercepted play is formatted the exact same as a player awarded a solo\n",
        "  #   #   tackle during a completed pass play. I will leverage that here and move the player\n",
        "  #   #   to the correct feature ('SoloTackle' -> 'PassDefendedBy')\n",
        "  #   if df_intended_play['SoloTackle'].iloc[0] != 'nan':\n",
        "  #     df_intended_play.at[0, 'PassDefendedBy'] = (intercepted_by[0], df_intended_play['SoloTackle'].iloc[0])\n",
        "  #     df_intended_play['SoloTackle'] = 'nan'\n",
        "  #   else:\n",
        "  #     df_intended_play['PassDefendedBy'] = intercepted_by[0]\n",
        "\n",
        "\n",
        "  # I think penalties might be taken care of if I send the rest of the grouping to the run cleaning method..?\n",
        "\n",
        "  # #############\n",
        "  # # PENALTIES #\n",
        "  # #############\n",
        "\n",
        "  # if len(penalties) > 0:\n",
        "  #   # start of play\n",
        "  #   start_string = play\n",
        "  #   dict_start = {\n",
        "  #       interception_play_end_pattern: [0, 1]\n",
        "  #   }\n",
        "  #   # end of play\n",
        "  #   end_string = play\n",
        "  #   dict_end = {\n",
        "  #       defensive_takeaway_run_pattern: [1, 2]\n",
        "  #   }\n",
        "  #   # play yardage\n",
        "  #   play_yardage_string = play\n",
        "  #   dict_play_yardage = {\n",
        "  #       defensive_takeaway_run_pattern: [3]\n",
        "  #   }\n",
        "  #   extract_penalty_data(df_yardage_after_interception, play, df_yardage_after_interception.index[0], start_string, dict_start, end_string, dict_end, play_yardage_string, dict_play_yardage)\n",
        "\n",
        "  #############################\n",
        "  # NEW REPLACEMENT DATAFRAME #\n",
        "  #############################\n",
        "\n",
        "  # combine both single row dataframes into one\n",
        "  if df_yardage_after_interception['PlayDescription'].iloc[0] == 'nan':\n",
        "    df_cleaned_replacement = df_intended_play\n",
        "  else:\n",
        "    df_cleaned_replacement = pd.concat([df_intended_play, df_yardage_after_interception], ignore_index=True)\n",
        "\n",
        "  # Replace old row with new cleaned dataframe\n",
        "  df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "  df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "  df_plays = pd.concat([df_before_row, df_cleaned_replacement, df_after_row], ignore_index=True)\n",
        "\n",
        "  # If this is the last play in the dataset\n",
        "  if df_intercepted_plays.tail(1).index.tolist()[0] == idx:\n",
        "    return df_plays\n",
        "  else:\n",
        "    return clean_intercepted_plays(df_plays, idx+len(df_cleaned_replacement))"
      ],
      "metadata": {
        "id": "O6sF3tCdaT52"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp-Bszm-B9rh"
      },
      "source": [
        "#### SACKS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "s8F6nfFsCG6B"
      },
      "outputs": [],
      "source": [
        "def clean_sacked_plays(df_plays, index_start = None):\n",
        "\n",
        "  # Will cut df_plays starting from index_start (narrowing our search space)\n",
        "  if index_start != None:\n",
        "    df_plays_adjusted = df_plays.iloc[index_start:]\n",
        "    df_sacked_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('Sack')]\n",
        "  else:\n",
        "    df_sacked_plays = df_plays[df_plays['PlayOutcome'].str.contains('Sack')]\n",
        "\n",
        "  for idx, play in df_sacked_plays['PlayDescription'].items():\n",
        "\n",
        "    ################\n",
        "    # Play details #\n",
        "    ################\n",
        "\n",
        "    # TimeOnTheClock\n",
        "    TimeOnTheClock = re.findall(time_on_clock_pattern, play)\n",
        "    if len(TimeOnTheClock) > 0:\n",
        "      df_plays.loc[idx, 'TimeOnTheClock'] = TimeOnTheClock[0]\n",
        "\n",
        "    ###########\n",
        "    # FUMBLES #\n",
        "    ###########\n",
        "\n",
        "    if play.find('FUMBLES') != -1:\n",
        "\n",
        "      main_action_patterns = [passer_name_pattern,\n",
        "                              defensive_takeaway_run_pattern,\n",
        "                              touchdown_after_takeaway_pattern]\n",
        "\n",
        "      map_who_fumbled_patterns = {\n",
        "          passer_name_pattern : 0,\n",
        "      }\n",
        "\n",
        "      main_cleaning_method = clean_sacked_plays\n",
        "      df_replacement_rows = extract_fumble_data(df_plays, play, idx,\n",
        "                                                main_action_patterns,\n",
        "                                                map_who_fumbled_patterns,\n",
        "                                                main_cleaning_method)\n",
        "\n",
        "      # \"df_plays.index.tolist().index(idx)\" needed for method usage with slices of original dataframe.\n",
        "      df_before = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before, df_replacement_rows, df_after], ignore_index=True)\n",
        "      index_of_last_added_row = idx + len(df_replacement_rows) - 1\n",
        "      # returning row after the last index\n",
        "      if df_sacked_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_sacked_plays(df_plays, index_of_last_added_row + 1)\n",
        "\n",
        "    #############\n",
        "    #  OFFENSE  #\n",
        "    #############\n",
        "\n",
        "    # Formation\n",
        "    Formation = re.findall(formation, play)\n",
        "    if len(Formation) > 0:\n",
        "      if Formation[0] == 'Aborted':\n",
        "        pass\n",
        "      else:\n",
        "        df_plays.loc[idx, 'Formation'] = Formation[0]\n",
        "\n",
        "    # Sacked Passer\n",
        "    sacked_passer_name = re.findall(passer_name_pattern, play)\n",
        "    if len(sacked_passer_name) > 0:\n",
        "      df_plays.loc[idx, 'Passer'] = sacked_passer_name[0]\n",
        "\n",
        "    # Yardage lost\n",
        "    yardage = re.findall(yardage_from_sack, play)\n",
        "    if len(yardage) > 0:\n",
        "      df_plays.loc[idx, 'Yardage'] = int(yardage[0])\n",
        "\n",
        "    #############\n",
        "    #  DEFENSE  #\n",
        "    #############\n",
        "\n",
        "    # Solo sack (One person sacked the passer)\n",
        "    solo_sack = re.findall(solo_tackle_pattern, play)\n",
        "    if len(solo_sack) > 0:\n",
        "      df_plays.loc[idx, 'SackedBy'] = solo_sack[0]\n",
        "      df_plays.loc[idx, 'SoloTackle'] = solo_sack[0]\n",
        "\n",
        "    # Split sack (A sack was given to the passer by multiple defenders)\n",
        "    split_sack = re.findall(split_sack_pattern, play)\n",
        "    if len(split_sack) > 0:\n",
        "      df_plays.at[idx, 'SackedBy'] = split_sack[0]\n",
        "      df_plays.at[idx, 'AssistedTackle'] = split_sack[0]\n",
        "\n",
        "    ##############\n",
        "    #  INJURIES  #\n",
        "    ##############\n",
        "\n",
        "    injuries = re.findall(injury_pattern, play)\n",
        "    if len(injuries) > 0:\n",
        "      df_plays.at[idx, 'InjuredPlayers'] = injuries\n",
        "\n",
        "    #############\n",
        "    #  PENALTY  #\n",
        "    #############\n",
        "\n",
        "    if play.lower().find('penalty') != -1:\n",
        "      # start of play\n",
        "      start_string = df_plays['PlayStart'].loc[idx]\n",
        "      dict_start = {\n",
        "          play_start_pattern: [0, 1]\n",
        "      }\n",
        "      # end of play\n",
        "      end_string = play\n",
        "      dict_end = {\n",
        "          standard_play_end_pattern: [0, 1]\n",
        "      }\n",
        "      # play yardage\n",
        "      play_yardage_string = play\n",
        "      dict_play_yardage = {\n",
        "          standard_play_end_pattern: [2]\n",
        "      }\n",
        "      extract_penalty_data(df_plays, play, idx, start_string, dict_start, end_string, dict_end, play_yardage_string, dict_play_yardage)\n",
        "\n",
        "    if df_sacked_plays.tail(1).index.tolist()[0] == idx:\n",
        "      return df_plays"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIX_e2jUrwdt"
      },
      "source": [
        "### SPECIAL TEAMS CLEANING METHODS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rt2DLo02qSa5"
      },
      "source": [
        "#### PUNTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "IL0XDsAyqWtO"
      },
      "outputs": [],
      "source": [
        "# A punt playtype will be split into 2 or more rows\n",
        "#   1. The Punt\n",
        "#      - 'PlayType'\n",
        "#         - Punt\n",
        "#      - 'Punter'\n",
        "#      - 'LongSnapper'\n",
        "#   2. The Punt Return\n",
        "#      - 'PlayType'\n",
        "#         - Punt Return\n",
        "#      - 'PlayOutcome'\n",
        "#         - x yard punt return\n",
        "#         - fair catch\n",
        "#         - touchback\n",
        "#         - out of bounds\n",
        "#         - downed\n",
        "#      - 'Returner'\n",
        "#      - 'Receiver'\n",
        "#      - 'Yardage'\n",
        "#      - 'TackleBy1'\n",
        "#      - 'TackleBy2'\n",
        "#      - 'DownedBy'\n",
        "\n",
        "# I need to figure out a fake punt\n",
        "# I need to figure out a punt that has been blocked\n",
        "# I need to figure out what to do when a fumble happens\n",
        "# I need to figure out what to do when a touchdown happens\n",
        "# Maybe in the future, to make this more space friendly, I can combine features\n",
        "# - Such as 'Punter' & 'LongSnapper' OR 'TackleBy1' & 'DownedBy'\n",
        "#   OR 'Returner' & 'Receiver'\n",
        "\n",
        "def clean_punt_plays(df_plays, index_start = None):\n",
        "\n",
        "  # Will cut df_plays starting from index_start (narrowing our search space)\n",
        "  if index_start != None:\n",
        "    df_plays_adjusted = df_plays.loc[index_start:]\n",
        "    df_punt_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('Punt')]\n",
        "  else:\n",
        "    df_punt_plays = df_plays[df_plays['PlayOutcome'].str.contains('Punt')]\n",
        "\n",
        "  if df_punt_plays.empty:\n",
        "    return df_plays\n",
        "\n",
        "  # Retrieve the index and 'PlayDescription' of the first punt play in 'df_punt_plays'\n",
        "  # - Process one play per iteration in the recursive method\n",
        "  idx = df_punt_plays.index[0]\n",
        "  play = df_plays['PlayDescription'].loc[idx]\n",
        "  row_copy = df_plays.loc[idx].copy()\n",
        "\n",
        "  ############\n",
        "  # REVERSES #\n",
        "  ############\n",
        "\n",
        "  # In 'PlayDescription' all information before the \"reversed\" sentence is not needed.\n",
        "  # - All information before is stored within 'ReverseDetails' and the remaining is cleaned.\n",
        "  if play.find('REVERSED') != -1:\n",
        "    play_elements = play.split(\". \")\n",
        "    for i in play_elements:\n",
        "      if i.find(\"REVERSED\") != -1:\n",
        "        df_plays.at[idx, 'ReverseDetails'] = play_elements[:play_elements.index(i) + 1]\n",
        "        play = \". \".join(play_elements[play_elements.index(i) + 1:])\n",
        "        break\n",
        "\n",
        "  ###########\n",
        "  # FUMBLES #\n",
        "  ###########\n",
        "\n",
        "  if play.find('FUMBLES') != -1:\n",
        "    main_action_patterns = [punting_pattern, punt_return_pattern, defensive_takeaway_run_pattern, handoff_pattern]\n",
        "\n",
        "    map_who_fumbled_patterns = {\n",
        "        punt_return_pattern: 0,\n",
        "        defensive_takeaway_run_pattern: 0,\n",
        "        handoff_pattern: 0\n",
        "    }\n",
        "\n",
        "    main_cleaning_method = clean_punt_plays\n",
        "    df_replacement_rows = extract_fumble_data(df_plays, play, idx,\n",
        "                                              main_action_patterns,\n",
        "                                              map_who_fumbled_patterns,\n",
        "                                              main_cleaning_method)\n",
        "\n",
        "    df_before = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "    df_after = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "    df_plays = pd.concat([df_before, df_replacement_rows, df_after], ignore_index=True)\n",
        "    index_of_last_added_row = idx + len(df_replacement_rows) - 1\n",
        "\n",
        "    if df_punt_plays.tail(1).index.tolist()[0] == idx:\n",
        "      return df_plays\n",
        "    else:\n",
        "      return clean_punt_plays(df_plays, index_of_last_added_row + 1)\n",
        "\n",
        "  # Create 2 single row dataframes.\n",
        "  # 1. The Punt\n",
        "  df_punt = row_copy\n",
        "  df_punt = pd.DataFrame([df_punt], columns=df_plays.columns)\n",
        "  df_punt.reset_index(drop=True, inplace=True)\n",
        "  df_punt['PlayDescription'] = 'nan'\n",
        "  # 2. The Punt Return\n",
        "  df_punt_return = row_copy\n",
        "  df_punt_return = pd.DataFrame([df_punt_return], columns=df_plays.columns)\n",
        "  df_punt_return.reset_index(drop=True, inplace=True)\n",
        "  df_punt_return['PlayDescription'] = 'nan'\n",
        "\n",
        "  #############\n",
        "  # PLAY TIME #\n",
        "  #############\n",
        "\n",
        "  time = re.findall(time_on_clock_pattern, play)\n",
        "  if len(time) > 0:\n",
        "    df_punt.loc[0, 'TimeOnTheClock'] = time[0]\n",
        "\n",
        "  # break down play by sentences.\n",
        "  play_elements = play.split(\". \")\n",
        "\n",
        "  accepted_penalties = []\n",
        "  declined_penalties = []\n",
        "\n",
        "  for i in play_elements:\n",
        "\n",
        "    ########\n",
        "    # PUNT #\n",
        "    ########\n",
        "\n",
        "    # All data needed for first row in replacement dataframe\n",
        "    punt = re.findall(punting_pattern, i)\n",
        "    if len(punt) > 0:\n",
        "      df_punt['PlayType'] = 'Punt'\n",
        "      df_punt['PlayDescription'] = i\n",
        "      df_punt['Kicker'] = punt[0][0]\n",
        "      df_punt['Yardage'] = int(punt[0][1])\n",
        "      df_punt['LongSnapper'] = punt[0][4]\n",
        "      # Touchback\n",
        "      if i.find('Touchback') != -1:\n",
        "        df_punt['PlayOutcome'] = 'Touchback'\n",
        "        continue\n",
        "      # Out of bounds\n",
        "      if i.find('out of bounds') != -1:\n",
        "        df_punt['PlayOutcome'] = 'out of bounds'\n",
        "        continue\n",
        "      # Downed by\n",
        "      if i.find('downed by') != -1:\n",
        "        df_punt['PlayOutcome'] = 'downed'\n",
        "        downed_by = re.findall(kick_downed_by_pattern, i)\n",
        "        df_punt['DownedBy'] = downed_by[0][downed_by[0].find(\"-\")+1:] # Need to get abreviation of team name away from player name (e.g. IND-G.Stuard)\n",
        "        continue\n",
        "      # fair catch\n",
        "      if i.find('fair catch') != -1:\n",
        "        df_punt['PlayOutcome'] = 'fair catch'\n",
        "        fair_catch_by = re.findall(punt_fair_catch_pattern, i)\n",
        "        df_punt['Returner'] = fair_catch_by[0]\n",
        "        continue\n",
        "      continue\n",
        "\n",
        "    ######################################\n",
        "    # PUNT RETURN (Including touchdowns) #\n",
        "    ######################################\n",
        "\n",
        "    # All data needed for the second row within replacement dataframe\n",
        "    # - Second row only needed when there is a punt return for yardage\n",
        "    # - I think I am going to run into trouble if there is a fumble recovery for yardage\n",
        "    punt_return_patterns = [punt_return_pattern, touchdown_after_takeaway_pattern]\n",
        "    for return_pattern in punt_return_patterns:\n",
        "      punt_return = re.findall(return_pattern, i)\n",
        "      if len(punt_return) > 0:\n",
        "        df_punt_return['PlayDescription'] = i\n",
        "        df_punt_return['PlayOutcome'] = 'Run'\n",
        "        # Change team with possession on punt returns to the team that is returning the ball\n",
        "        if df_punt['TeamWithPossession'].iloc[0] == dict_teams.get(df_punt['AwayTeam'].iloc[0]):\n",
        "          df_punt_return.loc[0, 'TeamWithPossession'] = dict_teams.get(df_punt['HomeTeam'].iloc[0])\n",
        "        else:\n",
        "          df_punt_return.loc[0, 'TeamWithPossession'] = dict_teams.get(df_punt['AwayTeam'].iloc[0])\n",
        "        df_punt_return = clean_run_plays(df_punt_return)\n",
        "        df_punt_return['PlayOutcome'] = row_copy['PlayOutcome']\n",
        "        df_punt_return['PlayType'] = 'Punt Return'\n",
        "        df_punt_return['Rusher'] = 'nan'\n",
        "        if return_pattern == punt_return_pattern:\n",
        "          df_punt_return['Returner'] = punt_return[0][0]\n",
        "        else:\n",
        "          df_punt_return['Returner'] = punt_return[0]\n",
        "        break\n",
        "\n",
        "    #############\n",
        "    #  PENALTY  #\n",
        "    #############\n",
        "\n",
        "    if i.find('PENALTY') != -1:\n",
        "      accepted_penalties.append(i)\n",
        "    if i.find('Penalty') != -1:\n",
        "      declined_penalties.append(i)\n",
        "\n",
        "  # To keep consistency with plays being split into multiple rows,\n",
        "  # I think I should have the penalties placed with the first row (punt) and\n",
        "  # not the following (punt return)\n",
        "  # - I don't know what to do right now.\n",
        "  #   1. Punts\n",
        "  #      - A punter loses yardage on their kick when:\n",
        "  #        1. there is a punt return\n",
        "  #        2. I think a penalty as well..? (I need more data to see)\n",
        "  #   2. Punt returns\n",
        "  #      - A punt return loses yardage if there is a penalty on the return team\n",
        "  # - I think for now I am only going to focus on punt returns.\n",
        "  #   When the time comes, I will make adjustments for yardage on punts.\n",
        "  if play.lower().find('penalty') != -1:\n",
        "    if df_punt_return['Returner'].iloc[0] == 'nan':\n",
        "      df_punt.at[0, 'AcceptedPenalty'] = accepted_penalties\n",
        "      df_punt.at[0, 'DeclinedPenalty'] = declined_penalties\n",
        "    else:\n",
        "      # start of play\n",
        "      start_string = play\n",
        "      dict_start = {\n",
        "          punting_pattern: [2, 3]\n",
        "      }\n",
        "      # end of play\n",
        "      end_string = play\n",
        "      dict_end = {\n",
        "          defensive_takeaway_run_pattern: [1, 2]\n",
        "      }\n",
        "      # play yardage\n",
        "      play_yardage_string = play\n",
        "      dict_play_yardage = {\n",
        "          defensive_takeaway_run_pattern: [3]\n",
        "      }\n",
        "      extract_penalty_data(df_punt_return, play, df_punt_return.index[0], start_string, dict_start, end_string, dict_end, play_yardage_string, dict_play_yardage)\n",
        "\n",
        "  #############################\n",
        "  # NEW REPLACEMENT DATAFRAME #\n",
        "  #############################\n",
        "\n",
        "  if df_punt_return['PlayDescription'].iloc[0] == 'nan':\n",
        "    df_replacement_rows = df_punt\n",
        "  elif df_punt['PlayDescription'].iloc[0] == 'nan': # Will happen during fumbled punt returns.\n",
        "    df_replacement_rows = df_punt_return\n",
        "  else:\n",
        "    df_replacement_rows = pd.concat([df_punt, df_punt_return], ignore_index=True)\n",
        "\n",
        "  df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "  df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "  df_plays = pd.concat([df_before_row, df_replacement_rows, df_after_row], ignore_index=True)\n",
        "\n",
        "  if df_punt_plays.tail(1).index.tolist()[0] == idx:\n",
        "    return df_plays\n",
        "  else:\n",
        "    return clean_punt_plays(df_plays, idx+len(df_replacement_rows))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzGnlGvPZiZE"
      },
      "source": [
        "#### KICKOFFS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "2EPzUDaYZl35"
      },
      "outputs": [],
      "source": [
        "# A kickoff playtype will be split into 1 or more rows\n",
        "\n",
        "# I need to figure out an onside kick (recovered by kicking team)\n",
        "# I need to figure out fumbled kickoff returns\n",
        "# I need to figure out returns for a touchdown\n",
        "# injuries?\n",
        "\n",
        "# Method can mirror punts method.\n",
        "\n",
        "def clean_kickoff_plays(df_plays, index_start = None):\n",
        "\n",
        "  # Will cut df_plays starting from index_start (narrowing our search space)\n",
        "  if index_start != None:\n",
        "    df_plays_adjusted = df_plays.loc[index_start:]\n",
        "    df_kickoff_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('kickoff', case=False)]\n",
        "  else:\n",
        "    df_kickoff_plays = df_plays[df_plays['PlayOutcome'].str.contains('kickoff', case=False)]\n",
        "\n",
        "  # exit case\n",
        "  if df_kickoff_plays.empty:\n",
        "    return df_plays\n",
        "\n",
        "  # Retrieve the index and 'PlayDescription' of the first kickoff play in 'df_kickoff_plays'\n",
        "  # - Process one play per iteration in the recursive method\n",
        "  idx = df_kickoff_plays.index[0]\n",
        "  play = df_plays['PlayDescription'].loc[idx]\n",
        "\n",
        "  ############\n",
        "  # REVERSES #\n",
        "  ############\n",
        "\n",
        "  # In 'PlayDescription' all information before the \"reversed\" sentence is not needed.\n",
        "  # - All information before is stored within 'ReverseDetails' and the remaining is cleaned.\n",
        "  if play.find('REVERSED') != -1:\n",
        "    play_elements = play.split(\". \")\n",
        "    for i in play_elements:\n",
        "      if i.find(\"REVERSED\") != -1:\n",
        "        df_plays.at[idx, 'ReverseDetails'] = play_elements[:play_elements.index(i) + 1]\n",
        "        play = \". \".join(play_elements[play_elements.index(i) + 1:])\n",
        "        break\n",
        "\n",
        "  ###########\n",
        "  # FUMBLES #\n",
        "  ###########\n",
        "\n",
        "  if play.find('FUMBLES') != -1:\n",
        "    main_action_patterns = [kickoff_pattern, kick_return_pattern, defensive_takeaway_run_pattern, handoff_pattern]\n",
        "\n",
        "    map_who_fumbled_patterns = {\n",
        "        kick_return_pattern: 0,\n",
        "        defensive_takeaway_run_pattern: 0,\n",
        "        handoff_pattern: 0\n",
        "    }\n",
        "\n",
        "    main_cleaning_method = clean_kickoff_plays\n",
        "    df_replacement_rows = extract_fumble_data(df_plays, play, idx,\n",
        "                                              main_action_patterns,\n",
        "                                              map_who_fumbled_patterns,\n",
        "                                              main_cleaning_method)\n",
        "\n",
        "    df_before = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "    df_after = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "    df_plays = pd.concat([df_before, df_replacement_rows, df_after], ignore_index=True)\n",
        "    index_of_last_added_row = idx + len(df_replacement_rows) - 1\n",
        "\n",
        "    # returning row after the last index\n",
        "    if df_kickoff_plays.tail(1).index.tolist()[0] == idx:\n",
        "      return df_plays\n",
        "    else:\n",
        "      return clean_kickoff_plays(df_plays, index_of_last_added_row + 1)\n",
        "\n",
        "  # Create 2 single row dataframes.\n",
        "  # 1. The Kickoff\n",
        "  df_kickoff = df_plays.loc[idx].copy()\n",
        "  df_kickoff = pd.DataFrame([df_kickoff], columns=df_plays.columns)\n",
        "  df_kickoff.reset_index(drop=True, inplace=True)\n",
        "  df_kickoff['PlayDescription'] = 'nan'\n",
        "  # 2. The Kickoff Return\n",
        "  df_kickoff_return = df_plays.loc[idx].copy()\n",
        "  df_kickoff_return = pd.DataFrame([df_kickoff_return], columns=df_plays.columns)\n",
        "  df_kickoff_return.reset_index(drop=True, inplace=True)\n",
        "  df_kickoff_return['PlayDescription'] = 'nan'\n",
        "\n",
        "  # break down play by sentences.\n",
        "  play_elements = play.split(\". \")\n",
        "\n",
        "  accepted_penalties = []\n",
        "  declined_penalties = []\n",
        "\n",
        "  for i in play_elements:\n",
        "\n",
        "    ###########\n",
        "    # KICKOFF #\n",
        "    ###########\n",
        "\n",
        "    kickoff = re.findall(kickoff_pattern, i)\n",
        "    if len(kickoff) > 0:\n",
        "      df_kickoff['PlayType'] = 'Kickoff'\n",
        "      df_kickoff['PlayDescription'] = i\n",
        "\n",
        "      # Change team with possession on kickoff to the team that is kicking\n",
        "      if df_kickoff['TeamWithPossession'].iloc[0] == dict_teams.get(df_kickoff['AwayTeam'].iloc[0]):\n",
        "        df_kickoff.loc[0, 'TeamWithPossession'] = dict_teams.get(df_kickoff['HomeTeam'].iloc[0])\n",
        "      else:\n",
        "        df_kickoff.loc[0, 'TeamWithPossession'] = dict_teams.get(df_kickoff['AwayTeam'].iloc[0])\n",
        "\n",
        "      df_kickoff['Kicker'] = kickoff[0][0]\n",
        "      df_kickoff['Yardage'] = int(kickoff[0][1])\n",
        "      if i.find('Touchback') != -1:\n",
        "        df_kickoff['PlayOutcome'] = 'Touchback'\n",
        "        continue\n",
        "      # I need to figure out what the difference will be when the kicking team recovers\n",
        "      if i.find('onside') != -1:\n",
        "        df_kickoff['PlayOutcome'] = 'onside'\n",
        "        downed_by = re.findall(kick_downed_by_pattern, i)\n",
        "        if len(downed_by) > 0:\n",
        "          df_kickoff['DownedBy'] = downed_by[0][downed_by[0].find(\"-\")+1:]\n",
        "        continue\n",
        "      continue\n",
        "\n",
        "    #########################################\n",
        "    # KICKOFF RETURN (Including touchdowns) #\n",
        "    #########################################\n",
        "\n",
        "    kick_return_patterns = [kick_return_pattern, touchdown_after_takeaway_pattern]\n",
        "    for return_pattern in kick_return_patterns:\n",
        "      kick_return = re.findall(return_pattern, i)\n",
        "      if len(kick_return) > 0:\n",
        "        df_kickoff_return['PlayDescription'] = i\n",
        "        df_kickoff_return['PlayOutcome'] = 'Run'\n",
        "        df_kickoff_return = clean_run_plays(df_kickoff_return)\n",
        "        df_kickoff_return['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "        df_kickoff_return['PlayType'] = 'Kickoff Return'\n",
        "        df_kickoff_return['Rusher'] = 'nan'\n",
        "        df_kickoff_return['Returner'] = kick_return[0][0] # I think this will be a problem once I get a dataset with kick return touchdowns\n",
        "        break\n",
        "\n",
        "    #############\n",
        "    #  PENALTY  #\n",
        "    #############\n",
        "\n",
        "    # Accepted Penalty\n",
        "    if i.find('PENALTY') != -1:\n",
        "      accepted_penalties.append(i)\n",
        "\n",
        "    # Declined Penalty\n",
        "    if i.find('Penalty') != -1:\n",
        "      declined_penalties.append(i)\n",
        "\n",
        "  if play.lower().find('penalty') != -1:\n",
        "    if df_kickoff_return['Returner'].iloc[0] == 'nan':\n",
        "      df_kickoff.at[0, 'AcceptedPenalty'] = accepted_penalties\n",
        "      df_kickoff.at[0, 'DeclinedPenalty'] = declined_penalties\n",
        "    else:\n",
        "      # start of play\n",
        "      start_string = play\n",
        "      dict_start = {\n",
        "          kickoff_pattern: [4, 5]\n",
        "      }\n",
        "      # end of play\n",
        "      end_string = play\n",
        "      dict_end = {\n",
        "          kick_return_pattern: [1, 2]\n",
        "      }\n",
        "      # play yardage\n",
        "      play_yardage_string = play\n",
        "      dict_play_yardage = {\n",
        "          kick_return_pattern: [3]\n",
        "      }\n",
        "      extract_penalty_data(df_kickoff_return, play, df_kickoff_return.index[0], start_string, dict_start, end_string, dict_end, play_yardage_string, dict_play_yardage)\n",
        "\n",
        "  #############################\n",
        "  # NEW REPLACEMENT DATAFRAME #\n",
        "  #############################\n",
        "\n",
        "  if df_kickoff_return['PlayDescription'].iloc[0] == 'nan':\n",
        "    df_replacement_rows = df_kickoff\n",
        "  elif df_kickoff['PlayDescription'].iloc[0] == 'nan': # Will happen during fumbled kickoff returns\n",
        "    df_replacement_rows = df_kickoff_return\n",
        "  else:\n",
        "    df_replacement_rows = pd.concat([df_kickoff, df_kickoff_return], ignore_index=True)\n",
        "\n",
        "  df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "  df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "  df_plays = pd.concat([df_before_row, df_replacement_rows, df_after_row], ignore_index=True)\n",
        "\n",
        "  if df_kickoff_plays.tail(1).index.tolist()[0] == idx:\n",
        "    return df_plays\n",
        "  else:\n",
        "    return clean_kickoff_plays(df_plays, idx+len(df_replacement_rows))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdlQ00Gxr216"
      },
      "source": [
        "###SCORING CLEANING METHODS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5B4OEwz2AwnX"
      },
      "source": [
        "#### TOUCHDOWNS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "GjW0FNUyOSVx"
      },
      "outputs": [],
      "source": [
        "# Still need to figure out whether or not plays that have multiple rows will all have\n",
        "# 'IsScoringDrive' = 1, 'IsScoringDrive' = 1, 'PlayOutcome' = *teamname* Touchdown\n",
        "# - The reasoning to not have this is because if a qb was to throw a pick 6,\n",
        "#   it wouldn't count as a \"Scoring Drive\" for them but the opposing team.\n",
        "# - For consistency, I will have the entire play have\n",
        "#   'IsScoringDrive' = 1, 'IsScoringDrive' = 1, 'PlayOutcome' = *teamname* Touchdown\n",
        "# - Need larger dataset to include all other touchdown plays such as kickoff returns and field goal returns\n",
        "\n",
        "# - I need to clean this method an condense. I feel like I can probably condense this a lot.\n",
        "\n",
        "def clean_touchdown_plays(df_plays, index_start=None):\n",
        "\n",
        "  # Cut 'df_plays' to begin from 'index_start' to the last touchdown play available in dataframe\n",
        "  if index_start != None:\n",
        "    df_plays_adjusted = df_plays.loc[index_start:]\n",
        "    df_touchdown_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('Touchdown')]\n",
        "  else:\n",
        "    df_touchdown_plays = df_plays[df_plays['PlayOutcome'].str.contains('Touchdown')]\n",
        "\n",
        "  # Iterating through every touchdown play within 'df_touchdown_plays'\n",
        "  for idx, play in df_touchdown_plays['PlayDescription'].items():\n",
        "\n",
        "    # - Once i figure out what kind of touchdown it was, then I will be able to\n",
        "    #   determine the 'PlayType'\n",
        "\n",
        "    ######################\n",
        "    # PASSING TOUCHDOWNS #\n",
        "    ######################\n",
        "\n",
        "    # If a play has a passer throwing the ball, I am assuming it is a passing play\n",
        "    passing_play = re.findall(passer_name_pattern, play)\n",
        "    if len(passing_play) > 0 and play.find(\"sacked\") == -1 and play.find(\"INTERCEPTED\") == -1:\n",
        "\n",
        "      # creating a copy of the passing touchdown play row and cleaning the copy\n",
        "      passing_touchdown_row = df_plays.loc[idx].copy()\n",
        "      passing_touchdown_row['PlayType'] = 'Pass'\n",
        "      passing_touchdown_row['PlayOutcome'] = 'Pass'\n",
        "      passing_touchdown_row['IsScoringPlay'] = 1\n",
        "      passing_touchdown_row = pd.DataFrame([passing_touchdown_row], columns=df_plays.columns)\n",
        "      passing_touchdown_row = clean_pass_plays(passing_touchdown_row)\n",
        "      passing_touchdown_row['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "\n",
        "      # Replacing old row with cleaned row\n",
        "      df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before_row, passing_touchdown_row, df_after_row], ignore_index=True)\n",
        "\n",
        "      # Recursion to update 'df_plays'\n",
        "      if df_touchdown_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_touchdown_plays(df_plays, idx+len(passing_touchdown_row))\n",
        "\n",
        "    ######################\n",
        "    # RUSHING TOUCHDOWNS #\n",
        "    ######################\n",
        "\n",
        "    rusher_patterns = [rusher_pattern]\n",
        "    # Loop through patterns and find the first match\n",
        "    for pattern in rusher_patterns:\n",
        "      rusher = re.findall(pattern, play)\n",
        "      if len(rusher) > 0:\n",
        "        # creating a copy of the rushing touchdown play row and cleaning the copy\n",
        "        rushing_touchdown_row = df_plays.loc[idx].copy()\n",
        "        rushing_touchdown_row['PlayType'] = 'Run'\n",
        "        rushing_touchdown_row['PlayOutcome'] = 'Run'\n",
        "        rushing_touchdown_row['IsScoringPlay'] = 1\n",
        "        rushing_touchdown_row = pd.DataFrame([rushing_touchdown_row], columns=df_plays.columns)\n",
        "        rushing_touchdown_row = clean_run_plays(rushing_touchdown_row)\n",
        "        rushing_touchdown_row['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "\n",
        "        # Replacing old row with cleaned row\n",
        "        df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "        df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "        df_plays = pd.concat([df_before_row, rushing_touchdown_row, df_after_row], ignore_index=True)\n",
        "\n",
        "        # Recursion to update 'df_plays'\n",
        "        if df_touchdown_plays.tail(1).index.tolist()[0] == idx:\n",
        "          return df_plays\n",
        "        else:\n",
        "          return clean_touchdown_plays(df_plays, idx+len(rushing_touchdown_row))\n",
        "\n",
        "    ##########################\n",
        "    # INTERCEPTED TOUCHDOWNS #\n",
        "    ##########################\n",
        "\n",
        "    # Still need to clean intercepted play types\n",
        "    if play.find(\"INTERCEPTED\") != -1:\n",
        "\n",
        "      # creating a copy of the incercepted touchdown play and cleaning the copy\n",
        "      intercepted_touchdown_row = df_plays.loc[idx].copy()\n",
        "      intercepted_touchdown_row['PlayOutcome'] = 'Interception'\n",
        "      intercepted_touchdown_row['IsScoringPlay'] = 1 # This will only be the value for the team that threw the interception\n",
        "      intercepted_touchdown_row = pd.DataFrame([intercepted_touchdown_row], columns=df_plays.columns)\n",
        "      intercepted_touchdown_row.reset_index(drop=True, inplace=True)\n",
        "\n",
        "      #################################################################################################### Under Construction\n",
        "      # Change feature 'TeamWithPossession' for each play in drive\n",
        "      # - Raw data states that the team that intercepted the ball for a touchdown had possession for each play\n",
        "      #   within drive. The correct value for this feature for each play in drive is the team that threw\n",
        "      #   the interception.\n",
        "\n",
        "      wrong_team_with_possession = df_plays['TeamWithPossession'].loc[idx]\n",
        "      if wrong_team_with_possession == dict_teams.get(df_plays['HomeTeam'].loc[idx]):\n",
        "        correct_team_with_possession = dict_teams.get(df_plays['AwayTeam'].loc[idx])\n",
        "      else:\n",
        "        correct_team_with_possession = dict_teams.get(df_plays['HomeTeam'].loc[idx])\n",
        "\n",
        "      # HERE I NEED TO CHANGE ALL 'TEAMWITHPOSSESSION' FEATURES FOR EVERY PLAY IN DRIVE\n",
        "      # I need to figure out how to efficiently grab every play in drive.\n",
        "      intercepted_touchdown_row['TeamWithPossession'] = correct_team_with_possession\n",
        "      conditions_for_unique_drive = ((df_plays['Season'] == df_plays['Season'].loc[idx]) &\n",
        "      (df_plays['Week'] == df_plays['Week'].loc[idx]) &\n",
        "      (df_plays['AwayTeam'] == df_plays['AwayTeam'].loc[idx]) &\n",
        "      (df_plays['HomeTeam'] == df_plays['HomeTeam'].loc[idx]) &\n",
        "      (df_plays['Quarter'] == df_plays['Quarter'].loc[idx]) &\n",
        "      (df_plays['DriveNumber'] == df_plays['DriveNumber'].loc[idx]))\n",
        "\n",
        "      df_plays.loc[conditions_for_unique_drive, 'TeamWithPossession'] = correct_team_with_possession\n",
        "\n",
        "      ####################################################################################################\n",
        "\n",
        "      # Because this is an interception for a touchdown, the defensive team should have their team\n",
        "      # with possession to end the drive.\n",
        "      # REMINDER: This single play is separated into multiple actions (play will be represented with multiple rows)\n",
        "      intercepted_touchdown_row = clean_intercepted_plays(intercepted_touchdown_row)\n",
        "      intercepted_touchdown_row['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "\n",
        "      # Replacing old row with cleaned row\n",
        "      df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before_row, intercepted_touchdown_row, df_after_row], ignore_index=True)\n",
        "\n",
        "      # Recursion to update 'df_plays'\n",
        "      if df_touchdown_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_touchdown_plays(df_plays, idx+len(intercepted_touchdown_row))\n",
        "\n",
        "    #####################################\n",
        "    # SACKED FUMBLE RECOVERY TOUCHDOWNS #\n",
        "    #####################################\n",
        "\n",
        "    if play.find(\"sacked\") != -1:\n",
        "\n",
        "      # creating a copy of the sack touchdown play and cleaning the copy\n",
        "      sacked_touchdown_row = df_plays.loc[idx].copy()\n",
        "      sacked_touchdown_row['PlayOutcome'] = 'Sack'\n",
        "      sacked_touchdown_row['IsScoringPlay'] = 1\n",
        "      sacked_touchdown_row = pd.DataFrame([sacked_touchdown_row], columns=df_plays.columns)\n",
        "      sacked_touchdown_row.reset_index(drop=True, inplace=True)\n",
        "\n",
        "      #################################################################################################### Under Construction\n",
        "      # Change feature 'TeamWithPossession' for each play in drive\n",
        "      # - Raw data states that the team that recovered the ball for a touchdown had possession for each play\n",
        "      #   within drive. The correct value for this feature for each play in drive is the team that fumbled.\n",
        "      #   - WRONG: I think this could cause some issues in the future. During a fumbled play, the feature\n",
        "      #            'TeamWithPossession' could go back and forth between both teams during that single play.\n",
        "      #            - This would take each of those rows representing that sinlge fumbled play and state that\n",
        "      #              the offense had possession the entire time.\n",
        "\n",
        "      wrong_team_with_possession = df_plays['TeamWithPossession'].loc[idx]\n",
        "      if wrong_team_with_possession == dict_teams.get(df_plays['HomeTeam'].loc[idx]):\n",
        "        correct_team_with_possession = dict_teams.get(df_plays['AwayTeam'].loc[idx])\n",
        "      else:\n",
        "        correct_team_with_possession = dict_teams.get(df_plays['HomeTeam'].loc[idx])\n",
        "\n",
        "      # HERE I NEED TO CHANGE ALL 'TEAMWITHPOSSESSION' FEATURES FOR EVERY PLAY IN DRIVE\n",
        "      # I need to figure out how to efficiently grab every play in drive.\n",
        "      sacked_touchdown_row['TeamWithPossession'] = correct_team_with_possession\n",
        "      conditions_for_unique_drive = ((df_plays['Season'] == df_plays['Season'].loc[idx]) &\n",
        "      (df_plays['Week'] == df_plays['Week'].loc[idx]) &\n",
        "      (df_plays['AwayTeam'] == df_plays['AwayTeam'].loc[idx]) &\n",
        "      (df_plays['HomeTeam'] == df_plays['HomeTeam'].loc[idx]) &\n",
        "      (df_plays['Quarter'] == df_plays['Quarter'].loc[idx]) &\n",
        "      (df_plays['DriveNumber'] == df_plays['DriveNumber'].loc[idx]))\n",
        "\n",
        "      df_plays.loc[conditions_for_unique_drive, 'TeamWithPossession'] = correct_team_with_possession\n",
        "\n",
        "      ####################################################################################################\n",
        "\n",
        "      # Because this is a fumble recovery for a touchdown, the defensive team should have their team\n",
        "      # with possession to end the drive. If this was not here, it would state that\n",
        "      sacked_touchdown_row = clean_sacked_plays(sacked_touchdown_row)\n",
        "      sacked_touchdown_row['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "\n",
        "      # Replacing old row with cleaned row (Original row can sometimes be replaced with multiple rows)\n",
        "      df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before_row, sacked_touchdown_row, df_after_row], ignore_index=True)\n",
        "\n",
        "      # Recursion to update 'df_plays'\n",
        "      if df_touchdown_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_touchdown_plays(df_plays, idx+len(sacked_touchdown_row))\n",
        "\n",
        "    ##########################\n",
        "    # PUNT RETURN TOUCHDOWNS #\n",
        "    ##########################\n",
        "\n",
        "    punt_play = re.findall(punting_pattern, play)\n",
        "    if len(punt_play) > 0:\n",
        "\n",
        "      # creating a copy of the punt touchdown play and cleaning the copy\n",
        "      punt_touchdown_row = df_plays.loc[idx].copy()\n",
        "      punt_touchdown_row['PlayOutcome'] = 'Punt'\n",
        "      punt_touchdown_row['IsScoringPlay'] = 1 # This will only be the value for the team that punted the ball\n",
        "      punt_touchdown_row = pd.DataFrame([punt_touchdown_row], columns=df_plays.columns)\n",
        "      punt_touchdown_row.reset_index(drop=True, inplace=True)\n",
        "\n",
        "\n",
        "      #################################################################################################### Under Construction\n",
        "      # Change feature 'TeamWithPossession' for each play in drive\n",
        "      # - Raw data states that the team that returned the punt for a touchdown had possession for each play\n",
        "      #   within drive. The correct value for this feature for each play in drive is the team that punted.\n",
        "      #   - NOTE: A punting play is separated into 2 pieces.\n",
        "      #           1. The punt (Team with possession is the team that punted the ball)\n",
        "      #           2. The punt return (Team with possession is the team that is returning the ball)\n",
        "\n",
        "      wrong_team_with_possession = df_plays['TeamWithPossession'].loc[idx]\n",
        "      if wrong_team_with_possession == dict_teams.get(df_plays['HomeTeam'].loc[idx]):\n",
        "        correct_team_with_possession = dict_teams.get(df_plays['AwayTeam'].loc[idx])\n",
        "      else:\n",
        "        correct_team_with_possession = dict_teams.get(df_plays['HomeTeam'].loc[idx])\n",
        "\n",
        "      # HERE I NEED TO CHANGE ALL 'TEAMWITHPOSSESSION' FEATURES FOR EVERY PLAY IN DRIVE\n",
        "      # I need to figure out how to efficiently grab every play in drive.\n",
        "      punt_touchdown_row['TeamWithPossession'] = correct_team_with_possession\n",
        "      conditions_for_unique_drive = ((df_plays['Season'] == df_plays['Season'].loc[idx]) &\n",
        "      (df_plays['Week'] == df_plays['Week'].loc[idx]) &\n",
        "      (df_plays['AwayTeam'] == df_plays['AwayTeam'].loc[idx]) &\n",
        "      (df_plays['HomeTeam'] == df_plays['HomeTeam'].loc[idx]) &\n",
        "      (df_plays['Quarter'] == df_plays['Quarter'].loc[idx]) &\n",
        "      (df_plays['DriveNumber'] == df_plays['DriveNumber'].loc[idx]))\n",
        "\n",
        "      df_plays.loc[conditions_for_unique_drive, 'TeamWithPossession'] = correct_team_with_possession\n",
        "\n",
        "      ####################################################################################################\n",
        "\n",
        "\n",
        "      punt_touchdown_row = clean_punt_plays(punt_touchdown_row)\n",
        "      punt_touchdown_row['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "\n",
        "      # Replacing old row with cleaned row\n",
        "      df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before_row, punt_touchdown_row, df_after_row], ignore_index=True)\n",
        "\n",
        "      # Recursion to update 'df_plays'\n",
        "      if df_touchdown_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_touchdown_plays(df_plays, idx+len(punt_touchdown_row))\n",
        "\n",
        "    #################################\n",
        "    # BLOCKED FIELD GOAL TOUCHDOWNS #\n",
        "    #################################\n",
        "\n",
        "    field_goal_blocked = re.findall(field_goal_blocked_pattern, play)\n",
        "    if len(field_goal_blocked) > 0:\n",
        "\n",
        "      # creating a copy of recovered blocked field goal touchdown play and cleaning the copy\n",
        "      blocked_fg_touchdown_row = df_plays.loc[idx].copy()\n",
        "      blocked_fg_touchdown_row['PlayOutcome'] = 'Field Goal'\n",
        "      blocked_fg_touchdown_row['IsScoringPlay'] = 1 # This will only be the value for the team that attempted the field goal\n",
        "      blocked_fg_touchdown_row = pd.DataFrame([blocked_fg_touchdown_row], columns=df_plays.columns)\n",
        "      blocked_fg_touchdown_row.reset_index(drop=True, inplace=True)\n",
        "      blocked_fg_touchdown_row = clean_field_goal_plays(blocked_fg_touchdown_row)\n",
        "      blocked_fg_touchdown_row['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "\n",
        "      #################################################################################################### Under Construction\n",
        "      # Change feature 'TeamWithPossession' for each play in drive\n",
        "      # - Raw data states that the team that blocked the field goal attempt and recovered for a touchdown had possession for each play\n",
        "      #   within drive. The correct value for this feature for each play in drive is the team that threw\n",
        "      #   the interception.\n",
        "\n",
        "      wrong_team_with_possession = df_plays['TeamWithPossession'].loc[idx]\n",
        "      if wrong_team_with_possession == dict_teams.get(df_plays['HomeTeam'].loc[idx]):\n",
        "        correct_team_with_possession = dict_teams.get(df_plays['AwayTeam'].loc[idx])\n",
        "      else:\n",
        "        correct_team_with_possession = dict_teams.get(df_plays['HomeTeam'].loc[idx])\n",
        "\n",
        "      # HERE I NEED TO CHANGE ALL 'TEAMWITHPOSSESSION' FEATURES FOR EVERY PLAY IN DRIVE\n",
        "      # I need to figure out how to efficiently grab every play in drive.\n",
        "      blocked_fg_touchdown_row['TeamWithPossession'] = correct_team_with_possession\n",
        "      conditions_for_unique_drive = ((df_plays['Season'] == df_plays['Season'].loc[idx]) &\n",
        "      (df_plays['Week'] == df_plays['Week'].loc[idx]) &\n",
        "      (df_plays['AwayTeam'] == df_plays['AwayTeam'].loc[idx]) &\n",
        "      (df_plays['HomeTeam'] == df_plays['HomeTeam'].loc[idx]) &\n",
        "      (df_plays['Quarter'] == df_plays['Quarter'].loc[idx]) &\n",
        "      (df_plays['DriveNumber'] == df_plays['DriveNumber'].loc[idx]))\n",
        "\n",
        "      df_plays.loc[conditions_for_unique_drive, 'TeamWithPossession'] = correct_team_with_possession\n",
        "\n",
        "      ####################################################################################################\n",
        "\n",
        "      # Replacing old row with cleaned row\n",
        "      df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before_row, blocked_fg_touchdown_row, df_after_row], ignore_index=True)\n",
        "\n",
        "      # Recursion to update 'df_plays'\n",
        "      if df_touchdown_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_touchdown_plays(df_plays, idx+len(blocked_fg_touchdown_row))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TZ3ncsLtBrS"
      },
      "source": [
        "#### FIELD GOALS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "VnHezsPttNG0"
      },
      "outputs": [],
      "source": [
        "# I need an example of when a player returns the field goal for yardage\n",
        "# I need a larger sample size for \"Blocked\" field goals\n",
        "# I need to figure out what to do if someone fumbles a recovery\n",
        "# I need to figure out what to do on a trick play (e.i. holder runs out with the ball)\n",
        "# - INCOMPLETE. NEED LARGER SAMPLE SIZE\n",
        "\n",
        "def clean_field_goal_plays(df_plays, index_start = None):\n",
        "\n",
        "  # Adjusting df_plays to start cleaning at a specified index (index_start)\n",
        "  if index_start != None:\n",
        "    df_plays_adjusted = df_plays.loc[index_start:]\n",
        "    # Locating all field goal plays within dataframe\n",
        "    df_field_goal_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('Field Goal')]\n",
        "  else:\n",
        "    # Locating all field goal plays within dataframe\n",
        "    df_field_goal_plays = df_plays[df_plays['PlayOutcome'].str.contains('Field Goal')]\n",
        "\n",
        "  for idx, play in df_field_goal_plays['PlayDescription'].items():\n",
        "\n",
        "    play_elements = play.split(\". \")\n",
        "\n",
        "    ###################\n",
        "    # EXTRA PLAY DATA #\n",
        "    ###################\n",
        "\n",
        "    # I may have to change this later.\n",
        "    # I think I will have to move this towards the end.\n",
        "\n",
        "    # - eventually I will have to use 'extract_penalty_data'\n",
        "    #   to handle field goal penalties. For now I am just\n",
        "    #   going to record them.\n",
        "\n",
        "    if len(play_elements) > 1:\n",
        "\n",
        "      accepted_penalties = []\n",
        "      declined_penalties = []\n",
        "      injured_players = []\n",
        "\n",
        "      for i in play_elements:\n",
        "\n",
        "        # Accepted Penalty\n",
        "        if i.find('PENALTY') != -1:\n",
        "          accepted_penalties.append(i)\n",
        "\n",
        "        # Declined Penalty\n",
        "        if i.find('Penalty') != -1:\n",
        "          declined_penalties.append(i)\n",
        "\n",
        "        # Injuries\n",
        "        injury_on_play = re.findall(injury_pattern, i)\n",
        "        if len(injury_on_play) > 0:\n",
        "          injured_players.append(injury_on_play[0])\n",
        "\n",
        "      if len(accepted_penalties) > 0:\n",
        "        df_plays.at[idx, 'AcceptedPenalty'] = accepted_penalties\n",
        "      if len(declined_penalties) > 0:\n",
        "        df_plays.at[idx, 'DeclinedPenalty'] = declined_penalties\n",
        "      if len(injured_players) > 0:\n",
        "        df_plays.at[idx, 'InjuredPlayers'] = injured_players\n",
        "\n",
        "    # Time of play\n",
        "    time_on_clock = re.findall(time_on_clock_pattern, play)\n",
        "    if len(time_on_clock) > 0:\n",
        "      df_plays.loc[idx, 'TimeOnTheClock'] = time_on_clock[0]\n",
        "\n",
        "    #########################\n",
        "    # FIELD GOAL SITUATIONS #\n",
        "    #########################\n",
        "\n",
        "    # Field goal good\n",
        "    field_goal_good = re.findall(field_goal_good_pattern, play)\n",
        "    if len(field_goal_good) > 0:\n",
        "      df_plays.loc[idx, 'PlayOutcome'] = 'Field Goal Good'\n",
        "      df_plays.loc[idx, 'PlayType'] = 'Field Goal'\n",
        "      df_plays.loc[idx, 'Kicker'] = field_goal_good[0][0]\n",
        "      df_plays.loc[idx, 'Yardage'] = int(field_goal_good[0][1])\n",
        "      df_plays.loc[idx, 'LongSnapper'] = field_goal_good[0][2]\n",
        "      df_plays.loc[idx, 'Holder'] = field_goal_good[0][3]\n",
        "      continue\n",
        "\n",
        "    # Field goal no good\n",
        "    field_goal_no_good = re.findall(field_goal_no_good_pattern, play)\n",
        "    if len(field_goal_no_good) > 0:\n",
        "      df_plays.loc[idx, 'PlayOutcome'] = 'Field Goal No Good'\n",
        "      df_plays.loc[idx, 'PlayType'] = 'Field Goal'\n",
        "      df_plays.loc[idx, 'Kicker'] = field_goal_no_good[0][0]\n",
        "      df_plays.loc[idx, 'Yardage'] = int(field_goal_no_good[0][1])\n",
        "      df_plays.loc[idx, 'Direction'] = field_goal_no_good[0][2]\n",
        "      df_plays.loc[idx, 'LongSnapper'] = field_goal_no_good[0][3]\n",
        "      df_plays.loc[idx, 'Holder'] = field_goal_no_good[0][4]\n",
        "      continue\n",
        "\n",
        "    # Field goal blocked\n",
        "    # - I NEED A LARGER SAMPLE SIZE TO CORRECTLY CLEAN THESE\n",
        "    # - Should I create a feature for those who recovered the ball?\n",
        "    # - This part of the method will sometimes have a play that can only be broken down\n",
        "    #   into multiple sentences, reach representing individual actions.\n",
        "    #   - individual actions like the field goal attempt, the recovery from the blockage\n",
        "    #     possible fumbles (I have not implement this).\n",
        "    # - I need to note that if a penalty has been called during a blocked field goal\n",
        "    #   with a recovery for yardage, extra data (such as penalties and injuries) will\n",
        "    #   be recorded multiple times. (I am too lazy right now to clean a situation that\n",
        "    #   I have not come across yet.)\n",
        "    field_goal_blocked = re.findall(field_goal_blocked_pattern, play)\n",
        "    if len(field_goal_blocked) > 0:\n",
        "\n",
        "      ########################################\n",
        "      # LOCATING BLOCKED FIELD GOAL SENTENCE #\n",
        "      ########################################\n",
        "\n",
        "      play_elements = play.split(\". \")\n",
        "      if len(play_elements) > 1:\n",
        "        for i in play_elements:\n",
        "          # Locating which sentence contains the field goal attempt\n",
        "          field_goal_blocked = re.findall(field_goal_blocked_pattern, i)\n",
        "          if len(field_goal_blocked) > 0:\n",
        "\n",
        "            ########################################\n",
        "            # CLEANING BLOCKED FIELD GOAL SENTENCE #\n",
        "            ########################################\n",
        "\n",
        "            # Isolating blocked field goal sentence\n",
        "            field_goal_attempt = i\n",
        "\n",
        "            # creating copy of row as a single row dataframe with feature 'PlayDescription' as field goal blocked\n",
        "            df_field_goal_blocked_row = pd.DataFrame([df_plays.loc[idx].copy()], columns=df_plays.columns)\n",
        "            df_field_goal_blocked_row['PlayDescription'] = field_goal_attempt\n",
        "            df_field_goal_blocked_row['PlayOutcome'] = 'Field Goal'\n",
        "            df_field_goal_blocked_row = clean_field_goal_plays(df_field_goal_blocked_row)\n",
        "            df_field_goal_blocked_row['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "\n",
        "            #############################\n",
        "            # CLEANING RECOVERY YARDAGE #\n",
        "            #############################\n",
        "\n",
        "            # Grabbing all actions that followed the field goal attempt (should be things such as recovery for yardage, fumbles, recovery for touchdown, etc.)\n",
        "            field_goal_blocked_recovery_actions = play_elements[play_elements.index(i)+1::]\n",
        "            field_goal_blocked_recovery_actions = \". \".join(field_goal_blocked_recovery_actions)\n",
        "\n",
        "            # creating copy of row as a single row dataframe with feature 'PlayDescription' as recovery data\n",
        "            df_recovery_yardage_rows = pd.DataFrame([df_plays.loc[idx].copy()], columns=df_plays.columns)\n",
        "            df_recovery_yardage_rows['PlayDescription'] = field_goal_blocked_recovery_actions\n",
        "            df_recovery_yardage_rows['PlayOutcome'] = 'Run'\n",
        "            df_recovery_yardage_rows = clean_run_plays(df_recovery_yardage_rows)\n",
        "            df_recovery_yardage_rows['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "            df_recovery_yardage_rows['PlayType'] = 'Field Goal Return'\n",
        "\n",
        "            #############################################\n",
        "            # REPLACING UNCLEAN ROW WITH CLEANED ROW(S) #\n",
        "            #############################################\n",
        "\n",
        "            df_before = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "            df_after = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "            df_plays = pd.concat([df_before, df_field_goal_blocked_row, df_recovery_yardage_rows, df_after], ignore_index=True)\n",
        "            index_of_last_added_row = idx + len(df_field_goal_blocked_row) + len(df_recovery_yardage_rows)\n",
        "\n",
        "            if df_field_goal_plays.tail(1).index.tolist()[0] == idx:\n",
        "              return df_plays\n",
        "            else:\n",
        "              return clean_field_goal_plays(df_plays, index_of_last_added_row + 1)\n",
        "            break\n",
        "\n",
        "      df_plays.loc[idx, 'PlayOutcome'] = 'Field Goal Blocked'\n",
        "      df_plays.loc[idx, 'PlayType'] = 'Field Goal'\n",
        "      df_plays.loc[idx, 'Kicker'] = field_goal_blocked[0][0]\n",
        "      df_plays.loc[idx, 'Yardage'] = int(field_goal_blocked[0][1])\n",
        "      df_plays.loc[idx, 'BlockedBy'] = field_goal_blocked[0][2]\n",
        "      df_plays.loc[idx, 'LongSnapper'] = field_goal_blocked[0][3]\n",
        "      df_plays.loc[idx, 'Holder'] = field_goal_blocked[0][4]\n",
        "      continue\n",
        "\n",
        "  return df_plays"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhsLNvcBA9uW"
      },
      "source": [
        "####EXTRA POINT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "GfgZ5xQTA9B2"
      },
      "outputs": [],
      "source": [
        "def clean_extra_point_plays(df_plays, index_start = None):\n",
        "\n",
        "  # Adjusting df_plays to start cleaning at a specified index (index_start)\n",
        "  if index_start != None:\n",
        "    df_plays_adjusted = df_plays.loc[index_start:]\n",
        "    # Locating all extra point plays within dataframe\n",
        "    df_extra_point_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('Extra Point')]\n",
        "  else:\n",
        "    # Locating all extra point plays within dataframe\n",
        "    df_field_goal_plays = df_plays[df_plays['PlayOutcome'].str.contains('Extra Point')]\n",
        "\n",
        "  for idx, play in df_field_goal_plays['PlayDescription'].items():\n",
        "\n",
        "    play_elements = play.split(\". \")\n",
        "\n",
        "    ###################\n",
        "    # EXTRA PLAY DATA #\n",
        "    ###################\n",
        "\n",
        "    # - eventually I will have to use 'extract_penalty_data'\n",
        "    #   to handle field goal penalties. For now I am just\n",
        "    #   going to record them.\n",
        "\n",
        "    if len(play_elements) > 1:\n",
        "\n",
        "      accepted_penalties = []\n",
        "      declined_penalties = []\n",
        "      injured_players = []\n",
        "\n",
        "      for i in play_elements:\n",
        "\n",
        "        # Accepted Penalty\n",
        "        if i.find('PENALTY') != -1:\n",
        "          accepted_penalties.append(i)\n",
        "\n",
        "        # Declined Penalty\n",
        "        if i.find('Penalty') != -1:\n",
        "          declined_penalties.append(i)\n",
        "\n",
        "        # Injuries\n",
        "        injury_on_play = re.findall(injury_pattern, i)\n",
        "        if len(injury_on_play) > 0:\n",
        "          injured_players.append(injury_on_play[0])\n",
        "\n",
        "      if len(accepted_penalties) > 0:\n",
        "        df_plays.at[idx, 'AcceptedPenalty'] = accepted_penalties\n",
        "      if len(declined_penalties) > 0:\n",
        "        df_plays.at[idx, 'DeclinedPenalty'] = declined_penalties\n",
        "      if len(injured_players) > 0:\n",
        "        df_plays.at[idx, 'InjuredPlayers'] = injured_players\n",
        "\n",
        "    ##########################\n",
        "    # EXTRA POINT SITUATIONS #\n",
        "    ##########################\n",
        "\n",
        "    # Extra point good\n",
        "    extra_point_good = re.findall(extra_point_good_pattern, play)\n",
        "    if len(extra_point_good) > 0:\n",
        "      df_plays.loc[idx, 'PlayOutcome'] = 'Extra Point Good'\n",
        "      df_plays.loc[idx, 'PlayType'] = 'Extra Point'\n",
        "      df_plays.loc[idx, 'Kicker'] = extra_point_good[0][0]\n",
        "      df_plays.loc[idx, 'LongSnapper'] = extra_point_good[0][1]\n",
        "      df_plays.loc[idx, 'Holder'] = extra_point_good[0][2]\n",
        "      continue\n",
        "\n",
        "    # Extra point no good\n",
        "    extra_point_no_good = re.findall(extra_point_no_good_pattern, play)\n",
        "    if len(extra_point_no_good) > 0:\n",
        "      df_plays.loc[idx, 'PlayOutcome'] = 'Extra Point No Good'\n",
        "      df_plays.loc[idx, 'PlayType'] = 'Extra Point'\n",
        "      df_plays.loc[idx, 'Kicker'] = extra_point_no_good[0][0]\n",
        "      df_plays.loc[idx, 'Direction'] = extra_point_no_good[0][1]\n",
        "      df_plays.loc[idx, 'LongSnapper'] = extra_point_no_good[0][2]\n",
        "      df_plays.loc[idx, 'Holder'] = extra_point_no_good[0][3]\n",
        "      continue\n",
        "\n",
        "  return df_plays"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_uTKSIZsZDi"
      },
      "source": [
        "###OTHER CLEANING METHODS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A1yQxl0kmLn"
      },
      "source": [
        "#### FUMBLE PLAYS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "u-HHSAiskq1X"
      },
      "outputs": [],
      "source": [
        "# What about punt returns?\n",
        "# Might need more data on 'Aborted' fumbled plays. Currently it does not show who fumbled the ball.\n",
        "\n",
        "def clean_fumble_plays(df_plays, index_start=None):\n",
        "\n",
        "  # Cut 'df_plays' to begin from 'index_start' to the last penalty play available in dataframe\n",
        "  if index_start != None:\n",
        "    df_plays_adjusted = df_plays.loc[index_start:]\n",
        "    df_fumble_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('fumble', case=False)]\n",
        "  else:\n",
        "    df_fumble_plays = df_plays[df_plays['PlayOutcome'].str.contains('fumble', case=False)]\n",
        "\n",
        "  for idx, play in df_fumble_plays['PlayDescription'].items():\n",
        "\n",
        "    ############\n",
        "    # REVERSES #\n",
        "    ############\n",
        "\n",
        "    # In 'PlayDescription' all information before the \"reversed\" sentence is not needed.\n",
        "    # - All information before is stored within 'ReverseDetails' and the remaining is cleaned.\n",
        "    if play.find('REVERSED') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      for i in play_elements:\n",
        "        if i.find(\"REVERSED\") != -1:\n",
        "          df_plays.at[idx, 'ReverseDetails'] = play_elements[:play_elements.index(i) + 1]\n",
        "          play = \". \".join(play_elements[play_elements.index(i) + 1:])\n",
        "          break\n",
        "\n",
        "    ############################\n",
        "    # REPORTING IN AS ELIGIBLE #\n",
        "    ############################\n",
        "\n",
        "    # I do not think this contains any useful data so I am going to exclude it.\n",
        "    if play.find('reported in as eligible') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      for i in play_elements:\n",
        "        if i.find('reported in as eligible') != -1:\n",
        "          play = \". \".join(play_elements[play_elements.index(i) + 1:])\n",
        "          break\n",
        "\n",
        "    initial_action = play.split(\". \")[0]\n",
        "\n",
        "    ##################\n",
        "    # PASSING FUMBLE #\n",
        "    ##################\n",
        "\n",
        "    fumble_pass = re.findall(receiver_pattern, initial_action)\n",
        "    if len(fumble_pass) > 0:\n",
        "\n",
        "      # creating a copy of the passing fumbled play row and cleaning the copy\n",
        "      passing_fumble_row = df_plays.loc[idx].copy()\n",
        "      passing_fumble_row['PlayOutcome'] = 'Pass'\n",
        "      passing_fumble_row = pd.DataFrame([passing_fumble_row], columns=df_plays.columns)\n",
        "      passing_fumble_row = clean_pass_plays(passing_fumble_row)\n",
        "\n",
        "      # Record whether the pass was complete or incomplete.\n",
        "      if play.find('pass incomplete') != -1:\n",
        "        passing_fumble_row['PlayOutcome'] = f\"{df_plays['PlayOutcome'].loc[idx]} (I)\"\n",
        "      else:\n",
        "        passing_fumble_row['PlayOutcome'] = f\"{df_plays['PlayOutcome'].loc[idx]} (C)\"\n",
        "\n",
        "      # Replacing old row with cleaned row\n",
        "      df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before_row, passing_fumble_row, df_after_row], ignore_index=True)\n",
        "\n",
        "      # Recursion to update 'df_plays'\n",
        "      if df_fumble_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_fumble_plays(df_plays, idx+len(passing_fumble_row))\n",
        "\n",
        "    ##################\n",
        "    # RUSHING FUMBLE #\n",
        "    ##################\n",
        "\n",
        "    fumble_rush = re.findall(rusher_pattern, initial_action)\n",
        "    qb_fumble = re.findall(qb_fumble_pattern, initial_action)\n",
        "    fumble_aborted = initial_action.find('Aborted')\n",
        "    if len(fumble_rush) > 0 or fumble_aborted != -1 or len(qb_fumble) > 0:\n",
        "\n",
        "      # creating a copy of the rushing fumbled play row and cleaning the copy\n",
        "      rushing_fumble_row = df_plays.loc[idx].copy()\n",
        "      rushing_fumble_row['PlayOutcome'] = 'Run'\n",
        "      rushing_fumble_row = pd.DataFrame([rushing_fumble_row], columns=df_plays.columns)\n",
        "      rushing_fumble_row = clean_run_plays(rushing_fumble_row)\n",
        "      rushing_fumble_row['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "\n",
        "      # Replacing old row with cleaned row\n",
        "      df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before_row, rushing_fumble_row, df_after_row], ignore_index=True)\n",
        "\n",
        "      # Recursion to update 'df_plays'\n",
        "      if df_fumble_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_fumble_plays(df_plays, idx+len(rushing_fumble_row))\n",
        "\n",
        "    #################\n",
        "    # SACKED FUMBLE #\n",
        "    #################\n",
        "\n",
        "    if initial_action.find('sacked') != -1:\n",
        "\n",
        "      # creating a copy of the sacked fumble play row and cleaning the copy\n",
        "      sacked_fumble_row = df_plays.loc[idx].copy()\n",
        "      sacked_fumble_row['PlayOutcome'] = 'Sack'\n",
        "      sacked_fumble_row = pd.DataFrame([sacked_fumble_row], columns=df_plays.columns)\n",
        "      sacked_fumble_row = clean_sacked_plays(sacked_fumble_row)\n",
        "      sacked_fumble_row['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "\n",
        "      # Replacing old row with cleaned row\n",
        "      df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before_row, sacked_fumble_row, df_after_row], ignore_index=True)\n",
        "\n",
        "      # Recursion to update 'df_plays'\n",
        "      if df_fumble_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_fumble_plays(df_plays, idx+len(sacked_fumble_row))\n",
        "\n",
        "    ##################\n",
        "    # KICKOFF FUMBLE #\n",
        "    ##################\n",
        "\n",
        "    kickoff_fumble = re.findall(kickoff_pattern, initial_action)\n",
        "    if len(kickoff_fumble) > 0:\n",
        "\n",
        "      # creating a copy of the passing fumbled play row and cleaning the copy\n",
        "      kickoff_fumble_row = df_plays.loc[idx].copy()\n",
        "      kickoff_fumble_row['PlayOutcome'] = 'kickoff'\n",
        "      kickoff_fumble_row = pd.DataFrame([kickoff_fumble_row], columns=df_plays.columns)\n",
        "      kickoff_fumble_row = clean_kickoff_plays(kickoff_fumble_row)\n",
        "      kickoff_fumble_row['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "\n",
        "      # Replacing old row with cleaned row\n",
        "      df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before_row, kickoff_fumble_row, df_after_row], ignore_index=True)\n",
        "\n",
        "      # Recursion to update 'df_plays'\n",
        "      if df_fumble_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_fumble_plays(df_plays, idx+len(kickoff_fumble_row))\n",
        "\n",
        "  return df_plays"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9M6XwDERno2n"
      },
      "source": [
        "#### PENALTY PLAYS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "2IOjdt8dn7Vo"
      },
      "outputs": [],
      "source": [
        "# This probably does not cover every possible penalty play.\n",
        "# For example, in this sample of plays there are no penalties during kickoffs\n",
        "# when penalties during kickoffs are 100% possible.\n",
        "\n",
        "def clean_penalty_plays(df_plays, index_start=None):\n",
        "\n",
        "  # Cut 'df_plays' to begin from 'index_start' to the last penalty play available in dataframe\n",
        "  if index_start != None:\n",
        "    df_plays_adjusted = df_plays.loc[index_start:]\n",
        "    df_plays_adjusted = df_plays.iloc[df_plays.index.tolist().index(index_start):]\n",
        "    df_penalty_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('penalty', case=False)]\n",
        "  else:\n",
        "    df_penalty_plays = df_plays[df_plays['PlayOutcome'].str.contains('penalty', case=False)]\n",
        "\n",
        "  # Iterating through every penalty play within 'df_penalty_plays'\n",
        "  for idx, play in df_penalty_plays['PlayDescription'].items():\n",
        "\n",
        "    ############\n",
        "    # REVERSES #\n",
        "    ############\n",
        "\n",
        "    # In 'PlayDescription' all information before the \"reversed\" sentence is not needed.\n",
        "    # - All information before is stored within 'ReverseDetails' and the remaining is cleaned.\n",
        "    if play.find('REVERSED') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      for i in play_elements:\n",
        "        if i.find(\"REVERSED\") != -1:\n",
        "          df_plays.at[idx, 'ReverseDetails'] = play_elements[:play_elements.index(i) + 1]\n",
        "          play = \". \".join(play_elements[play_elements.index(i) + 1:])\n",
        "          break\n",
        "\n",
        "    ############################\n",
        "    # REPORTING IN AS ELIGIBLE #\n",
        "    ############################\n",
        "\n",
        "    # I do not think this contains any useful data so I am going to exclude it.\n",
        "    if play.find('reported in as eligible') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      for i in play_elements:\n",
        "        if i.find('reported in as eligible') != -1:\n",
        "          play = \". \".join(play_elements[play_elements.index(i) + 1:])\n",
        "          break\n",
        "\n",
        "    initial_action = play.split(\". \")[0]\n",
        "\n",
        "    ###############################\n",
        "    # PENALTY DURING PASSING PLAY #\n",
        "    ###############################\n",
        "\n",
        "    penalty_pass = re.findall(receiver_pattern, initial_action)\n",
        "    if len(penalty_pass) > 0 or play.find('pass incomplete') != -1:\n",
        "\n",
        "      # creating a copy of the passing penalty play row and cleaning the copy\n",
        "      passing_penalty_row = df_plays.loc[idx].copy()\n",
        "      passing_penalty_row['PlayOutcome'] = 'Pass'\n",
        "      passing_penalty_row = pd.DataFrame([passing_penalty_row], columns=df_plays.columns)\n",
        "      passing_penalty_row = clean_pass_plays(passing_penalty_row)\n",
        "      passing_penalty_row['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "      passing_penalty_row['PlayType'] = 'No Play'\n",
        "\n",
        "      # Replacing old row with cleaned row\n",
        "      df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before_row, passing_penalty_row, df_after_row], ignore_index=True)\n",
        "\n",
        "      # Recursion to update 'df_plays'\n",
        "      if df_penalty_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_penalty_plays(df_plays, idx+len(passing_penalty_row))\n",
        "\n",
        "    ###############################\n",
        "    # PENALTY DURING RUSHING PLAY #\n",
        "    ###############################\n",
        "\n",
        "    penalty_rush = re.findall(rusher_pattern, initial_action)\n",
        "    if len(penalty_rush) > 0 or play.find('Aborted') != -1:\n",
        "\n",
        "      # creating a copy of the rushing penalty play row and cleaning the copy\n",
        "      rushing_penalty_row = df_plays.loc[idx].copy()\n",
        "      rushing_penalty_row['PlayOutcome'] = 'Run'\n",
        "      rushing_penalty_row = pd.DataFrame([rushing_penalty_row], columns=df_plays.columns)\n",
        "      rushing_penalty_row = clean_run_plays(rushing_penalty_row)\n",
        "      rushing_penalty_row['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "      rushing_penalty_row['PlayType'] = 'No Play'\n",
        "\n",
        "      # Replacing old row with cleaned row\n",
        "      df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before_row, rushing_penalty_row, df_after_row], ignore_index=True)\n",
        "\n",
        "      # Recursion to update 'df_plays'\n",
        "      if df_penalty_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_penalty_plays(df_plays, idx+len(rushing_penalty_row))\n",
        "\n",
        "    ######################################\n",
        "    # PENALTY DURING 2PT CONVERSION PLAY #\n",
        "    ######################################\n",
        "\n",
        "    if play.find('TWO-POINT CONVERSION ATTEMPT') != -1:\n",
        "\n",
        "      # creating a copy of the 2pt conversion penalty play row and cleaning the copy\n",
        "      two_pt_conversion_penalty_row = df_plays.loc[idx].copy()\n",
        "      two_pt_conversion_penalty_row['PlayOutcome'] = '2PT Conversion'\n",
        "      two_pt_conversion_penalty_row = pd.DataFrame([two_pt_conversion_penalty_row], columns=df_plays.columns)\n",
        "      two_pt_conversion_penalty_row = cleaning_2pt_conversion_plays(two_pt_conversion_penalty_row)\n",
        "      two_pt_conversion_penalty_row['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "      two_pt_conversion_penalty_row['PlayType'] = 'No Play'\n",
        "\n",
        "      # Replacing old row with cleaned row\n",
        "      df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before_row, two_pt_conversion_penalty_row, df_after_row], ignore_index=True)\n",
        "\n",
        "      # Recursion to update 'df_plays'\n",
        "      if df_penalty_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_penalty_plays(df_plays, idx+len(two_pt_conversion_penalty_row))\n",
        "\n",
        "    #################\n",
        "    # SACKED FUMBLE #\n",
        "    #################\n",
        "\n",
        "    if initial_action.find('sacked') != -1:\n",
        "\n",
        "      # creating a copy of the sacked fumble play row and cleaning the copy\n",
        "      sacked_penalty_row = df_plays.loc[idx].copy()\n",
        "      sacked_penalty_row['PlayOutcome'] = 'Sack'\n",
        "      sacked_penalty_row = pd.DataFrame([sacked_penalty_row], columns=df_plays.columns)\n",
        "      sacked_penalty_row = clean_sacked_plays(sacked_penalty_row)\n",
        "      sacked_penalty_row['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "      sacked_penalty_row['PlayType'] = 'No Play'\n",
        "\n",
        "      # Replacing old row with cleaned row\n",
        "      df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before_row, sacked_penalty_row, df_after_row], ignore_index=True)\n",
        "\n",
        "      # Recursion to update 'df_plays'\n",
        "      if df_penalty_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_penalty_plays(df_plays, idx+len(sacked_penalty_row))\n",
        "\n",
        "    #########################\n",
        "    # PENALTY (False Start) #\n",
        "    #########################\n",
        "\n",
        "    # Will use 'clean_run_plays' method to clean these\n",
        "    # All other penalty plays (e.i. False Start, Delay of Game, Offside, Neutral Zone Infraction, Too Many Men on Field, Encroachment, Taunting)\n",
        "\n",
        "    # if play.find('False Start') != -1 or play.find('Delay of Game') != -1:\n",
        "\n",
        "    # TimeOnTheClock\n",
        "    TimeOnTheClock = re.findall(time_on_clock_pattern, play)\n",
        "    if len(TimeOnTheClock) > 0:\n",
        "      df_plays.loc[idx, 'TimeOnTheClock'] = TimeOnTheClock[0]\n",
        "\n",
        "    # Formation\n",
        "    Formation = re.findall(formation, play)\n",
        "    if len(Formation) > 0:\n",
        "      if Formation[0] == 'Aborted':\n",
        "        pass\n",
        "      else:\n",
        "        df_plays.loc[idx, 'Formation'] = Formation[0]\n",
        "\n",
        "    df_plays.at[idx, 'AcceptedPenalty'] = play\n",
        "    df_plays.at[idx, 'PlayType'] = 'No Play'\n",
        "\n",
        "  return df_plays"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOqTmdy5ldib"
      },
      "source": [
        "#### TURNOVER ON DOWNS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "Qq4L0BYwmrrF"
      },
      "outputs": [],
      "source": [
        "# Looks like either a pass / run / sack play\n",
        "\n",
        "def clean_turnover_on_downs_plays(df_plays, index_start=None):\n",
        "\n",
        "  # Cut 'df_plays' to begin from 'index_start' to the last penalty play available in dataframe\n",
        "  if index_start != None:\n",
        "    df_plays_adjusted = df_plays.loc[index_start:]\n",
        "    df_turnover_on_downs_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('Turnover on Downs', case=False)]\n",
        "  else:\n",
        "    df_turnover_on_downs_plays = df_plays[df_plays['PlayOutcome'].str.contains('Turnover on Downs', case=False)]\n",
        "\n",
        "  # Iterating through every penalty play within 'df_turnover_on_downs_plays'\n",
        "  for idx, play in df_turnover_on_downs_plays['PlayDescription'].items():\n",
        "\n",
        "    ############################\n",
        "    # TURNOVER ON DOWNS (PASS) #\n",
        "    ############################\n",
        "\n",
        "    passing_play = re.findall(passer_name_pattern, play)\n",
        "    if len(passing_play) > 0 and play.find(\"sacked\") == -1:\n",
        "\n",
        "      passing_turnover_on_downs = df_plays.loc[idx].copy()\n",
        "      passing_turnover_on_downs['PlayOutcome'] = 'Pass'\n",
        "      passing_turnover_on_downs = pd.DataFrame([passing_turnover_on_downs], columns=df_plays.columns)\n",
        "      passing_turnover_on_downs = clean_pass_plays(passing_turnover_on_downs)\n",
        "\n",
        "      # Record whether the pass was complete or incomplete.\n",
        "      if play.find('pass incomplete') != -1:\n",
        "        passing_turnover_on_downs['PlayOutcome'] = f\"{df_plays['PlayOutcome'].loc[idx]} (I)\"\n",
        "      else:\n",
        "        passing_turnover_on_downs['PlayOutcome'] = f\"{df_plays['PlayOutcome'].loc[idx]} (C)\"\n",
        "\n",
        "      # Replacing old row with cleaned row\n",
        "      df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before_row, passing_turnover_on_downs, df_after_row], ignore_index=True)\n",
        "\n",
        "      # Recursion to update 'df_plays'\n",
        "      if df_turnover_on_downs_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_turnover_on_downs_plays(df_plays, idx+len(passing_turnover_on_downs))\n",
        "\n",
        "    ############################\n",
        "    # TURNOVER ON DOWNS (RUSH) #\n",
        "    ############################\n",
        "\n",
        "    rushing_play = re.findall(rusher_pattern, play)\n",
        "    if len(rushing_play) > 0:\n",
        "\n",
        "      rushing_turnover_on_downs = df_plays.loc[idx].copy()\n",
        "      rushing_turnover_on_downs['PlayOutcome'] = 'Run'\n",
        "      rushing_turnover_on_downs = pd.DataFrame([rushing_turnover_on_downs], columns=df_plays.columns)\n",
        "      rushing_turnover_on_downs = clean_run_plays(rushing_turnover_on_downs)\n",
        "      rushing_turnover_on_downs['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "\n",
        "      df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before_row, rushing_turnover_on_downs, df_after_row], ignore_index=True)\n",
        "\n",
        "      if df_turnover_on_downs_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_turnover_on_downs_plays(df_plays, idx+len(rushing_turnover_on_downs))\n",
        "\n",
        "    ##############################\n",
        "    # TURNOVER ON DOWNS (SACKED) #\n",
        "    ##############################\n",
        "\n",
        "    if play.find(\"sacked\") != -1:\n",
        "\n",
        "      sacked_turnover_on_downs = df_plays.loc[idx].copy()\n",
        "      sacked_turnover_on_downs['PlayOutcome'] = 'Sack'\n",
        "      sacked_turnover_on_downs = pd.DataFrame([sacked_turnover_on_downs], columns=df_plays.columns)\n",
        "      sacked_turnover_on_downs.reset_index(drop=True, inplace=True)\n",
        "      sacked_turnover_on_downs = clean_sacked_plays(sacked_turnover_on_downs)\n",
        "      sacked_turnover_on_downs['PlayOutcome'] = df_plays['PlayOutcome'].loc[idx]\n",
        "\n",
        "      # Replacing old row with cleaned row\n",
        "      df_before_row = df_plays.iloc[:df_plays.index.tolist().index(idx)]\n",
        "      df_after_row = df_plays.iloc[df_plays.index.tolist().index(idx)+1:]\n",
        "      df_plays = pd.concat([df_before_row, sacked_turnover_on_downs, df_after_row], ignore_index=True)\n",
        "\n",
        "      # Recursion to update 'df_plays'\n",
        "      if df_turnover_on_downs_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_turnover_on_downs_plays(df_plays, idx+len(sacked_turnover_on_downs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0nkzhWl5FEn"
      },
      "source": [
        "## 4. PIPELINE MAIN METHOD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "7cbY2K4pyH8d"
      },
      "outputs": [],
      "source": [
        "# PURPOSE:\n",
        "# - Accept a dataframe of plays (dataframes formatted by NFL_Scrapers) and\n",
        "#   return a cleaned dataframe of those plays.\n",
        "# INPUT PARAMTERS:\n",
        "# df_all_plays         - dataframe - all plays in raw form from NFL_Scraper that user\n",
        "#                                    would like to clean.\n",
        "# OUTPUT:\n",
        "# df_all_plays_cleaned - dataframe - all plays from 'df_all_plays' cleaned and data\n",
        "#                                    dispersed into individual new features.\n",
        "\n",
        "# CURRENT DESIGN PLAN:\n",
        "# 1. Use uniquely designed methods for each play type to clean within dataframe\n",
        "#    - (e.g. pass, run, touchdown, punt, sack, ... )\n",
        "# 2. Repeat until all plays within dataframe have been cleaned.\n",
        "#   NOTE:\n",
        "#   - It is important to fully clean a play type before moving to the next\n",
        "#      because sometimes cleaning could involve adding a new row to the dataframe,\n",
        "#      causing a reset to the dataframes indexing.\n",
        "#      - If we were to separate all play types from the beginning, the indexes\n",
        "#        could shift around causing, for example, an index that might originally\n",
        "#        point to a run play to now instead point at a pass play.\n",
        "\n",
        "def clean_dataframe_of_plays(df_all_plays):\n",
        "\n",
        "  ################################\n",
        "  # RAW DATA COLUMN DESCRIPTIONS #\n",
        "  ################################\n",
        "  # Season             - Year of the season\n",
        "  # Week               - Game week of the season (e.g. 'Week 1')\n",
        "  # Day                - Day of the week (e.g. 'MON')\n",
        "  # Date               - Month and day of the game formatted MM/DD (e.g. '09/07')\n",
        "  # AwayTeam           - Visiting team of the game\n",
        "  # HomeTeam           - Home team of the game\n",
        "  # Quarter            - Quarter that the focused play is in\n",
        "  # DriveNumber        - Drive number that the focused play is in\n",
        "  # TeamWithPossession - Team with the ball during the play.\n",
        "  #                      - Can have multiple teams with possession during a single play.\n",
        "  #                        - Some plays are broken down into multiple rows such as fumbled plays.\n",
        "  # IsScoringDrive     - Does the drive that the focused play in result in a score?\n",
        "  # PlayOutcome        - Ultimate result of the play (e.g. '13 Yard Pass')\n",
        "  # PlayDescription    - The raw description given of the focused play, entailing everything\n",
        "  #                      that happened within it.\n",
        "  # PlayStart          - The down and where the play started on the field (e.g. '2nd & 9 at DET 21')\n",
        "\n",
        "  ###########################\n",
        "  # NEW COLUMN DESCRIPTIONS #\n",
        "  ###########################\n",
        "\n",
        "  # PlayType           - The type of play (e.g. pass/run)\n",
        "  # TimeOnTheClock     - The time that was on the clock when the play started\n",
        "  # Formation          - Play formation\n",
        "  # Passer             - Player that threw the ball (mostly the quarterback)\n",
        "  # Rusher             - Player that ran the ball (mostly the runningback)\n",
        "  # Receiver           - Player on the same team as the passer that caught the ball\n",
        "  # Direction          - Where the ball is going during the play\n",
        "  # Yardage            - Yards gained during the play\n",
        "  #                      - (Should specify that yardage does not include extra yardage gained from penalties)\n",
        "  #                      - (Player awarded yardage)\n",
        "  #                      - (also includes how far kicks have gone during kickoffs and punts)\n",
        "  # SoloTackle         - Player awarded a solo tackle from a play\n",
        "  # AssistedTackle     - Player awarded an assisted tackle from a play\n",
        "  # SharedTackle       - Player awarded a shared tackle from a play\n",
        "  # PassDefendedBy     - Defender that defended the passing play\n",
        "  # PressureBy         - Defender that applied pressure to the passer\n",
        "  # InterceptedBy      - Defender that intercepted the passing play\n",
        "  # SackedBy           - Player awarded a sack from a play. (Could be solo or split)\n",
        "  # ForcedFumbledBy    - Player awarded a forced fumble from a play\n",
        "  # WhoFumbled         - Player who last held the ball during a fumble.\n",
        "  # FumbleRecoveredBy  - Player who recovered the fumbled ball\n",
        "  # FumbleDetails      - A list that has what happened after the fumble\n",
        "  #                      - [forced fumble by, recovered by, yards gained, tackled by]\n",
        "  # ReverseDetails     - A list having plays leading up to play reversal\n",
        "  # InjuredPlayers     - Players that were injured during the play\n",
        "  # AcceptedPenalty    - Penalty on the field that was accepted\n",
        "  # DeclinedPenalty    - Penalty on the field that was declined\n",
        "  # Kicker             - Player who kicked the ball during a kickoff / punt / extra point / field goal\n",
        "  # LongSnapper        - Player who snapped the ball during a punt / extra point / field goal\n",
        "  # Returner           - Player who returned the ball during a kickoff / punt\n",
        "  # DownedBy           - ? ? ? I forget\n",
        "  # Holder             - Player who held ball for extra point / field goal\n",
        "  # BlockedBy          - Player who blocked a punt / extra point / field goal\n",
        "\n",
        "  new_columns = [\"PlayType\", \"TimeOnTheClock\", \"Formation\", \"Passer\", \"Rusher\", \"Receiver\", \"Direction\", \"Yardage\",\n",
        "                \"SoloTackle\", \"AssistedTackle\", \"SharedTackle\", 'PassDefendedBy', \"PressureBy\", \"InterceptedBy\", \"SackedBy\", \"ForcedFumbleBy\", \"WhoFumbled\", \"FumbleRecoveredBy\",\n",
        "                \"FumbleDetails\", \"ReverseDetails\",\n",
        "                \"InjuredPlayers\", \"AcceptedPenalty\", \"DeclinedPenalty\",\n",
        "                \"Kicker\", \"LongSnapper\", \"Returner\", \"DownedBy\", \"Holder\", \"BlockedBy\"]\n",
        "\n",
        "  string_columns = [\"PlayType\", \"TimeOnTheClock\", \"Formation\", \"Passer\", \"Rusher\", \"Receiver\", \"Direction\",\n",
        "                    \"SoloTackle\", \"AssistedTackle\", \"SharedTackle\", 'PassDefendedBy', \"PressureBy\", \"InterceptedBy\", \"SackedBy\", \"ForcedFumbleBy\", \"WhoFumbled\", \"FumbleRecoveredBy\",\n",
        "                    \"FumbleDetails\", \"ReverseDetails\",\n",
        "                    \"InjuredPlayers\", \"AcceptedPenalty\", \"DeclinedPenalty\",\n",
        "                    \"Kicker\", \"LongSnapper\", \"Returner\", \"DownedBy\", \"Holder\", \"BlockedBy\"]\n",
        "\n",
        "  int_columns = [\"Yardage\"]\n",
        "\n",
        "  ########################################\n",
        "  # RETURN DATAFRAME WITH ADDED FEATURES #\n",
        "  ########################################\n",
        "\n",
        "  df_all_plays_cleaned = df_all_plays.copy()\n",
        "  df_all_plays_cleaned = df_all_plays_cleaned.reindex(columns=df_all_plays_cleaned.columns.tolist() + new_columns)\n",
        "  df_all_plays_cleaned[string_columns] = df_all_plays_cleaned[string_columns].astype(str)\n",
        "  df_all_plays_cleaned[int_columns] = df_all_plays_cleaned[int_columns].astype(float)\n",
        "\n",
        "  ########################################\n",
        "  # GETTING PLAY CATEGORIES AND CLEANING #\n",
        "  ########################################\n",
        "\n",
        "  # TOUCHDOWNS MUST BE CLEANED FIRST\n",
        "  # - Any touchdown resulting from a change in possession (e.g. Interception for Touchdown)\n",
        "  #   raw data states that the team on defense had possession the entire drive.\n",
        "  #   - So all plays leading up to the touchdown state that the defense has possession.\n",
        "  # df_all_plays_cleaned = clean_touchdown_plays(df_all_plays_cleaned)\n",
        "  # df_all_plays_cleaned = clean_run_plays(df_all_plays_cleaned)\n",
        "  # df_all_plays_cleaned = clean_pass_plays(df_all_plays_cleaned)\n",
        "  # df_all_plays_cleaned = cleaning_2pt_conversion_plays(df_all_plays_cleaned)\n",
        "  df_all_plays_cleaned = clean_intercepted_plays(df_all_plays_cleaned)\n",
        "  # df_all_plays_cleaned = clean_sacked_plays(df_all_plays_cleaned)\n",
        "  # df_all_plays_cleaned = clean_punt_plays(df_all_plays_cleaned)\n",
        "  # df_all_plays_cleaned = clean_kickoff_plays(df_all_plays_cleaned)\n",
        "  # df_all_plays_cleaned = clean_field_goal_plays(df_all_plays_cleaned)\n",
        "  # df_all_plays_cleaned = clean_extra_point_plays(df_all_plays_cleaned)\n",
        "  # df_all_plays_cleaned = clean_fumble_plays(df_all_plays_cleaned)\n",
        "  # df_all_plays_cleaned = clean_penalty_plays(df_all_plays_cleaned)\n",
        "  # df_all_plays_cleaned = clean_turnover_on_downs_plays(df_all_plays_cleaned)\n",
        "\n",
        "  return df_all_plays_cleaned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7HnZWShxAX5"
      },
      "source": [
        "# TESTING (Helper Methods)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "RzaGgriDS9Js"
      },
      "outputs": [],
      "source": [
        "# PURPOSE:\n",
        "# - A tool that can be used to compare original plays and their cleaned versions\n",
        "\n",
        "# I would like to return a map that has:\n",
        "# KEY: index of original unclean play\n",
        "# VALUE: index(es) of cleaned play\n",
        "\n",
        "def unclean_clean_matches(df_unclean_plays, df_clean_plays):\n",
        "\n",
        "  my_map = {}\n",
        "\n",
        "  # This group of features is unique to each play\n",
        "  # - Both the unclean and cleaned versions of the plays have these\n",
        "  # - These features will be used to find the matching plays between the unclean df and the cleaned df\n",
        "  # matching_features = ['Season', 'Week', 'Date', 'AwayTeam', 'HomeTeam', 'Quarter', 'DriveNumber', 'TeamWithPossession', 'PlayNumberInDrive']\n",
        "  matching_features = ['Season', 'Week', 'Date', 'AwayTeam', 'HomeTeam', 'Quarter', 'DriveNumber', 'PlayNumberInDrive']\n",
        "\n",
        "  # Iterate through each row of the dataframe of unclean plays\n",
        "  for u_row in df_unclean_plays.itertuples(index=True):\n",
        "    u_features = [getattr(u_row, col) for col in matching_features]\n",
        "\n",
        "    matching_indexes = []\n",
        "    matches_found = False\n",
        "\n",
        "    # Iterate through each row of the dataframe of cleaned plays\n",
        "    # - The starting index will be the index of the unclean play within the main original dataframe of plays\n",
        "    #   - The matching cleaned pair will either be at the exact same location or higher\n",
        "    for c_row in df_clean_plays[u_row.Index::].itertuples(index=True):\n",
        "      c_features = [getattr(c_row, col) for col in matching_features]\n",
        "\n",
        "      # If a match is found, check for consective rows of matches because some uncleaned plays needed to be cleaned using multiple rows\n",
        "      # - Once a row that does not match follows one that does, will break the loop because the one play match has been found.\n",
        "      if u_features == c_features:\n",
        "        matching_indexes.append(c_row.Index)\n",
        "        matches_found = True\n",
        "      elif matches_found:\n",
        "        my_map[u_row.Index] = matching_indexes\n",
        "        break\n",
        "\n",
        "  return my_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN4kSTEvpiHe"
      },
      "source": [
        "# TESTING AREA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "WneGzl-4StKu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae87467e-5ff2-49e9-aba7-da456eb740d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10:48) (Shotgun) J.Burrow pass short middle intended for T.Higgins INTERCEPTED by G.Stone at BAL 2\n",
            "G.Stone ran ob at BAL 38 for 36 yards (J.Burrow).\n",
            "(12:39) (Shotgun) D.Ridder pass deep middle intended for J.Smith INTERCEPTED by R.Douglas [K.Clark] at GB 42\n",
            "R.Douglas to GB 40 for -2 yards (K.Pitts).\n",
            "(3:58) T.Munford reported in as eligible.  J.Garoppolo pass short right intended for J.Jacobs INTERCEPTED by M.Milano at BUF 49\n",
            "M.Milano to LV 48 for 3 yards (J.Jacobs).\n",
            "(11:51) (Shotgun) Z.Wilson pass short right intended for G.Wilson INTERCEPTED by J.Kearse at NYJ 49\n",
            "J.Kearse to NYJ 17 for 32 yards (D.Brown). Penalty on NYJ-M.Becton, Offensive Holding, declined.\n",
            "(10:33) (No Huddle, Shotgun) R.Wilson pass short left intended for C.Sutton INTERCEPTED by E.Forbes at DEN 47\n",
            "E.Forbes to DEN 44 for 3 yards. FUMBLES, ball out of bounds at DEN 44. The Replay Official reviewed the interception ruling, and the play was Upheld. The ruling on the field stands.\n",
            "0\n",
            "[]\n",
            "['E.Forbes to DEN 44 for 3 yards', 'FUMBLES, ball out of bounds at DEN 44']\n",
            "[('DEN', '36')]\n",
            "[('DEN', '44', '3')]\n",
            "[('DEN', '44')]\n",
            "(4:17) (No Huddle, Shotgun) M.Stafford pass short left intended for K.Williams INTERCEPTED by I.Oliver at SF 25\n",
            "I.Oliver to SF 28 for 3 yards (K.Williams).\n",
            "(8:22) J.Garoppolo pass short middle intended for A.Abdullah INTERCEPTED by T.Bernard (G.Rousseau) [D.Jones] at LV 28\n",
            "T.Bernard to LV 28 for no gain (A.Abdullah).\n",
            "(10:04) (Shotgun) T.Tagovailoa pass deep left intended for T.Hill INTERCEPTED by C.Gonzalez [M.Judon] at NE 14\n",
            "C.Gonzalez to NE 14 for no gain (T.Hill).\n",
            "(8:12) (Shotgun) K.Pickett pass short left intended for G.Pickens INTERCEPTED by G.Delpit at PIT 19\n",
            "G.Delpit to PIT 19 for no gain (C.Austin).\n",
            "(4:58) (Shotgun) M.Stafford pass short middle intended for V.Jefferson INTERCEPTED by D.Lenoir at LA 36\n",
            "D.Lenoir ran ob at LA 15 for 21 yards (C.Shelton).\n",
            "(:57) (No Huddle, Shotgun) M.Jones pass deep right intended for D.Parker INTERCEPTED by X.Howard at MIA 3\n",
            "X.Howard pushed ob at MIA 3 for no gain (D.Parker).\n",
            "(4:30) (No Huddle, Shotgun) D.Jones pass short right intended for S.Barkley INTERCEPTED by J.Thompson at ARI 31\n",
            "J.Thompson ran ob at NYG 34 for 35 yards (D.Jones).\n",
            "(6:10) (Shotgun) Z.Wilson pass deep left intended for G.Wilson INTERCEPTED by M.Hooker at DAL 8\n",
            "M.Hooker to DAL 8 for no gain (G.Wilson).\n",
            "(3:04) (Shotgun) J.Hurts pass deep middle intended for D.Smith INTERCEPTED by Th.Jackson at MIN 35\n",
            "Th.Jackson to MIN 35 for no gain (D.Smith).\n",
            "(9:51) (Shotgun) P.Mahomes pass deep middle intended for Ju.Watson INTERCEPTED by A.Cisco [J.Allen] at JAX 12\n",
            "A.Cisco to JAX 12 for no gain (Ju.Watson).\n",
            "(3:16) (Shotgun) D.Carr pass deep right intended for C.Olave INTERCEPTED by V.Bell at NO 48\n",
            "V.Bell to NO 37 for 11 yards (T.Jones).\n",
            "(3:07) (Shotgun) Z.Wilson pass short left intended for Mi.Carter INTERCEPTED by T.Diggs at DAL 45\n",
            "T.Diggs to NYJ 47 for 8 yards (Mi.Carter).\n",
            "(1:17) (No Huddle, Shotgun) J.Fields pass short middle intended for C.Claypool INTERCEPTED by C.Izien (A.Winfield) at CHI 29\n",
            "C.Izien to CHI 25 for 4 yards (R.Johnson).\n"
          ]
        }
      ],
      "source": [
        "df_week2_plays_cleaned = clean_dataframe_of_plays(week2_2023_plays_modified)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l79N87_MWkzH",
        "outputId": "d0872379-8353-4507-fd77-832082949382"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2652, 44)"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ],
      "source": [
        "df_week2_plays_cleaned.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3xBIferz67H"
      },
      "source": [
        "## PLAYTYPE OBSERVATIONS\n",
        "- Looking at each play from each playtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYVhXDgbC3m3"
      },
      "source": [
        "### Passing plays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "AnnrktjKJu3z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "fd88cbe9-2aad-4732-853c-5ad3a1d90b86"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_week1_plays_cleaned' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-33147371.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_unclean_pass_plays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweek2_2023_plays_modified\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mweek2_2023_plays_modified\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PlayOutcome'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Pass'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmap_passing_plays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munclean_clean_matches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_unclean_pass_plays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_week1_plays_cleaned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_passing_plays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_week1_plays_cleaned' is not defined"
          ]
        }
      ],
      "source": [
        "# Number of passing type plays during 2023, Week 1\n",
        "\n",
        "df_unclean_pass_plays = week2_2023_plays_modified.loc[week2_2023_plays_modified['PlayOutcome'].str.contains('Pass')]\n",
        "\n",
        "map_passing_plays = unclean_clean_matches(df_unclean_pass_plays, df_week1_plays_cleaned)\n",
        "\n",
        "len(map_passing_plays.keys())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_tackles = df_unclean_pass_plays.loc[\n",
        "    (df_unclean_pass_plays['PlayDescription'].str.contains('D.Jones'))\n",
        "    &\n",
        "    (~df_unclean_pass_plays['PlayDescription'].str.contains('pass incomplete'))]\n",
        "\n",
        "for idx, play in df_tackles['PlayDescription'].items():\n",
        "  print(idx)\n",
        "  play_split = play.split(\". \")\n",
        "  for i in play_split:\n",
        "    print(i)\n",
        "  print()"
      ],
      "metadata": {
        "id": "2hCCrVAjdgSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNtZrXPKno2W"
      },
      "outputs": [],
      "source": [
        "# Every unclean passing play and their associated cleaned play breakdown\n",
        "\n",
        "for i in map_passing_plays.keys():\n",
        "  print(f\"({i}, {map_passing_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kofdUBx2kLuU"
      },
      "outputs": [],
      "source": [
        "# passing type plays during 2023, Week 1 that have been spiked\n",
        "\n",
        "df_unclean_pass_plays_spiked = week1_2023_plays_modified.loc[(week1_2023_plays_modified['PlayOutcome'].str.contains('Pass')) &\n",
        "                                                             (week1_2023_plays_modified['PlayDescription'].str.contains('spiked', case=False))]\n",
        "\n",
        "map_passing_spiked_plays = unclean_clean_matches(df_unclean_pass_plays_spiked, df_week1_plays_cleaned)\n",
        "\n",
        "for i in map_passing_spiked_plays.keys():\n",
        "  print(f\"({i}, {map_passing_spiked_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOb_Z_X_gECI"
      },
      "outputs": [],
      "source": [
        "# passing type plays during 2023, Week 1 that result in touchdown\n",
        "\n",
        "df_unclean_pass_plays_touchdown = week1_2023_plays_modified.loc[(week1_2023_plays_modified['PlayOutcome'].str.contains('touchdown', case=False)) &\n",
        "                                                                (week1_2023_plays_modified['PlayDescription'].str.contains('pass', case=False))]\n",
        "\n",
        "map_passing_touchdown_plays = unclean_clean_matches(df_unclean_pass_plays_touchdown, df_week1_plays_cleaned)\n",
        "\n",
        "for i in map_passing_touchdown_plays.keys():\n",
        "  print(f\"({i}, {map_passing_touchdown_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NSr2Lxzlt08"
      },
      "outputs": [],
      "source": [
        "# passing type plays during 2023, Week 1 that result in touchdown\n",
        "\n",
        "df_unclean_pass_plays_touchdown = week1_2023_plays_modified.loc[(week1_2023_plays_modified['PlayOutcome'].str.contains('touchdown', case=False)) &\n",
        "                                                                (week1_2023_plays_modified['PlayDescription'].str.contains('PENALTY', case=False))]\n",
        "\n",
        "map_passing_touchdown_plays = unclean_clean_matches(df_unclean_pass_plays_touchdown, df_week1_plays_cleaned)\n",
        "\n",
        "for i in map_passing_touchdown_plays.keys():\n",
        "  print(f\"({i}, {map_passing_touchdown_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aM4Flk8_SmK1"
      },
      "outputs": [],
      "source": [
        "# every passing play that resulted in a fumble (including fumble recoveries resulting in a touchdown)\n",
        "\n",
        "df_unclean_pass_fumble_plays = week1_2023_plays_modified.loc[((week1_2023_plays_modified['PlayOutcome'].str.contains('Pass')) |\n",
        "                                                             ((week1_2023_plays_modified['PlayDescription'].str.contains('Touchdown', case=False)) &\n",
        "                                                              (week1_2023_plays_modified['PlayOutcome'].str.contains('Pass')))) &\n",
        "                                                              (week1_2023_plays_modified['PlayDescription'].str.contains('fumbles', case=False))]\n",
        "\n",
        "for i in unclean_clean_matches(df_unclean_pass_fumble_plays, df_week1_plays_cleaned).items():\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srpeGK1JS1pa"
      },
      "outputs": [],
      "source": [
        "dict_unclean_to_clean_pass_fumble_plays = unclean_clean_matches(df_unclean_pass_fumble_plays, df_week1_plays_cleaned)\n",
        "\n",
        "for i in dict_unclean_to_clean_pass_fumble_plays.keys():\n",
        "  # print(i)\n",
        "  print(f\"({i}, {dict_unclean_to_clean_pass_fumble_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# All passing plays with accepted penalties\n",
        "\n",
        "df_unclean_pass_plays = week1_2023_plays_modified.loc[(week1_2023_plays_modified['PlayOutcome'].str.contains('Pass')) &\n",
        "                                                      (week1_2023_plays_modified['PlayDescription'].str.contains('PENALTY'))]\n",
        "\n",
        "map_passing_penalty_plays = unclean_clean_matches(df_unclean_pass_plays, df_week1_plays_cleaned)\n",
        "\n",
        "for i in map_passing_penalty_plays.keys():\n",
        "  print(f\"({i}, {map_passing_penalty_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "ir_d9j-Jfv60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All passing plays with lateral\n",
        "\n",
        "df_unclean_pass_plays = week1_2023_plays_modified.loc[(week1_2023_plays_modified['PlayOutcome'].str.contains('Pass')) &\n",
        "                                                      (week1_2023_plays_modified['PlayDescription'].str.contains('lateral', case=False))]\n",
        "\n",
        "map_passing_penalty_plays = unclean_clean_matches(df_unclean_pass_plays, df_week1_plays_cleaned)\n",
        "\n",
        "for i in map_passing_penalty_plays.keys():\n",
        "  print(f\"({i}, {map_passing_penalty_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "z34rFvI3nK9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01U2No85CuOo"
      },
      "source": [
        "### Rushing plays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CLnY7a5zKLR"
      },
      "outputs": [],
      "source": [
        "# Number of running type plays during 2023, Week 1\n",
        "\n",
        "df_unclean_run_plays = week1_2023_plays_modified.loc[week1_2023_plays_modified['PlayOutcome'].str.contains('Run')]\n",
        "\n",
        "map_run_plays = unclean_clean_matches(df_unclean_run_plays, df_week1_plays_cleaned)\n",
        "\n",
        "len(map_run_plays.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3trhAkLPzjH-"
      },
      "outputs": [],
      "source": [
        "# Every unclean passing play and their associated cleaned play breakdown\n",
        "\n",
        "for i in map_run_plays.keys():\n",
        "  print(f\"({i}, {map_run_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6X0YtJuOmkMH"
      },
      "outputs": [],
      "source": [
        "# penalty rushing plays\n",
        "\n",
        "df_unclean_rush_penalty_plays = week1_2023_plays_modified.loc[(week1_2023_plays_modified['PlayOutcome'].str.contains('Run')) &\n",
        "                                                              (week1_2023_plays_modified['PlayDescription'].str.contains('penalty', case=False))]\n",
        "\n",
        "dict_unclean_rush_penalty_plays = unclean_clean_matches(df_unclean_rush_penalty_plays, df_week1_plays_cleaned)\n",
        "\n",
        "for i in dict_unclean_rush_penalty_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_rush_penalty_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmK9dsi9Vc6O"
      },
      "outputs": [],
      "source": [
        "# fumbled rushing plays (not including touchdowns)\n",
        "\n",
        "df_unclean_rush_fumble_plays = week1_2023_plays_modified.loc[(week1_2023_plays_modified['PlayOutcome'].str.contains('Run')) &\n",
        "                                                             (week1_2023_plays_modified['PlayDescription'].str.contains('fumbles', case=False))]\n",
        "\n",
        "for i in unclean_clean_matches(df_unclean_rush_fumble_plays, df_week1_plays_cleaned).items():\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGNT0pxIWS6l"
      },
      "outputs": [],
      "source": [
        "dict_unclean_to_clean_rush_fumble_plays = unclean_clean_matches(df_unclean_rush_fumble_plays, df_week1_plays_cleaned)\n",
        "\n",
        "for i in dict_unclean_to_clean_rush_fumble_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_rush_fumble_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zLi4gJHb21u"
      },
      "outputs": [],
      "source": [
        "# All rushing touchdowns\n",
        "\n",
        "df_unclean_pass_plays_touchdown = week1_2023_plays_modified.loc[(week1_2023_plays_modified['PlayOutcome'].str.contains('touchdown', case=False))]\n",
        "\n",
        "list_all_touchdown_rushing_plays = []\n",
        "\n",
        "for idx, play in df_unclean_pass_plays_touchdown['PlayDescription'].items():\n",
        "  run_play = re.findall(rusher_pattern, play)\n",
        "  if len(run_play) > 0:\n",
        "    list_all_touchdown_rushing_plays.append(idx)\n",
        "\n",
        "map_rushing_touchdown_plays = unclean_clean_matches(week1_2023_plays_modified.loc[list_all_touchdown_rushing_plays], df_week1_plays_cleaned)\n",
        "\n",
        "for i in map_rushing_touchdown_plays.keys():\n",
        "  print(f\"({i}, {map_rushing_touchdown_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lateral rushing plays\n",
        "\n",
        "df_unclean_rush_penalty_plays = week1_2023_plays_modified.loc[(week1_2023_plays_modified['PlayOutcome'].str.contains('Run')) &\n",
        "                                                              (week1_2023_plays_modified['PlayDescription'].str.contains('lateral', case=False))]\n",
        "\n",
        "dict_unclean_rush_penalty_plays = unclean_clean_matches(df_unclean_rush_penalty_plays, df_week1_plays_cleaned)\n",
        "\n",
        "for i in dict_unclean_rush_penalty_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_rush_penalty_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "nwuVZ4etYSWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMTxhm9K2gY9"
      },
      "source": [
        "###2pt Conversions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhtqlOup2oTR"
      },
      "outputs": [],
      "source": [
        "# All extra point plays\n",
        "\n",
        "df_unclean_2pt_conversion_week1 = week1_2023_plays_modified[week1_2023_plays_modified['PlayOutcome'].str.contains('2PT Conversion')]\n",
        "\n",
        "dict_unclean_to_clean_2ptc = unclean_clean_matches(df_unclean_2pt_conversion_week1, df_week1_plays_cleaned)\n",
        "\n",
        "print(f\"{len(dict_unclean_to_clean_2ptc)} number of 2pt conversion attempts\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_2ptc.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_2ptc.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbasinI35YsM"
      },
      "outputs": [],
      "source": [
        "# All passing 2PT conversion attempts\n",
        "\n",
        "index_pass_2ptc = []\n",
        "\n",
        "for i in list(df_unclean_2pt_conversion_week1.index):\n",
        "  pass_2ptc = re.findall(tp_conversion_pass_pattern, week1_2023_plays_modified['PlayDescription'].iloc[i])\n",
        "  if len(pass_2ptc) > 0:\n",
        "    index_pass_2ptc.append(i)\n",
        "\n",
        "dict_unclean_to_clean_pass_2ptc = unclean_clean_matches(week1_2023_plays_modified.iloc[index_pass_2ptc], df_week1_plays_cleaned)\n",
        "\n",
        "print(f\"{len(dict_unclean_to_clean_pass_2ptc)} number of 2pt conversion pass attempts\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_pass_2ptc.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_pass_2ptc.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIIVcqU-6WzA"
      },
      "outputs": [],
      "source": [
        "# All rushing 2PT conversion attempts\n",
        "\n",
        "index_rush_2ptc = []\n",
        "\n",
        "for i in list(df_unclean_2pt_conversion_week1.index):\n",
        "  rush_2ptc = re.findall(tp_conversion_rush_pattern, week1_2023_plays_modified['PlayDescription'].iloc[i])\n",
        "  if len(rush_2ptc) > 0:\n",
        "    index_rush_2ptc.append(i)\n",
        "\n",
        "dict_unclean_to_clean_rush_2ptc = unclean_clean_matches(week1_2023_plays_modified.iloc[index_rush_2ptc], df_week1_plays_cleaned)\n",
        "\n",
        "print(f\"{len(dict_unclean_to_clean_rush_2ptc)} number of 2pt conversion attempts\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_rush_2ptc.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_rush_2ptc.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56zcEqI4C9NQ"
      },
      "source": [
        "### Intercepted plays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqpFWV9MC-vy"
      },
      "outputs": [],
      "source": [
        "df_unclean_intercepted_plays = week1_2023_plays_modified.loc[(week1_2023_plays_modified['PlayDescription'].str.contains('INTERCEPTED', case=False)) |\n",
        "                                                             (week1_2023_plays_modified['PlayOutcome'].str.contains('Interception', case=False))]\n",
        "\n",
        "dict_unclean_to_clean_intercepted_plays = unclean_clean_matches(df_unclean_intercepted_plays, df_week1_plays_cleaned)\n",
        "\n",
        "for i in dict_unclean_to_clean_intercepted_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_intercepted_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# All interceptions with a penalty\n",
        "\n",
        "df_unclean_intercepted_penalty_plays = week1_2023_plays_modified.loc[(week1_2023_plays_modified['PlayDescription'].str.contains('INTERCEPTED', case=False)) &\n",
        "                                                                    (week1_2023_plays_modified['PlayDescription'].str.contains('PENALTY', case=False))]\n",
        "\n",
        "dict_unclean_to_clean_intercepted_penalty_plays = unclean_clean_matches(df_unclean_intercepted_penalty_plays, df_week1_plays_cleaned)\n",
        "\n",
        "for i in dict_unclean_to_clean_intercepted_penalty_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_intercepted_penalty_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "Xe06imUggp4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "am3SJi6-QssS"
      },
      "outputs": [],
      "source": [
        "# All interceptions resulting in a touchdown\n",
        "\n",
        "df_unclean_intercepted_touchdown_plays = week1_2023_plays_modified.loc[(week1_2023_plays_modified['PlayDescription'].str.contains('INTERCEPTED', case=False)) &\n",
        "                                                                       (week1_2023_plays_modified['PlayOutcome'].str.contains('touchdown', case=False))]\n",
        "\n",
        "dict_unclean_to_clean_intercepted_touchdown_plays = unclean_clean_matches(df_unclean_intercepted_touchdown_plays, df_week1_plays_cleaned)\n",
        "\n",
        "for i in dict_unclean_to_clean_intercepted_touchdown_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_intercepted_touchdown_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F09Qp3xQ9oq9"
      },
      "source": [
        "### Sacked Plays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_sHtdif9taC"
      },
      "outputs": [],
      "source": [
        "df_unclean_sacked_plays = week1_2023_plays_modified.loc[(week1_2023_plays_modified['PlayOutcome'].str.contains('Sack', case=False))]\n",
        "\n",
        "dict_unclean_to_clean_sacked_plays = unclean_clean_matches(df_unclean_sacked_plays, df_week1_plays_cleaned)\n",
        "\n",
        "for i in dict_unclean_to_clean_sacked_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_sacked_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cd5hJRiTNtA8"
      },
      "outputs": [],
      "source": [
        "# All sacked plays resulting in a touchdown\n",
        "\n",
        "df_unclean_sacked_touchdown_plays = week1_2023_plays_modified.loc[(week1_2023_plays_modified['PlayOutcome'].str.contains('touchdown', case=False)) &\n",
        "                                                                  (week1_2023_plays_modified['PlayDescription'].str.contains('sack', case=False))]\n",
        "\n",
        "dict_unclean_to_clean_sacked_touchdown_plays = unclean_clean_matches(df_unclean_sacked_touchdown_plays, df_week1_plays_cleaned)\n",
        "\n",
        "for i in dict_unclean_to_clean_sacked_touchdown_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_sacked_touchdown_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OQ37qpPhCPo"
      },
      "outputs": [],
      "source": [
        "# All sacked plays resulting in a fumble\n",
        "\n",
        "df_unclean_sacked_fumble_plays = week1_2023_plays_modified.loc[(week1_2023_plays_modified['PlayDescription'].str.contains('sack', case=False)) &\n",
        "                                                                  (week1_2023_plays_modified['PlayDescription'].str.contains('fumbles', case=False))]\n",
        "\n",
        "dict_unclean_to_clean_sacked_fumble_plays = unclean_clean_matches(df_unclean_sacked_fumble_plays, df_week1_plays_cleaned)\n",
        "\n",
        "for i in dict_unclean_to_clean_sacked_fumble_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_sacked_fumble_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# All sacked plays with a penalty\n",
        "\n",
        "df_unclean_sacked_penalty_plays = week1_2023_plays_modified.loc[(week1_2023_plays_modified['PlayDescription'].str.contains('sack', case=False)) &\n",
        "                                                                  (week1_2023_plays_modified['PlayDescription'].str.contains('penalty', case=False))]\n",
        "\n",
        "dict_unclean_to_clean_sacked_penalty_plays = unclean_clean_matches(df_unclean_sacked_penalty_plays, df_week1_plays_cleaned)\n",
        "\n",
        "for i in dict_unclean_to_clean_sacked_penalty_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_sacked_penalty_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "7jr0FD3CSRHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMM5uVTFyDYu"
      },
      "source": [
        "### Punt Plays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tm2bsr5GyClu"
      },
      "outputs": [],
      "source": [
        "df_unclean_punt_plays = week1_2023_plays_modified.loc[week1_2023_plays_modified['PlayDescription'].str.contains('punts', case=False)]\n",
        "\n",
        "dict_unclean_to_clean_punt_plays = unclean_clean_matches(df_unclean_punt_plays, df_week1_plays_cleaned)\n",
        "\n",
        "for i in dict_unclean_to_clean_punt_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_punt_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Punts that have penalties\n",
        "\n",
        "df_punt_penalty_plays = week1_2023_plays_modified.loc[(week1_2023_plays_modified['PlayDescription'].str.contains('punts', case=False)) &\n",
        "                                                      (week1_2023_plays_modified['PlayDescription'].str.contains('penalty', case=False))]\n",
        "\n",
        "dict_unclean_to_clean_punt_penalty_plays = unclean_clean_matches(df_punt_penalty_plays, df_week1_plays_cleaned)\n",
        "\n",
        "for i in dict_unclean_to_clean_punt_penalty_plays.keys():\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_check = re.findall(punt_return_pattern, play)\n",
        "  if len(play_check) > 0:\n",
        "    print(f\"({i}, {dict_unclean_to_clean_punt_penalty_plays.get(i)})\")\n",
        "    play_split = play.split(\". \")\n",
        "    for j in play_split:\n",
        "      print(j)\n",
        "    print()"
      ],
      "metadata": {
        "id": "YgFNt49vcplk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G61pNfiuMBs8"
      },
      "outputs": [],
      "source": [
        "# All punt return touchdown plays\n",
        "\n",
        "df_unclean_punt_touchdown_plays = week1_2023_plays_modified.loc[week1_2023_plays_modified['PlayDescription'].str.contains('punts', case=False) &\n",
        "                                                                week1_2023_plays_modified['PlayDescription'].str.contains('touchdown', case=False)]\n",
        "\n",
        "dict_unclean_to_clean_punt_touchdown_plays = unclean_clean_matches(df_unclean_punt_touchdown_plays, df_week1_plays_cleaned)\n",
        "\n",
        "for i in dict_unclean_to_clean_punt_touchdown_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_punt_touchdown_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-sl_mhsaHWQ"
      },
      "source": [
        "### Kickoffs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3xyxhdmaJNJ"
      },
      "outputs": [],
      "source": [
        "# All kickoff plays\n",
        "\n",
        "df_unclean_kickoff_plays = week1_2023_plays_modified.loc[week1_2023_plays_modified['PlayOutcome'].str.contains('kickoff', case=False)]\n",
        "\n",
        "dict_unclean_to_clean_kickoff_plays = unclean_clean_matches(df_unclean_kickoff_plays, df_week1_plays_cleaned)\n",
        "\n",
        "for i in dict_unclean_to_clean_kickoff_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_kickoff_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNwyWsNpxZoC"
      },
      "outputs": [],
      "source": [
        "# All onside kicks\n",
        "\n",
        "df_unclean_kickoff_onside_plays = week1_2023_plays_modified.loc[week1_2023_plays_modified['PlayOutcome'].str.contains('kickoff', case=False) &\n",
        "                                                                week1_2023_plays_modified['PlayDescription'].str.contains('onside', case=False)]\n",
        "\n",
        "dict_unclean_to_clean_kickoff_onside_plays = unclean_clean_matches(df_unclean_kickoff_onside_plays, df_week1_plays_cleaned)\n",
        "\n",
        "for i in dict_unclean_to_clean_kickoff_onside_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_kickoff_onside_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCJ0f1_cpJ_K"
      },
      "outputs": [],
      "source": [
        "# All kickoff fumble plays\n",
        "\n",
        "df_unclean_kickoff_fumble_plays = week1_2023_plays_modified.loc[(week1_2023_plays_modified['PlayDescription'].str.contains('kicks', case=False)) &\n",
        "                                                                (week1_2023_plays_modified['PlayDescription'].str.contains('fumble', case=False))]\n",
        "\n",
        "dict_unclean_to_clean_kickoff_plays = unclean_clean_matches(df_unclean_kickoff_fumble_plays, df_week1_plays_cleaned)\n",
        "\n",
        "for i in dict_unclean_to_clean_kickoff_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_kickoff_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3i6ytmPQ5463"
      },
      "source": [
        "### Touchdown plays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSyeKr6X596o"
      },
      "outputs": [],
      "source": [
        "# All touchdown plays\n",
        "\n",
        "df_unclean_touchdown_plays = week1_2023_plays_modified.loc[week1_2023_plays_modified['PlayOutcome'].str.contains('touchdown', case=False)]\n",
        "\n",
        "dict_unclean_to_clean_touchdown_plays = unclean_clean_matches(df_unclean_touchdown_plays, df_week1_plays_cleaned)\n",
        "\n",
        "for i in dict_unclean_to_clean_touchdown_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_touchdown_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btd2EUHxtbL2"
      },
      "source": [
        "### Field goals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqBe7NSa3Jlx"
      },
      "outputs": [],
      "source": [
        "# All field goal plays\n",
        "\n",
        "df_unclean_fieldgoal_week1 = week1_2023_plays_modified[week1_2023_plays_modified['PlayOutcome'].str.contains('Field Goal')]\n",
        "\n",
        "dict_unclean_to_clean_field_goal_plays = unclean_clean_matches(df_unclean_fieldgoal_week1, df_week1_plays_cleaned)\n",
        "\n",
        "# Number of field goal plays\n",
        "print(f\"{len(dict_unclean_to_clean_field_goal_plays)} number of field goal plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_field_goal_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_field_goal_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gji9ZboHcBQV"
      },
      "outputs": [],
      "source": [
        "# All field goal plays (good)\n",
        "\n",
        "made_field_goal_play_indexes = []\n",
        "\n",
        "for i in list(df_2023_fieldgoal_week1.index):\n",
        "  made_field_goal = re.findall(field_goal_good_pattern, week1_2023_plays_modified['PlayDescription'].iloc[i])\n",
        "  if len(made_field_goal) > 0:\n",
        "    made_field_goal_play_indexes.append(i)\n",
        "\n",
        "dict_unclean_to_clean_good_field_goals = unclean_clean_matches(week1_2023_plays_modified.iloc[made_field_goal_play_indexes], df_week1_plays_cleaned)\n",
        "\n",
        "# Number of field goal plays\n",
        "print(f\"{len(dict_unclean_to_clean_good_field_goals)} number of good field goal plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_good_field_goals.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_good_field_goals.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-P5Mz-AfdgxC"
      },
      "outputs": [],
      "source": [
        "# All field goal plays (no good)\n",
        "\n",
        "no_good_field_goal_play_indexes = []\n",
        "\n",
        "for i in list(df_2023_fieldgoal_week1.index):\n",
        "  made_field_goal = re.findall(field_goal_no_good_pattern, week1_2023_plays_modified['PlayDescription'].iloc[i])\n",
        "  if len(made_field_goal) > 0:\n",
        "    no_good_field_goal_play_indexes.append(i)\n",
        "\n",
        "dict_unclean_to_clean_no_good_field_goals = unclean_clean_matches(week1_2023_plays_modified.iloc[no_good_field_goal_play_indexes], df_week1_plays_cleaned)\n",
        "\n",
        "# Number of field goal plays\n",
        "print(f\"{len(dict_unclean_to_clean_no_good_field_goals)} number of no good field goal plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_no_good_field_goals.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_no_good_field_goals.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-vMwKQWgN27"
      },
      "outputs": [],
      "source": [
        "# All field goal plays (special)\n",
        "\n",
        "special_field_goal_play_indexes = []\n",
        "\n",
        "special_field_goal_play_indexes = list(df_2023_fieldgoal_week1.index)\n",
        "\n",
        "for i in made_field_goal_play_indexes:\n",
        "  special_field_goal_play_indexes.pop(special_field_goal_play_indexes.index(i))\n",
        "\n",
        "for i in no_good_field_goal_play_indexes:\n",
        "  special_field_goal_play_indexes.pop(special_field_goal_play_indexes.index(i))\n",
        "\n",
        "\n",
        "dict_unclean_to_clean_special_field_goals = unclean_clean_matches(week1_2023_plays_modified.iloc[special_field_goal_play_indexes], df_week1_plays_cleaned)\n",
        "\n",
        "# Number of field goal plays\n",
        "print(f\"{len(dict_unclean_to_clean_special_field_goals)} number of special field goal plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_special_field_goals.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_special_field_goals.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHp6b-_SqOw_"
      },
      "source": [
        "### Extra Points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzJ6erNaqT9s"
      },
      "outputs": [],
      "source": [
        "# All extra point plays\n",
        "\n",
        "df_unclean_extrapoint_week1 = week1_2023_plays_modified[week1_2023_plays_modified['PlayOutcome'].str.contains('Extra Point')]\n",
        "\n",
        "dict_unclean_to_clean_extrapoint = unclean_clean_matches(df_unclean_extrapoint_week1, df_week1_plays_cleaned)\n",
        "\n",
        "print(f\"{len(dict_unclean_to_clean_extrapoint)} number of field goal plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_extrapoint.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_extrapoint.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vt8dClZ3r6mL"
      },
      "outputs": [],
      "source": [
        "# All extra point plays (good)\n",
        "\n",
        "extra_point_good_index_list = []\n",
        "\n",
        "for i in list(df_2023_extrapoint_week1.index):\n",
        "  made_extra_point = re.findall(extra_point_good_pattern, week1_2023_plays_modified['PlayDescription'].iloc[i])\n",
        "  if len(made_extra_point) > 0:\n",
        "    extra_point_good_index_list.append(i)\n",
        "\n",
        "dict_unclean_to_clean_extrapoint_good = unclean_clean_matches(week1_2023_plays_modified.iloc[extra_point_good_index_list], df_week1_plays_cleaned)\n",
        "\n",
        "print(f\"{len(dict_unclean_to_clean_extrapoint_good)} number of field goal plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_extrapoint_good.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_extrapoint_good.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8lRaoqjt_ap"
      },
      "outputs": [],
      "source": [
        "# All extra point plays (no good)\n",
        "\n",
        "extra_point_no_good_index_list = []\n",
        "\n",
        "for i in list(df_2023_extrapoint_week1.index):\n",
        "  no_good_extra_point = re.findall(extra_point_no_good_pattern, week1_2023_plays_modified['PlayDescription'].iloc[i])\n",
        "  if len(no_good_extra_point) > 0:\n",
        "    extra_point_no_good_index_list.append(i)\n",
        "\n",
        "dict_unclean_to_clean_extrapoint_no_good = unclean_clean_matches(week1_2023_plays_modified.iloc[extra_point_no_good_index_list], df_week1_plays_cleaned)\n",
        "\n",
        "print(f\"{len(dict_unclean_to_clean_extrapoint_no_good)} number of field goal plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_extrapoint_no_good.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_extrapoint_no_good.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tEwEZbeu_dl"
      },
      "outputs": [],
      "source": [
        "# Blocked extra point?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGd9pIPpvtL2"
      },
      "source": [
        "### Fumbles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ND23U1givw4y"
      },
      "outputs": [],
      "source": [
        "# All fumbled plays\n",
        "\n",
        "# recovered = offense recovered the ball\n",
        "# RECOVERED = defense recovered the ball\n",
        "# and recovers = QB recovered the ball (Or whoever initially fumbled the ball)\n",
        "\n",
        "df_unclean_fumble_plays = week1_2023_plays_modified.loc[(week1_2023_plays_modified['PlayOutcome'].str.contains('fumble', case=False)) |\n",
        "                                                        (week1_2023_plays_modified['PlayDescription'].str.contains('fumble', case=False))]\n",
        "\n",
        "dict_unclean_to_clean_fumble_plays = unclean_clean_matches(df_unclean_fumble_plays, df_week1_plays_cleaned)\n",
        "\n",
        "print(f\"{len(dict_unclean_to_clean_fumble_plays)} number of fumbled plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_fumble_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_fumble_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmW0-6AQCRWB"
      },
      "outputs": [],
      "source": [
        "# All passing fumble plays\n",
        "\n",
        "index_fumble_pass_plays = []\n",
        "\n",
        "for i in list(df_unclean_fumble_plays.index):\n",
        "  fumble_pass = re.findall(receiver_pattern, week1_2023_plays_modified['PlayDescription'].iloc[i])\n",
        "  if len(fumble_pass) > 0:\n",
        "    index_fumble_pass_plays.append(i)\n",
        "\n",
        "dict_unclean_to_clean_fumble_pass = unclean_clean_matches(week1_2023_plays_modified.iloc[index_fumble_pass_plays], df_week1_plays_cleaned)\n",
        "\n",
        "print(f\"{len(dict_unclean_to_clean_fumble_pass)} number of passing fumble plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_fumble_pass.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_fumble_pass.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lk810wiLm9R"
      },
      "outputs": [],
      "source": [
        "# All rushing fumble plays\n",
        "\n",
        "index_fumble_run_plays = []\n",
        "\n",
        "for i in list(df_unclean_fumble_plays.index):\n",
        "  fumble_pass = re.findall(rusher_pattern, week1_2023_plays_modified['PlayDescription'].iloc[i])\n",
        "  if len(fumble_pass) > 0:\n",
        "    index_fumble_run_plays.append(i)\n",
        "\n",
        "dict_unclean_to_clean_fumble_run = unclean_clean_matches(week1_2023_plays_modified.iloc[index_fumble_run_plays], df_week1_plays_cleaned)\n",
        "\n",
        "print(f\"{len(dict_unclean_to_clean_fumble_run)} number of rushing fumble plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_fumble_run.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_fumble_run.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNczGRV1OXrc"
      },
      "outputs": [],
      "source": [
        "# All sacked fumble plays\n",
        "\n",
        "index_fumble_sacked_plays = []\n",
        "\n",
        "for i in list(df_unclean_fumble_plays.index):\n",
        "  if week1_2023_plays_modified['PlayDescription'].iloc[i].find('sacked') != -1:\n",
        "    index_fumble_sacked_plays.append(i)\n",
        "\n",
        "dict_unclean_to_clean_sacked_fumble = unclean_clean_matches(week1_2023_plays_modified.iloc[index_fumble_sacked_plays], df_week1_plays_cleaned)\n",
        "\n",
        "print(f\"{len(dict_unclean_to_clean_sacked_fumble)} number of sacked fumble plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_sacked_fumble.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_sacked_fumble.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2wwjFbnMiL3"
      },
      "outputs": [],
      "source": [
        "# All Aborted fumbled plays\n",
        "\n",
        "# week1_2023_plays['PlayOutcome'].str.contains('fumble', case=False)\n",
        "\n",
        "index_fumble_aborted_plays = []\n",
        "\n",
        "for i in list(df_unclean_fumble_plays.index):\n",
        "  if week1_2023_plays_modified['PlayDescription'].iloc[i].find('Aborted') != -1:\n",
        "    index_fumble_aborted_plays.append(i)\n",
        "\n",
        "dict_unclean_to_clean_aborted_fumble = unclean_clean_matches(week1_2023_plays_modified.iloc[index_fumble_aborted_plays], df_week1_plays_cleaned)\n",
        "\n",
        "print(f\"{len(dict_unclean_to_clean_aborted_fumble)} number of aborted fumble plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_aborted_fumble.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_aborted_fumble.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iADR1LRbMaUg"
      },
      "outputs": [],
      "source": [
        "# All special fumbled plays\n",
        "\n",
        "index_fumble_special_plays = list(df_unclean_fumble_plays.index)\n",
        "\n",
        "for i in index_fumble_pass_plays:\n",
        "  index_fumble_special_plays.pop(index_fumble_special_plays.index(i))\n",
        "\n",
        "for i in index_fumble_run_plays:\n",
        "  index_fumble_special_plays.pop(index_fumble_special_plays.index(i))\n",
        "\n",
        "for i in index_fumble_sacked_plays:\n",
        "  index_fumble_special_plays.pop(index_fumble_special_plays.index(i))\n",
        "\n",
        "for i in index_fumble_aborted_plays:\n",
        "  index_fumble_special_plays.pop(index_fumble_special_plays.index(i))\n",
        "\n",
        "dict_unclean_to_clean_fumble_special = unclean_clean_matches(week1_2023_plays_modified.iloc[index_fumble_special_plays], df_week1_plays_cleaned)\n",
        "\n",
        "print(f\"{len(dict_unclean_to_clean_fumble_special)} number of special fumble plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_fumble_special.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_fumble_special.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh-8uXf-lvh1"
      },
      "source": [
        "### Penalties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHVJ2VCGlz15"
      },
      "outputs": [],
      "source": [
        "# What is the difference between these penalties and penalties in other play outcomes?\n",
        "\n",
        "# All plays with \"penalty\" outcomes\n",
        "\n",
        "df_unclean_penalty_plays = week1_2023_plays_modified.loc[week1_2023_plays_modified['PlayOutcome'].str.contains('penalty', case=False)]\n",
        "\n",
        "dict_unclean_to_clean_penalty_plays = unclean_clean_matches(df_unclean_penalty_plays, df_week1_plays_cleaned)\n",
        "\n",
        "# Number of penalty plays\n",
        "print(f\"{len(df_unclean_penalty_plays)} number of penalty plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_penalty_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_penalty_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZSjt3sOAiGp"
      },
      "outputs": [],
      "source": [
        "# All passing plays with \"penalty\" outcomes\n",
        "\n",
        "# Grabbing all penalty plays within original dataframe\n",
        "df_unclean_penalty_plays = week1_2023_plays_modified.loc[week1_2023_plays_modified['PlayOutcome'].str.contains('penalty', case=False)]\n",
        "\n",
        "# List for all indexes that are passing play type penalty plays\n",
        "list_unclean_penalty_passing_plays = []\n",
        "\n",
        "for idx, play in df_unclean_penalty_plays['PlayDescription'].items():\n",
        "  passing_play = re.findall(receiver_pattern, play)\n",
        "  if len(passing_play) > 0 or play.find('pass incomplete') != -1:\n",
        "    list_unclean_penalty_passing_plays.append(idx)\n",
        "\n",
        "# Dataframe of all passing plays with \"penalty\" outcomes\n",
        "df_unclean_penalty_passing_plays = week1_2023_plays_modified.iloc[list_unclean_penalty_passing_plays]\n",
        "\n",
        "dict_unclean_to_clean_penalty_passing_plays = unclean_clean_matches(df_unclean_penalty_passing_plays, df_week1_plays_cleaned)\n",
        "\n",
        "# Number of passing penalty plays\n",
        "print(f\"{len(list_unclean_penalty_passing_plays)} number of passing penalty plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_penalty_passing_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_penalty_passing_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Qpv1m_vL25t"
      },
      "outputs": [],
      "source": [
        "# All rushing plays with \"penalty\" outcomes\n",
        "\n",
        "# Grabbing all penalty plays within original dataframe\n",
        "df_unclean_penalty_plays = week1_2023_plays_modified.loc[week1_2023_plays_modified['PlayOutcome'].str.contains('penalty', case=False)]\n",
        "\n",
        "# List for all indexes that are passing play type penalty plays\n",
        "list_unclean_penalty_rushing_plays = []\n",
        "\n",
        "for idx, play in df_unclean_penalty_plays['PlayDescription'].items():\n",
        "  rushing_play = re.findall(rusher_pattern, play)\n",
        "  if len(rushing_play) > 0 or play.find('Aborted') != -1:\n",
        "    list_unclean_penalty_rushing_plays.append(idx)\n",
        "\n",
        "# Dataframe of all passing plays with \"penalty\" outcomes\n",
        "df_unclean_penalty_rushing_plays = week1_2023_plays_modified.iloc[list_unclean_penalty_rushing_plays]\n",
        "\n",
        "dict_unclean_to_clean_penalty_rushing_plays = unclean_clean_matches(df_unclean_penalty_rushing_plays, df_week1_plays_cleaned)\n",
        "\n",
        "# Number of rushing penalty plays\n",
        "print(f\"{len(list_unclean_penalty_rushing_plays)} number of passing penalty plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_penalty_rushing_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_penalty_rushing_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30VBAHc2llk_"
      },
      "outputs": [],
      "source": [
        "# All \"False Start\" or \"Delay of Game\" plays with \"penalty\" outcomes\n",
        "\n",
        "# Grabbing all penalty plays within original dataframe\n",
        "df_unclean_penalty_plays = week1_2023_plays_modified.loc[week1_2023_plays_modified['PlayOutcome'].str.contains('penalty', case=False)]\n",
        "\n",
        "# List for all indexes that are passing play type penalty plays\n",
        "list_unclean_penalty_false_start_plays = []\n",
        "\n",
        "for idx, play in df_unclean_penalty_plays['PlayDescription'].items():\n",
        "  if play.find('False Start') != -1 or play.find('Delay of Game') != -1:\n",
        "    list_unclean_penalty_false_start_plays.append(idx)\n",
        "\n",
        "dict_unclean_to_clean_penalty_false_start_plays = unclean_clean_matches(week1_2023_plays_modified.iloc[list_unclean_penalty_false_start_plays], df_week1_plays_cleaned)\n",
        "\n",
        "# Number of rushing penalty plays\n",
        "print(f\"{len(list_unclean_penalty_false_start_plays)} number of false start plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_penalty_false_start_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_penalty_false_start_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMVplg6mfw6v"
      },
      "outputs": [],
      "source": [
        "# All sacked plays with \"penalty\" outcomes\n",
        "\n",
        "# Grabbing all penalty plays within original dataframe\n",
        "df_unclean_penalty_plays = week1_2023_plays_modified.loc[week1_2023_plays_modified['PlayOutcome'].str.contains('penalty', case=False)]\n",
        "\n",
        "# List for all indexes that are passing play type penalty plays\n",
        "list_unclean_penalty_sacked_plays = []\n",
        "\n",
        "for idx, play in df_unclean_penalty_plays['PlayDescription'].items():\n",
        "  if play.find('sacked') != -1:\n",
        "    list_unclean_penalty_sacked_plays.append(idx)\n",
        "\n",
        "dict_unclean_to_clean_penalty_sacked_plays = unclean_clean_matches(week1_2023_plays_modified.iloc[list_unclean_penalty_sacked_plays], df_week1_plays_cleaned)\n",
        "\n",
        "# Number of rushing penalty plays\n",
        "print(f\"{len(list_unclean_penalty_sacked_plays)} number of false start plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_penalty_sacked_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_penalty_sacked_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEH-KU0arHXT"
      },
      "outputs": [],
      "source": [
        "# All TWO-POINT CONVERSION ATTEMPT plays with \"penalty\" outcomes\n",
        "\n",
        "# Grabbing all penalty plays within original dataframe\n",
        "df_unclean_penalty_plays = week1_2023_plays_modified.loc[week1_2023_plays_modified['PlayOutcome'].str.contains('penalty', case=False)]\n",
        "\n",
        "# List for all indexes that are passing play type penalty plays\n",
        "list_unclean_penalty_2pt_plays = []\n",
        "\n",
        "for idx, play in df_unclean_penalty_plays['PlayDescription'].items():\n",
        "  rushing_play = re.findall(rusher_pattern, play)\n",
        "  if play.find('TWO-POINT CONVERSION ATTEMPT') != -1 and len(rushing_play) == 0:\n",
        "    list_unclean_penalty_2pt_plays.append(idx)\n",
        "\n",
        "dict_unclean_to_clean_penalty_2pt_plays = unclean_clean_matches(week1_2023_plays_modified.iloc[list_unclean_penalty_2pt_plays], df_week1_plays_cleaned)\n",
        "\n",
        "# Number of rushing penalty plays\n",
        "print(f\"{len(list_unclean_penalty_2pt_plays)} number of false start plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_penalty_2pt_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_penalty_2pt_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIrreRJvMffs"
      },
      "outputs": [],
      "source": [
        "# All special plays with \"penalty\" outcomes\n",
        "\n",
        "# Grabbing all penalty plays within original dataframe\n",
        "df_unclean_penalty_plays = week1_2023_plays_modified.loc[week1_2023_plays_modified['PlayOutcome'].str.contains('penalty', case=False)]\n",
        "\n",
        "# List for all indexes that are passing play type penalty plays\n",
        "list_unclean_penalty_special_plays = list(df_unclean_penalty_plays.index)\n",
        "\n",
        "for i in list_unclean_penalty_passing_plays:\n",
        "  list_unclean_penalty_special_plays.pop(list_unclean_penalty_special_plays.index(i))\n",
        "\n",
        "for i in list_unclean_penalty_rushing_plays:\n",
        "  list_unclean_penalty_special_plays.pop(list_unclean_penalty_special_plays.index(i))\n",
        "\n",
        "for i in list_unclean_penalty_false_start_plays:\n",
        "  list_unclean_penalty_special_plays.pop(list_unclean_penalty_special_plays.index(i))\n",
        "\n",
        "for i in list_unclean_penalty_sacked_plays:\n",
        "  list_unclean_penalty_special_plays.pop(list_unclean_penalty_special_plays.index(i))\n",
        "\n",
        "for i in list_unclean_penalty_2pt_plays:\n",
        "  list_unclean_penalty_special_plays.pop(list_unclean_penalty_special_plays.index(i))\n",
        "\n",
        "dict_unclean_to_clean_penalty_special_plays = unclean_clean_matches(week1_2023_plays_modified.iloc[list_unclean_penalty_special_plays], df_week1_plays_cleaned)\n",
        "\n",
        "# Number of rushing penalty plays\n",
        "print(f\"{len(list_unclean_penalty_special_plays)} number of special penalty plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_penalty_special_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_penalty_special_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# All interceptions with some type of penalty\n",
        "\n",
        "df_unclean_penalty_plays = week1_2023_plays_modified.loc[(week1_2023_plays_modified['PlayOutcome'].str.contains('penalty', case=False)) &\n",
        "                                                         (week1_2023_plays_modified['PlayDescription'].str.contains('interception', case=False))]\n",
        "\n",
        "dict_unclean_to_clean_penalty_plays = unclean_clean_matches(df_unclean_penalty_plays, df_week1_plays_cleaned)\n",
        "\n",
        "# Number of penalty plays\n",
        "print(f\"{len(df_unclean_penalty_plays)} number of penalty plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_penalty_plays.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_penalty_plays.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ],
      "metadata": {
        "id": "FIvkF94ST2KC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4cK_IySHwL3"
      },
      "source": [
        "### Turnover On Downs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jlEnCQ0H1PV"
      },
      "outputs": [],
      "source": [
        "# All turnover on downs\n",
        "\n",
        "df_unclean_turnover_on_downs_week1 = week1_2023_plays_modified[week1_2023_plays_modified['PlayOutcome'].str.contains('Turnover on Downs')]\n",
        "\n",
        "dict_unclean_to_clean_turnover_on_downs = unclean_clean_matches(df_unclean_turnover_on_downs_week1, df_week1_plays_cleaned)\n",
        "\n",
        "print(f\"{len(dict_unclean_to_clean_turnover_on_downs)} number of field goal plays\")\n",
        "print(\"\\n\\n\")\n",
        "for i in dict_unclean_to_clean_turnover_on_downs.keys():\n",
        "  print(f\"({i}, {dict_unclean_to_clean_turnover_on_downs.get(i)})\")\n",
        "  play = week1_2023_plays_modified['PlayDescription'].iloc[i]\n",
        "  play_split = play.split(\". \")\n",
        "  for j in play_split:\n",
        "    print(j)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdoApDwkC6RV"
      },
      "source": [
        "## Index searching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXLWIM32UKmR"
      },
      "outputs": [],
      "source": [
        "week1_2023_plays_modified['PlayDescription'].iloc[1196]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gn363g0xpdHH"
      },
      "outputs": [],
      "source": [
        "df_week2_plays_cleaned.iloc[1097]\n",
        "# week1_2023_plays_modified.iloc[1943]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrudwcGMsfXh"
      },
      "source": [
        "# CLEANED DATASET OBSERVATIONS\n",
        "- Attempting to grab basic stats on players for a single game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGpFgVAxl6Zd"
      },
      "source": [
        "## Helper Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPch-YQYl9it"
      },
      "outputs": [],
      "source": [
        "# Get rid of duplicate rows (for play's that have multiple rows)\n",
        "\n",
        "def no_duplicates(df_with_duplicates, index_start=None):\n",
        "\n",
        "  # exit case\n",
        "  # - The last element has been grabbed\n",
        "  if df_with_duplicates.tail(1).index[0] == index_start:\n",
        "    return df_with_duplicates\n",
        "\n",
        "  if index_start == None:\n",
        "    index_start = df_with_duplicates.index[0]\n",
        "\n",
        "  first_element = df_with_duplicates.loc[index_start]\n",
        "\n",
        "  second_element = df_with_duplicates.iloc[df_with_duplicates.index.tolist().index(index_start)+1]\n",
        "\n",
        "  # Features that will decipher whether the two rows are apart of the same play\n",
        "  # matching_features = ['Season', 'Week', 'Date', 'AwayTeam', 'HomeTeam', 'Quarter', 'DriveNumber', 'TeamWithPossession', 'PlayNumberInDrive']\n",
        "  matching_features = ['Season', 'Week', 'Date', 'AwayTeam', 'HomeTeam', 'Quarter', 'DriveNumber', 'PlayNumberInDrive']\n",
        "\n",
        "  # - Check to see if 1st and 2nd elements are match\n",
        "  if first_element[matching_features].equals(second_element[matching_features]):\n",
        "    # 1. remove 2nd element\n",
        "    df_with_duplicates = df_with_duplicates.drop(df_with_duplicates.index[df_with_duplicates.index.tolist().index(index_start)+1], inplace=False)\n",
        "    # 2. run method starting search from 1st element\n",
        "    #    - This is in case more matches to 1st element\n",
        "    return no_duplicates(df_with_duplicates, index_start)\n",
        "  else:\n",
        "    # 1. run method starting search from 2nd element\n",
        "    #    - 2nd element will become '1st element'\n",
        "    #    - after 2nd element will become '2nd element'\n",
        "    return no_duplicates(df_with_duplicates, df_with_duplicates.index[df_with_duplicates.index.tolist().index(index_start)+1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IADrQKYwERwz"
      },
      "source": [
        "**Table Creation**\n",
        "- Goal is to mirror tables on NFL.com for testing purposes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DeKkFFpqIAD"
      },
      "outputs": [],
      "source": [
        "# Display the scoring table for a specified game.\n",
        "\n",
        "def score_table(away_team, home_team, df_cleaned_plays, dict_of_teams):\n",
        "  df_all_plays_in_game = df_cleaned_plays.loc[(df_cleaned_plays['HomeTeam'] == home_team) &\n",
        "                                              (df_cleaned_plays['AwayTeam'] == away_team)]\n",
        "\n",
        "  df_all_plays_in_game = no_duplicates(df_all_plays_in_game)\n",
        "\n",
        "  teams = [[away_team],[home_team]]\n",
        "\n",
        "  for i in range(len(teams)):\n",
        "    total_score = 0\n",
        "    for quarter in df_all_plays_in_game['Quarter'].unique():\n",
        "      quarter_score = 0\n",
        "\n",
        "      # touchdowns\n",
        "      df_touchdowns_in_quarter = df_all_plays_in_game.loc[(df_all_plays_in_game['PlayOutcome'].str.contains(f'touchdown {teams[i][0]}', case=False)) &\n",
        "                                                          (df_all_plays_in_game['Quarter'] == quarter)]\n",
        "      quarter_score += df_touchdowns_in_quarter.shape[0] * 6\n",
        "\n",
        "      # PAT\n",
        "      df_extra_points_in_quarter = df_all_plays_in_game.loc[(df_all_plays_in_game['PlayOutcome'].str.contains('Extra Point Good', case=False)) &\n",
        "                                                            (df_all_plays_in_game['Quarter'] == quarter) &\n",
        "                                                            (df_all_plays_in_game['TeamWithPossession'] == dict_of_teams.get(teams[i][0]))]\n",
        "      quarter_score += df_extra_points_in_quarter.shape[0] * 1\n",
        "\n",
        "      # field goals\n",
        "      df_field_goals_in_quarter = df_all_plays_in_game.loc[(df_all_plays_in_game['PlayOutcome'].str.contains('Field Goal Good', case = False)) &\n",
        "                                                          (df_all_plays_in_game['Quarter'] == quarter) &\n",
        "                                                          (df_all_plays_in_game['TeamWithPossession'] == dict_of_teams.get(teams[i][0]))]\n",
        "      quarter_score += df_field_goals_in_quarter.shape[0] * 3\n",
        "\n",
        "      # 2 Pt Conversions\n",
        "      df_two_pt = df_all_plays_in_game.loc[(df_all_plays_in_game['PlayOutcome'].str.contains('2PT Conversion Success', case=False)) &\n",
        "                                           (df_all_plays_in_game['Quarter'] == quarter) &\n",
        "                                           (df_all_plays_in_game['TeamWithPossession'] == dict_of_teams.get(teams[i][0]))]\n",
        "      quarter_score += df_two_pt.shape[0] * 2\n",
        "\n",
        "      teams[i].append(quarter_score)\n",
        "      total_score += quarter_score\n",
        "\n",
        "    teams[i].append(total_score)\n",
        "    teams[i].pop(0)\n",
        "\n",
        "  scoring_columns = df_all_plays_in_game['Quarter'].unique().tolist()\n",
        "\n",
        "  scoring_columns.append(\"Total\")\n",
        "\n",
        "  return pd.DataFrame(teams, columns = scoring_columns, index=[dict_of_teams.get(away_team), dict_of_teams.get(home_team)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "INDEX:\n",
        "- Each quarterback that played in game\n",
        "COLUMNS:\n",
        "- CP/ATT - completions / pass attempts\n",
        "- YDS - total passing yards\n",
        "- TD - total touchdowns thrown\n",
        "- INT - total interceptions thrown"
      ],
      "metadata": {
        "id": "EY3sUpVM6lP5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HltCrmDut2pV"
      },
      "outputs": [],
      "source": [
        "# Display quarterback stats for a specified game\n",
        "\n",
        "# def passing_table(away_team, home_team, df_cleaned_plays, dict_acronym_to_team):\n",
        "def passing_table(away_team, home_team, df_cleaned_plays, dict_acronym_to_team, home_or_away):\n",
        "\n",
        "\n",
        "  # User decides which receiving table they want (home or away)\n",
        "  if home_or_away == 0:\n",
        "    team = home_team\n",
        "  elif home_or_away == 1:\n",
        "    team = away_team\n",
        "  else:\n",
        "    return \"home_or_away parameter should be a 0 or 1. (home = 0, away = 1)\"\n",
        "\n",
        "  # All plays within game\n",
        "  df_all_plays_in_game = df_cleaned_plays.loc[(df_cleaned_plays['HomeTeam'] == home_team) &\n",
        "                                              (df_cleaned_plays['AwayTeam'] == away_team)]\n",
        "\n",
        "  # list of quarterbacks in game\n",
        "  list_qbs = df_all_plays_in_game['Passer'].unique().tolist()\n",
        "  if 'nan' in list_qbs:\n",
        "    list_qbs.pop(list_qbs.index('nan'))\n",
        "\n",
        "  #   key: quarterback\n",
        "  # value: team\n",
        "  dict_qbs_to_team = {}\n",
        "  for qb in list_qbs:\n",
        "    dict_qbs_to_team[qb] = dict_acronym_to_team.get(df_all_plays_in_game['TeamWithPossession'].loc[df_all_plays_in_game['Passer'] == qb].value_counts().index[0])\n",
        "\n",
        "  # Filtering 'dict_qbs_to_team'\n",
        "  #   key: quarterback(s) from desired team\n",
        "  # value: team\n",
        "  dict_qbs_to_team = {k:v for k,v in dict_qbs_to_team.items() if v == team}\n",
        "\n",
        "  df_quarterback_data = pd.DataFrame(columns=[\"CP/ATT\", \"YDS\", \"TD\", \"INT\"], index = list(dict_qbs_to_team.keys()))\n",
        "\n",
        "  # Grabbing data for each quarterback in game\n",
        "  for qb in df_quarterback_data.index:\n",
        "\n",
        "    passing_attempts = df_all_plays_in_game.loc[(df_all_plays_in_game['Passer'] == qb) &\n",
        "                                                (df_all_plays_in_game['PlayType'] == \"Pass\")]\n",
        "\n",
        "    passing_completions = passing_attempts.loc[(passing_attempts['PlayOutcome'].str.contains('yard pass', case=False)) |\n",
        "                                               (passing_attempts['PlayOutcome'].str.contains(f'touchdown {dict_qbs_to_team.get(qb)}', case=False)) |\n",
        "                                               (passing_attempts['PlayOutcome'].str.contains(\"Turnover On Downs \\(C\\)\", case=False)) |\n",
        "                                               (passing_attempts['PlayOutcome'].str.contains(\"Pass for No Gain\", case=False)) |\n",
        "                                               (passing_attempts['PlayOutcome'].str.contains(\"Fumble \\(C\\)\", case=False))]\n",
        "\n",
        "    df_quarterback_data.loc[qb, 'CP/ATT'] = f\"{passing_completions.shape[0]}/{passing_attempts.shape[0]}\"\n",
        "\n",
        "    df_quarterback_data.loc[qb, 'YDS'] = int(passing_completions['Yardage'].sum())\n",
        "\n",
        "    total_touchdowns = passing_completions.loc[passing_completions['PlayOutcome'].str.contains(f'touchdown {dict_qbs_to_team.get(qb)}', case=False)]\n",
        "\n",
        "    df_quarterback_data.loc[qb, 'TD'] = total_touchdowns.shape[0]\n",
        "\n",
        "    total_interceptions = passing_attempts.loc[passing_attempts['PlayDescription'].str.contains('intercepted', case=False)]\n",
        "\n",
        "    df_quarterback_data.loc[qb, 'INT'] = total_interceptions.shape[0]\n",
        "\n",
        "  return df_quarterback_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reiXXks4GUpn"
      },
      "outputs": [],
      "source": [
        "# Display rushing stats for a specified game\n",
        "\n",
        "def rushing_table(away_team, home_team, df_cleaned_plays, dict_acronym_to_team, home_or_away):\n",
        "\n",
        "  # All plays within game\n",
        "  df_all_plays_in_game = df_cleaned_plays.loc[(df_cleaned_plays['HomeTeam'] == home_team) &\n",
        "                                              (df_cleaned_plays['AwayTeam'] == away_team)]\n",
        "\n",
        "  # User decides which rushing table they want (home or away)\n",
        "  if home_or_away == 0:\n",
        "    team = home_team\n",
        "  elif home_or_away == 1:\n",
        "    team = away_team\n",
        "  else:\n",
        "    return \"home_or_away parameter should be a 0 or 1. (home = 0, away = 1)\"\n",
        "\n",
        "  print(f\"Rushing Table: {team}\")\n",
        "  print()\n",
        "\n",
        "  df_team_rushing_plays = df_all_plays_in_game.loc[(df_all_plays_in_game['PlayType'] == 'Run') &\n",
        "                                                   (df_all_plays_in_game['TeamWithPossession'] == dict_acronym_to_team.get(team)) &\n",
        "                                                   (~df_all_plays_in_game['PlayOutcome'].str.contains('2PT Conversion', case=False))]\n",
        "\n",
        "  list_rushers = df_team_rushing_plays['Rusher'].unique().tolist()\n",
        "  if 'nan' in list_rushers:\n",
        "    list_rushers.pop(list_rushers.index('nan'))\n",
        "\n",
        "  # Dataframe that will be returned\n",
        "  df_rusher_data = pd.DataFrame(columns=[\"CAR\", \"YDS\", \"TD\", \"AVG\"], index = list_rushers)\n",
        "\n",
        "  for rb in df_rusher_data.index:\n",
        "    rusher_plays = df_team_rushing_plays.loc[df_team_rushing_plays['Rusher'] == rb]\n",
        "    df_rusher_data.loc[rb, 'CAR'] = rusher_plays.shape[0] - rusher_plays.loc[rusher_plays['PlayType'] == 'lateral after run'].shape[0]\n",
        "    df_rusher_data.loc[rb, 'YDS'] = int(rusher_plays['Yardage'].sum())\n",
        "    df_rusher_data.loc[rb, 'TD'] = rusher_plays.loc[rusher_plays['PlayOutcome'].str.contains('touchdown', case=False)].shape[0]\n",
        "    df_rusher_data.loc[rb, 'AVG'] = round(rusher_plays['Yardage'].mean(), 2)\n",
        "\n",
        "  return df_rusher_data.sort_values(by=\"YDS\", ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSiJE4ZQ1lpn"
      },
      "outputs": [],
      "source": [
        "# Display receiving stats for a specified game\n",
        "\n",
        "def receiving_table(away_team, home_team, df_cleaned_plays, dict_acronym_to_team, home_or_away):\n",
        "\n",
        "  # All plays within game\n",
        "  df_all_plays_in_game = df_cleaned_plays.loc[(df_cleaned_plays['HomeTeam'] == home_team) &\n",
        "                                              (df_cleaned_plays['AwayTeam'] == away_team)]\n",
        "\n",
        "  # User decides which receiving table they want (home or away)\n",
        "  if home_or_away == 0:\n",
        "    team = home_team\n",
        "  elif home_or_away == 1:\n",
        "    team = away_team\n",
        "  else:\n",
        "    return \"home_or_away parameter should be a 0 or 1. (home = 0, away = 1)\"\n",
        "\n",
        "  print(f\"Receiving Table: {team}\")\n",
        "  print()\n",
        "\n",
        "  df_receiving_plays = df_all_plays_in_game.loc[(df_all_plays_in_game['PlayType'].str.contains('pass', case=False)) &\n",
        "                                                (df_all_plays_in_game['TeamWithPossession'] == dict_teams.get(team)) &\n",
        "                                                (~df_all_plays_in_game['PlayOutcome'].str.contains('2PT Conversion', case=False))]\n",
        "\n",
        "  receivers = df_receiving_plays['Receiver'].unique().tolist()\n",
        "  if 'nan' in receivers:\n",
        "    receivers.pop(receivers.index('nan'))\n",
        "\n",
        "  df_receiver_data = pd.DataFrame(columns=[\"REC\", \"YDS\", \"TD\", \"TGTS\"], index = receivers)\n",
        "\n",
        "  # print(df_receiver_data)\n",
        "\n",
        "  for receiver in df_receiver_data.index:\n",
        "    receiver_plays = df_receiving_plays.loc[df_receiving_plays['Receiver'] == receiver]\n",
        "    # df_receiver_data.loc[receiver, 'REC'] = receiver_plays.loc[(receiver_plays['PlayOutcome'].str.contains('yard pass', case=False)) |\n",
        "    #                                                           (receiver_plays['PlayOutcome'].str.contains(f'Touchdown {team}', case=False)) |\n",
        "    #                                                           (receiver_plays['PlayOutcome'].str.contains(\"Turnover On Downs \\(C\\)\", case=False)) |\n",
        "    #                                                           (receiver_plays['PlayOutcome'].str.contains(\"Pass for No Gain\", case=False)) |\n",
        "    #                                                           (receiver_plays['PlayOutcome'].str.contains(\"Fumble \\(C\\)\", case=False))].shape[0]\n",
        "\n",
        "    df_receiver_data.loc[receiver, 'REC'] = receiver_plays.loc[(\n",
        "        (receiver_plays['PlayOutcome'].str.contains('yard pass', case=False)) |\n",
        "         (receiver_plays['PlayOutcome'].str.contains(f'Touchdown {team}', case=False)) |\n",
        "          (receiver_plays['PlayOutcome'].str.contains(\"Turnover On Downs \\(C\\)\", case=False)) |\n",
        "           (receiver_plays['PlayOutcome'].str.contains(\"Pass for No Gain\", case=False)) |\n",
        "            (receiver_plays['PlayOutcome'].str.contains(\"Fumble \\(C\\)\", case=False))) &\n",
        "                                                               ~ (receiver_plays['PlayType'].str.contains(\"lateral after pass\", case=False))\n",
        "                                                               ].shape[0]\n",
        "\n",
        "    df_receiver_data.loc[receiver, 'YDS'] = int(receiver_plays['Yardage'].sum())\n",
        "    df_receiver_data.loc[receiver, 'TD'] = receiver_plays.loc[receiver_plays['PlayOutcome'].str.contains(f'touchdown {team}', case=False)].shape[0]\n",
        "    df_receiver_data.loc[receiver, 'TGTS'] = receiver_plays.shape[0] - receiver_plays.loc[receiver_plays['PlayType'] == 'lateral after pass'].shape[0]\n",
        "\n",
        "  return df_receiver_data.sort_values(by=\"YDS\", ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yh--b37gctuw"
      },
      "outputs": [],
      "source": [
        "# Display all fumble stats for a specified game\n",
        "\n",
        "# NOTE:\n",
        "# - nfl.com does not have the correct table stats.\n",
        "#   - nfl.com has a lot of flaws in their play by play data\n",
        "\n",
        "# - I need to grab all players that recovered a fumbled ball.\n",
        "\n",
        "def fumble_table(away_team, home_team, df_cleaned_plays, dict_acronym_to_team, home_or_away):\n",
        "\n",
        "  # User decides which fumble table they want (home or away)\n",
        "  if home_or_away == 0:\n",
        "    team = home_team\n",
        "  elif home_or_away == 1:\n",
        "    team = away_team\n",
        "  else:\n",
        "    return \"home_or_away parameter should be a 0 or 1. (home = 0, away = 1)\"\n",
        "\n",
        "  print(f\"Fumbles Table: {team}\")\n",
        "  print()\n",
        "\n",
        "  # Dataframe of all plays within game\n",
        "  df_all_plays_in_game = df_cleaned_plays.loc[(df_cleaned_plays['HomeTeam'] == home_team) &\n",
        "                                              (df_cleaned_plays['AwayTeam'] == away_team) &\n",
        "                                              (df_cleaned_plays['PlayType'] != 'No Play')]\n",
        "\n",
        "  # Dataframe of all fumbles within game\n",
        "  df_all_fumbles_in_game = df_all_plays_in_game.loc[df_all_plays_in_game['FumbleDetails'] != 'nan']\n",
        "\n",
        "  # Dataframe of all desired team fumbles\n",
        "  df_team_fumbles = df_all_fumbles_in_game.loc[df_all_fumbles_in_game['TeamWithPossession'] == dict_acronym_to_team.get(team)]\n",
        "\n",
        "  # Dataframe of all fumbles that were recovered by a player (both desired team and opposing)\n",
        "  df_team_fumbles_recovered = df_all_fumbles_in_game.loc[df_all_fumbles_in_game['FumbleRecoveredBy'] != 'nan']\n",
        "\n",
        "  # Dataframe for return 'FUMBLES' table\n",
        "  df_team_fumble_data = pd.DataFrame(columns=[\"FUM\", \"LOST\", \"FF\", \"REC\"])\n",
        "\n",
        "\n",
        "  # NOTE: I might be able to add both players who fumbled and players who recovered here in a list and make it work.\n",
        "\n",
        "  # List of all desired team players who fumbled\n",
        "  list_team_fumblers = df_team_fumbles['WhoFumbled'].unique().tolist()\n",
        "  if 'nan' in list_team_fumblers:\n",
        "    list_team_fumblers.pop(list_team_fumblers.index('nan'))\n",
        "\n",
        "\n",
        "  # Filling 'FUMBLES' table (FUM, LOST, REC)\n",
        "\n",
        "  # - Cycle through all players who have fumbled on the team\n",
        "  for player in list_team_fumblers:\n",
        "    fum = 0\n",
        "    lost = 0\n",
        "    rec = 0\n",
        "    df_all_player_fumbles = df_team_fumbles.loc[df_team_fumbles['WhoFumbled'] == player]\n",
        "    for idx, row in df_all_player_fumbles.iterrows():\n",
        "      fum = fum + 1\n",
        "      # Nobody recovered the ball\n",
        "      if row['FumbleRecoveredBy'] == 'nan':\n",
        "        continue\n",
        "\n",
        "      # Looking at who recovered the ball (The person who fumbled also recovered)\n",
        "      if row['FumbleDetails'].find('and recovers') != -1:\n",
        "        rec = rec + 1\n",
        "        continue\n",
        "\n",
        "      # When a player fumbled the ball, did it result in a turnover?\n",
        "      if 'recovered' in row['FumbleDetails'].lower():\n",
        "        fumble_recovery = re.findall(fumble_recovery_pattern, row['FumbleDetails'])\n",
        "        if len(fumble_recovery) > 0:\n",
        "          fumble_recovery_team = fumble_recovery[0][0].split(\"-\")[0]\n",
        "          if fumble_recovery_team != row['TeamWithPossession']:\n",
        "            lost = lost + 1\n",
        "\n",
        "    df_team_fumble_data.loc[player, 'FUM'] = fum\n",
        "    df_team_fumble_data.loc[player, 'LOST'] = lost\n",
        "    df_team_fumble_data.loc[player, 'REC'] = rec\n",
        "\n",
        "\n",
        "  # - Cycling through all players who recovered a fumble on both teams.\n",
        "  for idx, row in df_team_fumbles_recovered.iterrows():\n",
        "    fumble_recovery = re.findall(fumble_recovery_pattern, row['FumbleDetails'])\n",
        "    if len(fumble_recovery) > 0:\n",
        "      fumble_recovery_team = dict_teams_2.get(fumble_recovery[0][0].split(\"-\")[0])\n",
        "      player = fumble_recovery[0][0].split(\"-\")[1:][0]\n",
        "      if fumble_recovery_team == team:\n",
        "        if player not in df_team_fumble_data.index.tolist():\n",
        "          df_team_fumble_data.loc[player, 'REC'] = 1\n",
        "        else:\n",
        "          df_team_fumble_data.loc[player, 'REC'] = df_team_fumble_data.loc[player, 'REC'] + 1\n",
        "\n",
        "\n",
        "  # Filling 'FUMBLES' table (FF)\n",
        "  if home_or_away == 0:\n",
        "    df_team_forced_fumble_data = df_all_fumbles_in_game.loc[df_all_fumbles_in_game['TeamWithPossession'] == dict_acronym_to_team.get(away_team)]\n",
        "  else:\n",
        "    df_team_forced_fumble_data = df_all_fumbles_in_game.loc[df_all_fumbles_in_game['TeamWithPossession'] == dict_acronym_to_team.get(home_team)]\n",
        "\n",
        "  # All team players with a forced fumble\n",
        "  list_team_forced_fumblers = df_team_forced_fumble_data['ForcedFumbleBy'].unique().tolist()\n",
        "  if 'nan' in list_team_forced_fumblers:\n",
        "    list_team_forced_fumblers.pop(list_team_forced_fumblers.index('nan'))\n",
        "\n",
        "  for player in list_team_forced_fumblers:\n",
        "    df_team_fumble_data.loc[player, 'FF'] = df_team_forced_fumble_data.loc[df_team_forced_fumble_data['ForcedFumbleBy'] == player].shape[0]\n",
        "\n",
        "  for idx, row in df_team_fumble_data.iterrows():\n",
        "    for col in df_team_fumble_data.columns:\n",
        "      if pd.isna(df_team_fumble_data.loc[idx, col]):\n",
        "        df_team_fumble_data.loc[idx, col] = 0\n",
        "\n",
        "  return df_team_fumble_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j917ZbdW3g3h"
      },
      "outputs": [],
      "source": [
        "# Display interception table\n",
        "\n",
        "def interception_table(away_team, home_team, df_cleaned_plays, dict_acronym_to_team, home_or_away):\n",
        "\n",
        "  # All plays within game\n",
        "  df_all_plays_in_game = df_cleaned_plays.loc[(df_cleaned_plays['HomeTeam'] == home_team) &\n",
        "                                              (df_cleaned_plays['AwayTeam'] == away_team)]\n",
        "\n",
        "  # User decides which fumble table they want (home or away)\n",
        "  if home_or_away == 0:\n",
        "    team = away_team\n",
        "    unwanted_team = home_team\n",
        "  elif home_or_away == 1:\n",
        "    team = home_team\n",
        "    unwanted_team = away_team\n",
        "  else:\n",
        "    return \"home_or_away parameter should be a 0 or 1. (home = 0, away = 1)\"\n",
        "\n",
        "  print(f\"Interception Table: {unwanted_team}\")\n",
        "  print()\n",
        "\n",
        "  # All team defensive plays\n",
        "  df_team_defensive_plays = df_all_plays_in_game.loc[df_all_plays_in_game['TeamWithPossession'] == dict_acronym_to_team.get(team)]\n",
        "\n",
        "  # Interception table\n",
        "  df_interception_table = pd.DataFrame(columns=[\"INT\", \"YDS\", \"PD\"])\n",
        "\n",
        "  # All team interceptions\n",
        "  df_team_interceptions = df_team_defensive_plays.loc[df_team_defensive_plays['InterceptedBy'] != 'nan']\n",
        "\n",
        "  # list of players with interceptions\n",
        "  list_team_interception_players = df_team_interceptions['InterceptedBy'].unique().tolist()\n",
        "\n",
        "  for player in list_team_interception_players:\n",
        "    df_interception_table.loc[player, 'INT'] = df_team_interceptions.loc[df_team_interceptions['InterceptedBy'] == player].shape[0]\n",
        "    df_interception_table.loc[player, 'YDS'] = int(df_all_plays_in_game['Yardage'].loc[(df_all_plays_in_game['PlayType'] == 'Run After Interception') &\n",
        "                                                                                          (df_all_plays_in_game['Rusher'] == player)].sum())\n",
        "\n",
        "  # All team pass defends\n",
        "  df_team_pass_defends = df_team_defensive_plays.loc[df_team_defensive_plays['PassDefendedBy'] != 'nan']\n",
        "\n",
        "  # list of players who have defended passes (sometimes there are multiple defenders for a single play)\n",
        "  list_team_pass_defenders = df_team_pass_defends['PassDefendedBy'].loc[df_team_pass_defends['PassDefendedBy'] != 'nan'].tolist()\n",
        "\n",
        "  # list of all players involved in defended passes\n",
        "  list_team_pass_defenders_split = []\n",
        "  for player in list_team_pass_defenders:\n",
        "    if isinstance(player, tuple):\n",
        "      for p in player:\n",
        "        list_team_pass_defenders_split.append(p)\n",
        "    else:\n",
        "        list_team_pass_defenders_split.append(player)\n",
        "\n",
        "  for pass_defender in list_team_pass_defenders_split:\n",
        "    df_interception_table.loc[pass_defender, 'PD'] = list_team_pass_defenders_split.count(pass_defender)\n",
        "\n",
        "  # Replacing all 'nan' values with 0\n",
        "  for idx, row in df_interception_table.iterrows():\n",
        "    for col in df_interception_table.columns:\n",
        "      if pd.isna(df_interception_table.loc[idx, col]):\n",
        "        df_interception_table.loc[idx, col] = 0\n",
        "\n",
        "  return df_interception_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7L_Wv8rPU0x"
      },
      "outputs": [],
      "source": [
        "# Display Defense table\n",
        "\n",
        "# QUESTIONS:\n",
        "# 1. Is a TFL when its '<= 0 yards' or '< 0 yards'\n",
        "\n",
        "def defense_table(away_team, home_team, df_cleaned_plays, dict_team_name_to_acronym, home_or_away):\n",
        "\n",
        "  if home_or_away == 0:\n",
        "    wanted_team = home_team\n",
        "    unwanted_team = away_team\n",
        "  elif home_or_away == 1:\n",
        "    wanted_team = away_team\n",
        "    unwanted_team = home_team\n",
        "  else:\n",
        "    return \"home_or_away parameter should be a 0 or 1. (home = 0, away = 1)\"\n",
        "\n",
        "  print(f\"Defense Table: {wanted_team}\")\n",
        "  print()\n",
        "\n",
        "  # Dataframe of all defensive and offensive players that contributed defensively\n",
        "  df_wanted_team_defense_plays = df_cleaned_plays.loc[\n",
        "      (df_cleaned_plays['TeamWithPossession'] == dict_team_name_to_acronym.get(unwanted_team))\n",
        "      &\n",
        "      (~df_cleaned_plays['PlayType'].str.contains('No Play', case=False))\n",
        "  ]\n",
        "\n",
        "  # List of all players that recorded a solo tackle\n",
        "  list_solo_tackles = []\n",
        "  for idx, solo_tackler in df_wanted_team_defense_plays['SoloTackle'].items():\n",
        "    if solo_tackler == 'nan':\n",
        "      continue\n",
        "    else:\n",
        "      list_solo_tackles.append(solo_tackler)\n",
        "\n",
        "  # List of all recorded assisted tackles by players\n",
        "  list_assisted_tackles = []\n",
        "  for idx, assisted_tackler in df_wanted_team_defense_plays['AssistedTackle'].items():\n",
        "    if assisted_tackler == 'nan':\n",
        "      continue\n",
        "    else:\n",
        "      for player in assisted_tackler:\n",
        "        list_assisted_tackles.append(player)\n",
        "\n",
        "  # List of all recorded shared tackles by players\n",
        "  list_shared_tackles = []\n",
        "  for idx, shared_tackler in df_wanted_team_defense_plays['SharedTackle'].items():\n",
        "    if shared_tackler == 'nan':\n",
        "      continue\n",
        "    else:\n",
        "      for player in shared_tackler:\n",
        "        list_shared_tackles.append(player)\n",
        "\n",
        "  # List of every tackle recorded in the game for the wanted team by player name\n",
        "  list_tackles = list_solo_tackles + list_assisted_tackles + list_shared_tackles\n",
        "\n",
        "  # List of all players that made a defensive impact for wanted team\n",
        "  # No duplicates\n",
        "  list_defensive_players = []\n",
        "  for name in list_tackles:\n",
        "    if name not in list_defensive_players:\n",
        "      list_defensive_players.append(name)\n",
        "\n",
        "  # Return dataframe\n",
        "  df_defense_data = pd.DataFrame(columns=[\"T-A\", \"SACK\", \"TFL\", \"TD\", \"Tackles\", \"LastName\"])\n",
        "\n",
        "  # Filling dataframe\n",
        "  for player in list_defensive_players:\n",
        "    # Grabbing all last names for dataframe sorting purposes\n",
        "    df_defense_data.loc[player, 'LastName'] = player.split(\".\")[1]\n",
        "    # Grabbing all solo tackles for each player in dataframe for sorting purposes\n",
        "    df_defense_data.loc[player, 'Tackles'] = list_solo_tackles.count(player)\n",
        "    # T = Solo tackles\n",
        "    # A = Assisted tackles + Shared tackles\n",
        "    df_defense_data.loc[player, 'T-A'] = f\"{list_solo_tackles.count(player)}-{list_assisted_tackles.count(player) + list_shared_tackles.count(player)}\"\n",
        "    # All solo sacks\n",
        "    df_defense_data.loc[player, 'SACK'] = df_wanted_team_defense_plays.loc[df_wanted_team_defense_plays['SackedBy'] == player].shape[0]\n",
        "\n",
        "    # Tackle for loss (version 2)\n",
        "    df_defense_data.loc[player, 'TFL'] = df_wanted_team_defense_plays.loc[\n",
        "        (df_wanted_team_defense_plays['SoloTackle'] == player)\n",
        "        &\n",
        "        (df_wanted_team_defense_plays['TeamWithPossession'] != dict_team_name_to_acronym.get(wanted_team))\n",
        "        &\n",
        "        (df_wanted_team_defense_plays['Yardage'] < 0)].shape[0]\n",
        "\n",
        "    # TD count for defenders that scoop or intercept and score.\n",
        "    df_defense_data.loc[player, 'TD'] = df_cleaned_plays.loc[\n",
        "        (df_cleaned_plays['Rusher'] == player)\n",
        "        &\n",
        "        (df_cleaned_plays['PlayType'].isin(['Run After Interception', 'Fumble Return']))\n",
        "        &\n",
        "        (df_cleaned_plays['PlayOutcome'].str.contains('touchdown', case=False))\n",
        "        &\n",
        "        (df_cleaned_plays['WhoFumbled'] != player)].shape[0]\n",
        "\n",
        "  # Grabbing assisted tackles that result in a tackle for loss, although they are assisted tackles they are recorded as a TFL\n",
        "  # - This is not the case for some organizations that record nfl stats. Some may say that an assisted tackle for loss is just an assisted tackle.\n",
        "  for idx, assisted_tackler in df_wanted_team_defense_plays['AssistedTackle'].items():\n",
        "    if assisted_tackler == 'nan':\n",
        "      continue\n",
        "    else:\n",
        "      # (1:17) J.Ford right guard to CLE 29 for -4 yards (D.Hill, G.Pratt)\n",
        "      # - in this scenario, I believe that the first player (D.Hill) is awarded the TFL.\n",
        "      for player in assisted_tackler:\n",
        "        if df_wanted_team_defense_plays['Yardage'].loc[idx] < 0:\n",
        "          df_defense_data.loc[player, 'TFL'] = df_defense_data.loc[player, 'TFL'] + 1\n",
        "\n",
        "  # ^^^ shared tackles follow the same rules as above\n",
        "  for idx, shared_tackler in df_wanted_team_defense_plays['SharedTackle'].items():\n",
        "    if shared_tackler == 'nan':\n",
        "      continue\n",
        "    else:\n",
        "      # for player in shared_tackler:\n",
        "      #   if df_wanted_team_defense_plays['Yardage'].loc[idx] < 0:\n",
        "      #     df_defense_data.loc[player, 'TFL'] = df_defense_data.loc[player, 'TFL'] + 1\n",
        "      if isinstance(shared_tackler, tuple):\n",
        "        if df_wanted_team_defense_plays['Yardage'].loc[idx] < 0:\n",
        "          df_defense_data.loc[shared_tackler[0], 'TFL'] = df_defense_data.loc[shared_tackler[0], 'TFL'] + 1\n",
        "\n",
        "  # I need to grab split sacks. On split sacks, a player involved is awarded 0.5 of a sack\n",
        "  for idx, sack in df_wanted_team_defense_plays['SackedBy'].items():\n",
        "    if sack == 'nan':\n",
        "      continue\n",
        "    else:\n",
        "      if isinstance(sack, tuple):\n",
        "        for player in sack:\n",
        "          df_defense_data.loc[player, 'SACK'] = df_defense_data.loc[player, 'SACK'] + 0.5\n",
        "\n",
        "  # Organizing dataframe\n",
        "  # df_defense_data = df_defense_data.sort_values(by=[\"T-A\", \"LastName\"], ascending=[False, True]) # <-- This sorting method feels better.\n",
        "  df_defense_data = df_defense_data.sort_values(by=[\"Tackles\", \"LastName\"], ascending=[False, True]) # <-- This sorting method is how NFL.com has it. (easier cross referencing)\n",
        "  df_defense_data = df_defense_data.drop([\"Tackles\", \"LastName\"], axis=1)\n",
        "\n",
        "  # Replacing all 'nan' values with 0\n",
        "  for idx, row in df_defense_data.iterrows():\n",
        "    for col in df_defense_data.columns:\n",
        "      if pd.isna(df_defense_data.loc[idx, col]):\n",
        "        df_defense_data.loc[idx, col] = 0\n",
        "\n",
        "  return df_defense_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display KICKING table\n",
        "\n",
        "def kicking_table(away_team, home_team, df_cleaned_plays, dict_team_name_to_acronym, home_or_away):\n",
        "\n",
        "  if home_or_away == 0:\n",
        "    team = home_team\n",
        "  elif home_or_away == 1:\n",
        "    team = away_team\n",
        "\n",
        "  print(f\"Kicking Table: {team}\")\n",
        "  print()\n",
        "\n",
        "  df_all_plays_in_game = df_cleaned_plays.loc[(df_cleaned_plays['HomeTeam'] == home_team) &\n",
        "                                              (df_cleaned_plays['AwayTeam'] == away_team)]\n",
        "\n",
        "  df_all_kicking_plays = df_all_plays_in_game.loc[\n",
        "                                                  (\n",
        "                                                      (df_all_plays_in_game['PlayOutcome'].str.contains('Field Goal', case=False))\n",
        "                                                      |\n",
        "                                                      (\n",
        "                                                           (df_all_plays_in_game['PlayOutcome'].str.contains('Extra Point', case=False))\n",
        "                                                           &\n",
        "                                                           (df_all_plays_in_game['Kicker'] != 'nan')\n",
        "                                                      )\n",
        "                                                  )\n",
        "                                                  &\n",
        "                                                  (df_all_plays_in_game['TeamWithPossession'] == dict_team_name_to_acronym.get(team))]\n",
        "\n",
        "  list_kickers = df_all_kicking_plays['Kicker'].unique().tolist()\n",
        "  if 'nan' in list_kickers:\n",
        "    list_kickers.pop(list_kickers.index('nan'))\n",
        "\n",
        "  df_kicker_data = pd.DataFrame(columns=[\"FG\", \"LONG\", \"XP\", \"PTS\"])\n",
        "\n",
        "  for kicker in list_kickers:\n",
        "    # FG\n",
        "    df_field_goals_good = df_all_kicking_plays.loc[(df_all_kicking_plays['PlayOutcome'] == 'Field Goal Good') &\n",
        "                                                  (df_all_kicking_plays['Kicker'] == kicker)]\n",
        "    df_field_goals_no_good = df_all_kicking_plays.loc[(df_all_kicking_plays['PlayOutcome'] == 'Field Goal No Good') &\n",
        "                                                      (df_all_kicking_plays['Kicker'] == kicker)]\n",
        "    df_kicker_data.loc[kicker, \"FG\"] = f\"{len(df_field_goals_good)}/{len(df_field_goals_good) + len(df_field_goals_no_good)}\"\n",
        "    # LONG\n",
        "    df_kicker_data.loc[kicker, \"LONG\"] = df_field_goals_good['Yardage'].max()\n",
        "    if pd.isna(df_kicker_data.loc[kicker, \"LONG\"]):\n",
        "      df_kicker_data.loc[kicker, \"LONG\"] = 0\n",
        "    # XP\n",
        "    df_extra_points_good = df_all_kicking_plays.loc[(df_all_kicking_plays['PlayOutcome'] == 'Extra Point Good') &\n",
        "                                                    (df_all_kicking_plays['Kicker'] == kicker)]\n",
        "    df_extra_points_no_good = df_all_kicking_plays.loc[(df_all_kicking_plays['PlayOutcome'] == 'Extra Point No Good') &\n",
        "                                                      (df_all_kicking_plays['Kicker'] == kicker)]\n",
        "    df_kicker_data.loc[kicker, \"XP\"] = f\"{len(df_extra_points_good)}/{len(df_extra_points_good) + len(df_extra_points_no_good)}\"\n",
        "    # PTS\n",
        "    df_kicker_data.loc[kicker, \"PTS\"] = len(df_field_goals_good) * 3 + len(df_extra_points_good)\n",
        "\n",
        "  return df_kicker_data"
      ],
      "metadata": {
        "id": "oYq3RkU9vETX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display PUNTING table\n",
        "\n",
        "def punting_table(away_team, home_team, df_cleaned_plays, dict_team_name_to_acronym, home_or_away):\n",
        "\n",
        "  if home_or_away == 0:\n",
        "    team = home_team\n",
        "  elif home_or_away == 1:\n",
        "    team = away_team\n",
        "\n",
        "  print(f\"Punting Table: {team}\")\n",
        "  print()\n",
        "\n",
        "  df_all_plays_in_game = df_cleaned_plays.loc[(df_cleaned_plays['HomeTeam'] == home_team) &\n",
        "                                              (df_cleaned_plays['AwayTeam'] == away_team)]\n",
        "\n",
        "  df_all_punting_plays = df_all_plays_in_game.loc[(df_all_plays_in_game['PlayType'].str.contains('punt', case=False)) &\n",
        "                                                  (df_all_plays_in_game['TeamWithPossession'] == dict_team_name_to_acronym.get(team)) &\n",
        "                                                  (df_all_plays_in_game['Kicker'] != 'nan')]\n",
        "\n",
        "  df_all_punters = df_all_punting_plays['Kicker'].unique().tolist()\n",
        "\n",
        "  df_punting_table = pd.DataFrame(columns=[\"PUNTS\", \"AVG\", \"I20\", \"LONG\"])\n",
        "\n",
        "  for punter in df_all_punters:\n",
        "\n",
        "    df_all_kicker_punts = df_all_punting_plays.loc[df_all_punting_plays['Kicker'] == punter]\n",
        "\n",
        "    # PUNTS\n",
        "    df_punting_table.loc[punter, \"PUNTS\"] = df_all_kicker_punts.shape[0]\n",
        "\n",
        "    # AVG\n",
        "    df_punting_table.loc[punter, \"AVG\"] = round(float(df_all_punting_plays['Yardage'].loc[df_all_punting_plays['Kicker'] == punter].mean()), 2)\n",
        "\n",
        "    # - I need to take into account the return. If the kick is inside the 20 and\n",
        "    #   the returner goes passed the 20, then it does not count for an I20.\n",
        "    # - Should I find the 'punt return' that corresponds to the punt?\n",
        "    #   - if punt return found:\n",
        "    #     - use as 'end'\n",
        "    #   - else:\n",
        "    #     - use punting pattern.\n",
        "\n",
        "    # I20\n",
        "    i20_count = 0\n",
        "    for idx, row in df_all_kicker_punts.iterrows():\n",
        "      # start\n",
        "      start_punt = re.findall(play_start_pattern, row['PlayStart'])[0]\n",
        "      start_punt_territory = start_punt[0]\n",
        "      start_punt_yardage = start_punt[1]\n",
        "\n",
        "      # end\n",
        "      end_punt = re.findall(punting_pattern, row['PlayDescription'])\n",
        "      punt_yardage = end_punt[0][1]\n",
        "      end_punt_territory = end_punt[0][2]\n",
        "      end_punt_yardage = end_punt[0][3]\n",
        "\n",
        "      # touchback / out of bounds / etc..\n",
        "      if end_punt_yardage == '':\n",
        "        continue\n",
        "\n",
        "      # penalty\n",
        "      # - If an accepted penalty has taken place, the description of the penalty\n",
        "      #   will state the ball placement after the penalty has taken affect.\n",
        "      #   - Will leaverage this to identify if the spotting after the punting play\n",
        "      #     is inside the opposing 20 yard line.\n",
        "      # PLAN:\n",
        "      # 1. Identify territory that punter is aiming towards\n",
        "      # 2. Use spotting of accepted penalty to see if inside 20\n",
        "\n",
        "      # pseudo code: (example game : BUF vs KC)\n",
        "      # same territory: (BUF -> BUF)\n",
        "      #   start_punt_yards > end_punt_yards (BUF 40 -> BUF 20)\n",
        "      #     yardage +:\n",
        "      #       aim is BUF territory\n",
        "      #     yardage -:\n",
        "      #       aim is KC territory\n",
        "      #   start_punt_yards < end_punt_yards:\n",
        "      #     yardage +:\n",
        "      #       aim is KC territory\n",
        "      #     yardage -:\n",
        "      #       aim is BUF territory\n",
        "      # different territory:\n",
        "      #   yardage +:\n",
        "      #     aim is ending territory\n",
        "      #   yardage -:\n",
        "      #     aim is starting territory\n",
        "      if row['AcceptedPenalty'] != 'nan':\n",
        "        # variables\n",
        "        penalty = re.findall(penalty_yardage_pattern, row['AcceptedPenalty'][0])\n",
        "        penalty_territory = penalty[0][1]\n",
        "        penalty_yardage = penalty[0][2]\n",
        "\n",
        "        # algorithm\n",
        "        if start_punt_territory == end_punt_territory:\n",
        "          if int(start_punt_yardage) > int(end_punt_yardage):\n",
        "            if int(punt_yardage) > 0:\n",
        "              if start_punt_territory == penalty_territory and int(penalty_yardage) <= 20:\n",
        "                i20_count += 1\n",
        "                continue\n",
        "            else:\n",
        "              if start_punt_territory != penalty_territory and int(penalty_yardage) <= 20:\n",
        "                i20_count += 1\n",
        "                continue\n",
        "          else:\n",
        "            if int(punt_yardage) > 0:\n",
        "              if start_punt_territory != penalty_territory and int(penalty_yardage) <= 20:\n",
        "                i20_count += 1\n",
        "                continue\n",
        "            else:\n",
        "              if start_punt_territory == penalty_territory and int(penalty_yardage) <= 20:\n",
        "                i20_count += 1\n",
        "                continue\n",
        "        else:\n",
        "          if int(punt_yardage) > 0:\n",
        "            if end_punt_territory == penalty_territory and int(penalty_yardage) <= 20:\n",
        "              i20_count += 1\n",
        "              continue\n",
        "          else:\n",
        "            if start_punt_territory == penalty_territory and int(penalty_yardage) <= 20:\n",
        "              i20_count += 1\n",
        "              continue\n",
        "\n",
        "      # Trying to see if there is a punt return associated with the punt observed.\n",
        "      # - Search through every play in game and see if there is a match for punting play\n",
        "      #   - A match will come up if there has been an associated punt return with the punt\n",
        "      # - What about punt returns for a touchdown?\n",
        "      # - Does this table account for punts that result in a touchdown? <<<<<<<<<<<<<<<<<<\n",
        "      #   - I need to check if this table does as well as kickoffs. <<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
        "      searching_punt_return = df_all_plays_in_game.loc[(df_all_plays_in_game['Season'] == row[\"Season\"]) &\n",
        "                                                       (df_all_plays_in_game['Week'] == row[\"Week\"]) &\n",
        "                                                       (df_all_plays_in_game['AwayTeam'] == row[\"AwayTeam\"]) &\n",
        "                                                       (df_all_plays_in_game['Quarter'] == row[\"Quarter\"]) &\n",
        "                                                       (df_all_plays_in_game['DriveNumber'] == row[\"DriveNumber\"]) &\n",
        "                                                       (df_all_plays_in_game['PlayNumberInDrive'] == row[\"PlayNumberInDrive\"]) &\n",
        "                                                       (df_all_plays_in_game['PlayType'] == \"Punt Return\")]\n",
        "\n",
        "      # All I need from the punt return is the yardage gained\n",
        "      return_yardage = 0\n",
        "      if searching_punt_return.shape[0] > 0:\n",
        "        return_yardage = searching_punt_return['Yardage'].iloc[0]\n",
        "\n",
        "      # Checking to see if the punt landed inside 20\n",
        "      if int(end_punt_yardage) <= 20 and int(punt_yardage) > 0:\n",
        "        punt_inside_20 = False\n",
        "        if start_punt_territory == end_punt_territory:\n",
        "          if int(start_punt_yardage) > int(end_punt_yardage):\n",
        "            punt_inside_20 = True\n",
        "        else:\n",
        "          punt_inside_20 = True\n",
        "\n",
        "        # Take into account the punt return\n",
        "        if punt_inside_20:\n",
        "          if return_yardage > 0:\n",
        "            if int(return_yardage) + int(end_punt_yardage) <= 20:\n",
        "              i20_count += 1\n",
        "              continue\n",
        "          else:\n",
        "            i20_count += 1\n",
        "            continue\n",
        "\n",
        "    df_punting_table.loc[punter, \"I20\"] = i20_count\n",
        "\n",
        "    # LONG\n",
        "    df_punting_table.loc[punter, \"LONG\"] = int(df_all_punting_plays['Yardage'].loc[df_all_punting_plays['Kicker'] == punter].max())\n",
        "\n",
        "  return df_punting_table"
      ],
      "metadata": {
        "id": "8fgrvGs8zQaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display KICKOFF RETURNS table\n",
        "\n",
        "def kickoff_returns_table(away_team, home_team, df_cleaned_plays, dict_team_name_to_acronym, home_or_away):\n",
        "\n",
        "  if home_or_away == 0:\n",
        "    team = home_team\n",
        "  elif home_or_away == 1:\n",
        "    team = away_team\n",
        "\n",
        "  print(f\"Kickoff Returns Table: {team}\")\n",
        "  print()\n",
        "\n",
        "  df_all_plays_in_game = df_cleaned_plays.loc[(df_cleaned_plays['HomeTeam'] == home_team) &\n",
        "                                              (df_cleaned_plays['AwayTeam'] == away_team)]\n",
        "\n",
        "  df_all_kickoff_returns = df_all_plays_in_game.loc[(df_all_plays_in_game['PlayType'].str.contains('kickoff return', case=False)) &\n",
        "                                                    (df_all_plays_in_game['TeamWithPossession'] == dict_team_name_to_acronym.get(team))]\n",
        "\n",
        "  df_all_kickoff_returners = df_all_kickoff_returns['Returner'].unique().tolist()\n",
        "\n",
        "  df_kickoff_returns_table = pd.DataFrame(columns=[\"RET\", \"AVG\", \"TD\", \"LNG\"])\n",
        "\n",
        "  for returner in df_all_kickoff_returners:\n",
        "    # RET\n",
        "    df_kickoff_returns_table.loc[returner, \"RET\"] = df_all_kickoff_returns.loc[df_all_kickoff_returns['Returner'] == returner].shape[0]\n",
        "    # AVG\n",
        "    df_kickoff_returns_table.loc[returner, \"AVG\"] = round(float(df_all_kickoff_returns['Yardage'].loc[df_all_kickoff_returns['Returner'] == returner].mean()), 2)\n",
        "    # TD\n",
        "    df_kickoff_returns_table.loc[returner, \"TD\"] = df_all_kickoff_returns.loc[(df_all_kickoff_returns['Returner'] == returner) &\n",
        "                                                                              (df_all_kickoff_returns['PlayOutcome'].str.contains('touchdown', case=False))].shape[0]\n",
        "    # LNG\n",
        "    df_kickoff_returns_table.loc[returner, \"LNG\"] = int(df_all_kickoff_returns.loc[df_all_kickoff_returns['Returner'] == returner]['Yardage'].max())\n",
        "\n",
        "  return df_kickoff_returns_table"
      ],
      "metadata": {
        "id": "1vlSPEoGJWxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display PUNT RETURNS table\n",
        "\n",
        "def punt_returns_table(away_team, home_team, df_cleaned_plays, dict_team_name_to_acronym, home_or_away):\n",
        "\n",
        "  if home_or_away == 0:\n",
        "    team = home_team\n",
        "  elif home_or_away == 1:\n",
        "    team = away_team\n",
        "\n",
        "  print(f\"Punt Returns Table: {team}\")\n",
        "  print()\n",
        "\n",
        "  df_all_plays_in_game = df_cleaned_plays.loc[(df_cleaned_plays['HomeTeam'] == home_team) &\n",
        "                                              (df_cleaned_plays['AwayTeam'] == away_team)]\n",
        "\n",
        "  df_all_punt_returns = df_all_plays_in_game.loc[(df_all_plays_in_game['PlayType'].str.contains('punt return', case=False)) &\n",
        "                                                 (df_all_plays_in_game['TeamWithPossession'] == dict_team_name_to_acronym.get(team))]\n",
        "\n",
        "  df_all_punt_returners = df_all_punt_returns['Returner'].unique().tolist()\n",
        "\n",
        "  df_punt_returns_table = pd.DataFrame(columns=[\"RET\", \"AVG\", \"TD\", \"LNG\"])\n",
        "\n",
        "  # (2445, [2575, 2576])\n",
        "  # (7:45) N.Cooney punts 51 yards to WAS 19, Center-A.Brewer\n",
        "  # J.Crowder pushed ob at WAS 29 for 10 yards (V.Dimukeje)\n",
        "  # PENALTY on WAS-J.Martin, Illegal Block Above the Waist, 10 yards, enforced at WAS 19.\n",
        "\n",
        "  for returner in df_all_punt_returners:\n",
        "    # RET\n",
        "    df_punt_returns_table.loc[returner, \"RET\"] = df_all_punt_returns.loc[df_all_punt_returns['Returner'] == returner].shape[0]\n",
        "    # AVG\n",
        "    df_punt_returns_table.loc[returner, \"AVG\"] = round(float(df_all_punt_returns['Yardage'].loc[df_all_punt_returns['Returner'] == returner].mean()), 2)\n",
        "    # TD\n",
        "    df_punt_returns_table.loc[returner, \"TD\"] = df_all_punt_returns.loc[(df_all_punt_returns['Returner'] == returner) &\n",
        "                                                                        (df_all_punt_returns['PlayOutcome'].str.contains('touchdown', case=False))].shape[0]\n",
        "    # LNG\n",
        "    df_punt_returns_table.loc[returner, \"LNG\"] = int(df_all_punt_returns.loc[df_all_punt_returns['Returner'] == returner]['Yardage'].max())\n",
        "\n",
        "  return df_punt_returns_table"
      ],
      "metadata": {
        "id": "T0KVLqRTR_8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXOsRYYuiXxf"
      },
      "source": [
        "## Home and Away teams (Week 1, 2023)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6IG2fOYiKXQ"
      },
      "outputs": [],
      "source": [
        "# Season 2023 Week 1 schedule\n",
        "\n",
        "df_2023_week1_schedule = df_week1_plays_cleaned[['HomeTeam', 'AwayTeam', 'Season', 'Date', 'Day']].drop_duplicates().sort_values(by='Date').reset_index(drop=True)\n",
        "\n",
        "df_2023_week1_schedule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sfGIEjQpVm2"
      },
      "outputs": [],
      "source": [
        "dict_teams = {\n",
        "    'Cardinals': 'ARI', 'Falcons': 'ATL', 'Ravens': 'BAL', 'Bills': 'BUF', 'Panthers': 'CAR', 'Bears': 'CHI',\n",
        "    'Bengals': 'CIN', 'Browns': 'CLE', 'Cowboys': 'DAL', 'Broncos': 'DEN', 'Lions': 'DET', 'Packers': 'GB',\n",
        "    'Texans': 'HOU', 'Colts': 'IND', 'Jaguars': 'JAX', 'Chiefs': 'KC', 'Raiders': 'LV', 'Chargers': 'LAC',\n",
        "    'Rams': 'LA', 'Dolphins': 'MIA', 'Vikings': 'MIN', 'Patriots': 'NE', 'Saints': 'NO', 'Giants': 'NYG',\n",
        "    'Jets': 'NYJ', 'Eagles': 'PHI', 'Steelers': 'PIT', '49ers': 'SF', 'Seahawks': 'SEA', 'Buccaneers': 'TB',\n",
        "    'Titans': 'TEN', 'Commanders': 'WAS'\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pRagKkwJJYp"
      },
      "outputs": [],
      "source": [
        "dict_teams_2 = {\n",
        "    'ARI': 'Cardinals', 'ATL': 'Falcons', 'BAL': 'Ravens', 'BUF': 'Bills', 'CAR': 'Panthers', 'CHI': 'Bears',\n",
        "    'CIN': 'Bengals', 'CLE': 'Browns', 'DAL': 'Cowboys', 'DEN': 'Broncos', 'DET': 'Lions', 'GB': 'Packers',\n",
        "    'HOU': 'Texans', 'IND': 'Colts', 'JAX': 'Jaguars', 'KC': 'Chiefs', 'LV': 'Raiders', 'LAC': 'Chargers',\n",
        "    'LA': 'Rams', 'MIA': 'Dolphins', 'MIN': 'Vikings', 'NE': 'Patriots', 'NO': 'Saints', 'NYG': 'Giants',\n",
        "    'NYJ': 'Jets', 'PHI': 'Eagles', 'PIT': 'Steelers', 'SF': '49ers', 'SEA': 'Seahawks', 'TB': 'Buccaneers',\n",
        "    'TEN': 'Titans', 'WAS': 'Commanders'\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbnuMAHp2Pvd"
      },
      "source": [
        "## Scoring Table\n",
        "COLUMNS:\n",
        "- Each quarter of the game\n",
        "ROW:\n",
        "- Each team playing in game"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXun6Zd1Chv6"
      },
      "outputs": [],
      "source": [
        "# Some games may not have every play recorded.\n",
        "# (Week 1 2023, Game 1, 3rd quarter)\n",
        "# - A field goal was supposed to be recorded after the interception touchdown but\n",
        "#   was not.\n",
        "\n",
        "game_num = 3\n",
        "\n",
        "away_team = df_2023_week1_schedule['AwayTeam'].iloc[game_num]\n",
        "home_team = df_2023_week1_schedule['HomeTeam'].iloc[game_num]\n",
        "\n",
        "score_table(away_team, home_team, df_week1_plays_cleaned, dict_teams)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AWAY STATS"
      ],
      "metadata": {
        "id": "tRcsx3ze62Xs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "passing_table(away_team, home_team, df_week1_plays_cleaned, dict_teams_2, 1)"
      ],
      "metadata": {
        "id": "U9qm588052AO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDOqejGVMkNL"
      },
      "outputs": [],
      "source": [
        "rushing_table(away_team, home_team, df_week1_plays_cleaned, dict_teams, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GfWO2sMArjJ"
      },
      "outputs": [],
      "source": [
        "receiving_table(away_team, home_team, df_week1_plays_cleaned, dict_teams, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUQ_cjdkgT2k"
      },
      "outputs": [],
      "source": [
        "fumble_table(away_team, home_team, df_week1_plays_cleaned, dict_teams, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXwRXuPe6u2n"
      },
      "outputs": [],
      "source": [
        "interception_table(away_team, home_team, df_week1_plays_cleaned, dict_teams, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDtB9OMbZu3p"
      },
      "outputs": [],
      "source": [
        "defense_table(away_team, home_team, df_week1_plays_cleaned, dict_teams, 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kicking_table(away_team, home_team, df_week1_plays_cleaned, dict_teams, 1)"
      ],
      "metadata": {
        "id": "TS_mJJpsl5gY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "punting_table(away_team, home_team, df_week1_plays_cleaned, dict_teams, 1)"
      ],
      "metadata": {
        "id": "t9I6EpZ71hXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kickoff_returns_table(away_team, home_team, df_week1_plays_cleaned, dict_teams, 1)"
      ],
      "metadata": {
        "id": "01EuP-_VJTKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "punt_returns_table(away_team, home_team, df_week1_plays_cleaned, dict_teams, 1)"
      ],
      "metadata": {
        "id": "AasJowAPSwfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HOME STATS"
      ],
      "metadata": {
        "id": "QudNLboq7xpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "passing_table(away_team, home_team, df_week1_plays_cleaned, dict_teams_2, 0)"
      ],
      "metadata": {
        "id": "S6NYjUVW5HRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfDO4wbEMKZO"
      },
      "outputs": [],
      "source": [
        "rushing_table(away_team, home_team, df_week1_plays_cleaned, dict_teams, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2m12jat-aFe"
      },
      "outputs": [],
      "source": [
        "receiving_table(away_team, home_team, df_week1_plays_cleaned, dict_teams, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9TOQZaifFiE"
      },
      "outputs": [],
      "source": [
        "fumble_table(away_team, home_team, df_week1_plays_cleaned, dict_teams, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzmzQG4f7V92"
      },
      "outputs": [],
      "source": [
        "interception_table(away_team, home_team, df_week1_plays_cleaned, dict_teams, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9k_8__ZEhV2"
      },
      "outputs": [],
      "source": [
        "defense_table(away_team, home_team, df_week1_plays_cleaned, dict_teams, 0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kicking_table(away_team, home_team, df_week1_plays_cleaned, dict_teams, 0)"
      ],
      "metadata": {
        "id": "DIbejV-ixcpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "punting_table(away_team, home_team, df_week1_plays_cleaned, dict_teams, 0)"
      ],
      "metadata": {
        "id": "4txqtL122Ay5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kickoff_returns_table(away_team, home_team, df_week1_plays_cleaned, dict_teams, 0)"
      ],
      "metadata": {
        "id": "7Z16ywZtKZOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "punt_returns_table(away_team, home_team, df_week1_plays_cleaned, dict_teams, 0)"
      ],
      "metadata": {
        "id": "nyghoRoHS4xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Microscope (player observations)"
      ],
      "metadata": {
        "id": "xgJLDsCcx5eO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PM2lYhbYk6wA"
      },
      "outputs": [],
      "source": [
        "# every play with a players name in it\n",
        "\n",
        "df_all_plays_in_game = df_week1_plays_cleaned.loc[(df_week1_plays_cleaned['HomeTeam'] == home_team) &\n",
        "                                                  (df_week1_plays_cleaned['AwayTeam'] == away_team)]\n",
        "\n",
        "df_plays = df_all_plays_in_game.loc[(df_all_plays_in_game['PlayDescription'].str.contains(\"M.Sanders\"))]\n",
        "\n",
        "for idx, play in df_plays['PlayDescription'].items():\n",
        "  print(idx)\n",
        "  play_split = play.split(\". \")\n",
        "  for i in play_split:\n",
        "    print(i)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_unclean_plays_in_game = week1_2023_plays_modified.loc[(week1_2023_plays_modified['HomeTeam'] == home_team) &\n",
        "                                                         (week1_2023_plays_modified['AwayTeam'] == away_team)]\n",
        "\n",
        "df_unclean_plays = df_unclean_plays_in_game.loc[(df_unclean_plays_in_game['PlayDescription'].str.contains(\"L.Jackson\")) &\n",
        "                                                (df_unclean_plays_in_game['PlayDescription'].str.contains(\"fumbles\", case=False))]\n",
        "\n",
        "for idx, play in df_unclean_plays['PlayDescription'].items():\n",
        "  print(idx)\n",
        "  play_split = play.split(\". \")\n",
        "  for i in play_split:\n",
        "    print(i)\n",
        "  print()"
      ],
      "metadata": {
        "id": "yuSSy-3l1zwq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "HPdKuDJJPIUZ",
        "9JD1VzJWRWn0",
        "ELSW1R82_TqT",
        "uau4ner4_fug",
        "ZtbzjEyWlB8B",
        "XksC21RH41fY",
        "DFaoNUpK6sjg",
        "TJMX1xGDpQ3a",
        "XCAisXBXGNyb",
        "_Qs4C1j5asbR",
        "bRGsJa-J8CPe",
        "oHh3e-2kHDIM",
        "TieP_Cy5rmj-",
        "CZpJpikZCx--",
        "Rp-Bszm-B9rh",
        "eIX_e2jUrwdt",
        "Rt2DLo02qSa5",
        "yzGnlGvPZiZE",
        "xdlQ00Gxr216",
        "5B4OEwz2AwnX",
        "5TZ3ncsLtBrS",
        "dhsLNvcBA9uW",
        "I_uTKSIZsZDi",
        "9A1yQxl0kmLn",
        "9M6XwDERno2n",
        "LOqTmdy5ldib",
        "U7HnZWShxAX5",
        "p3xBIferz67H",
        "VYVhXDgbC3m3",
        "01U2No85CuOo",
        "wMTxhm9K2gY9",
        "56zcEqI4C9NQ",
        "F09Qp3xQ9oq9",
        "vMM5uVTFyDYu",
        "m-sl_mhsaHWQ",
        "3i6ytmPQ5463",
        "btd2EUHxtbL2",
        "QHp6b-_SqOw_",
        "MGd9pIPpvtL2",
        "Qh-8uXf-lvh1",
        "I4cK_IySHwL3",
        "sGpFgVAxl6Zd",
        "lXOsRYYuiXxf",
        "xgJLDsCcx5eO"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyP142hT8Z7r92fLIPCXNz2H",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}